{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import gamma\n",
    "from TLPP_Generation import Logic_Model_Generator\n",
    "from tqdm import *\n",
    "import itertools\n",
    "\n",
    "class LSTM_Encoding_Action(nn.Module):\n",
    "\n",
    "    '''\n",
    "    input: [batch_size, num_predicate, seq_length]\n",
    "    Parameters:\n",
    "        input_size:\n",
    "        hidden_size:\n",
    "        output_size:\n",
    "        num_layers:\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, device, num_layers:int = 1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_directions = 1 # one-directional LSTM\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x:torch.tensor):\n",
    "        batch_size, num_predicate, seq_length = x.shape\n",
    "        h_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        c_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        x, _  = self.lstm(x, (h_0, c_0)) #NOTE: x:(batch_size, seq_length, num_directions * hidden_size)\n",
    "        x = self.linear(x)\n",
    "        x = x.view(batch_size, num_predicate, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTM_Encoding_History(nn.Module):\n",
    "\n",
    "    '''\n",
    "    NOTE:Returns a categorical distribution\n",
    "\n",
    "    Parameters:\n",
    "        input_size:\n",
    "        hidden_size:\n",
    "        output_size:\n",
    "        num_layers\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, device, num_layers: int = 1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_directions = 1 # one-directional LSTM\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x:torch.tensor, action_embedding: torch.tensor):\n",
    "        '''\n",
    "        Parameters:\n",
    "            x: mental history\n",
    "            action_embedding: encoding of action history. This should be the output of LSTM_Encoding_Action\n",
    "        '''\n",
    "        batch_size, num_predicate, seq_length = x.shape\n",
    "        h_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        c_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        x, _ = self.lstm(x,(h_0,c_0))                              #NOTE: x:(batch_size, seq_length, num_directions * hidden_size)\n",
    "        x = torch.concat(tensors=[x, action_embedding], dim=1)     #NOTE: concatenate the action info and the mental info\n",
    "        batch_size, num_predicate, hidden_size = x.shape           #NOTE: num_predicate is changed\n",
    "        x = self.linear(x)                                         #NOTE: x:(batch_size, seq_length, num_directions * output_size)\n",
    "        x = x.view(batch_size, num_predicate, -1)\n",
    "        #TODO: return a vector with dimension (I+1), (I represents the number of types of mental states)\n",
    "        #TODO: the i-th (i=0,1,2,...,I) component of the output x represents the probability of the i-th mental type\n",
    "        x = self.softmax(x)\n",
    "        return x.view(-1,self.output_size).mean(axis=0)\n",
    "        \n",
    "\n",
    "class Logic_Model_Incomplete_Data:\n",
    "\n",
    "    def __init__(self, time_horizon:float, action_history:dict, hidden_size:tuple, output_size:tuple, batch_size:int, partition_size:float=0.1, device:str='cuda') -> None:\n",
    "        self.time_horizon = time_horizon\n",
    "        self.partition_size = partition_size            # num of small time intervals\n",
    "        self.action_history = action_history\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        #TODO:\n",
    "        ### the following parameters are used to manually define the logic rules\n",
    "        self.num_predicate = 7                  # num_predicate is same as num_node\n",
    "        self.num_formula = 8                    # num of prespecified logic rules\n",
    "        self.BEFORE = 'BEFORE'\n",
    "        self.EQUAL = 'EQUAL'\n",
    "        self.AFTER = 'AFTER'\n",
    "        self.Time_tolerance = 0.3               \n",
    "        self.body_predicate_set = []                        # the index set of all body predicates\n",
    "        self.mental_predicate_set = [0, 1, 2]\n",
    "        self.action_predicate_set = [3, 4, 5, 6]\n",
    "        self.head_predicate_set = [0, 1, 2, 3, 4, 5, 6]     # the index set of all head predicates\n",
    "        self.decay_rate = 1                                 # decay kernel\n",
    "        self.integral_resolution = 0.03\n",
    "\n",
    "        #TODO: convert the action_history:dict to a numpy array 'processed_data':np.array to put in the LSTMs\n",
    "        self.processed_data = self.process_data(action_history=self.action_history).to(device)\n",
    "        self.INPUT_SIZE_A = self.processed_data.shape[-1]\n",
    "        #self.INPUT_SIZE_M = int(self.time_horizon / self.partition_size)\n",
    "\n",
    "        #TODO: construct two LSTMs to encode the past history\n",
    "        #NOTE: encoding action history\n",
    "        self.LSTM_Action = LSTM_Encoding_Action(input_size=self.INPUT_SIZE_A,hidden_size=hidden_size[0],output_size=output_size[0],batch_size=batch_size,device=device)\n",
    "        self.LSTM_Action.to(device)\n",
    "        #NOTE: encoding whole history\n",
    "        self.LSTM_History = LSTM_Encoding_History(input_size=len(self.mental_predicate_set),hidden_size=hidden_size[1],output_size=output_size[1],batch_size=batch_size ,device=device)\n",
    "        self.LSTM_History.to(device)\n",
    "\n",
    "\n",
    "        ### the following parameters are used to generate synthetic data\n",
    "        ### for the learning part, the following is used to claim variables\n",
    "        ### self.model_parameter = {0:{},1:{},...,6:{}}\n",
    "        self.model_parameter = {}\n",
    "\n",
    "\n",
    "        '''\n",
    "        mental\n",
    "        '''\n",
    "\n",
    "        head_predicate_idx = 0\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.3).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.01).double(), requires_grad=True)\n",
    "        formula_idx = 1\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.01).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 1\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.3).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.02).double(), requires_grad=True)\n",
    "        formula_idx = 1\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.01).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 2\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.2).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.1).double(), requires_grad=True)\n",
    "\n",
    "\n",
    "        '''\n",
    "        action\n",
    "        '''\n",
    "        head_predicate_idx = 3\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.1).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.01).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 4\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.25).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.05).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 5\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.6).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.8).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 6\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.1).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.05).double(), requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #NOTE: set the content of logic rules\n",
    "        self.logic_template = self.logic_rule()\n",
    "    \n",
    "    def logic_rule(self):\n",
    "        #TODO: the logic rules encode the prior knowledge\n",
    "        # encode rule information\n",
    "        '''\n",
    "        This function encodes the content of logic rules\n",
    "        logic_template = {0:{},1:{},...,6:{}}\n",
    "        '''\n",
    "        logic_template = {}\n",
    "\n",
    "\n",
    "        '''\n",
    "        Mental (0-2)\n",
    "        '''\n",
    "\n",
    "        head_predicate_idx = 0\n",
    "        logic_template[head_predicate_idx] = {} # here 0 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (2 and 3 and 4) and before(2,0) and before(3,0) and before(4,0) \\to 0\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [2,3,4]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, 1, 1]  # use 1 to indicate True; use -1 to indicate False\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[2, 0], [3, 0], [4, 0]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE, self.BEFORE, self.BEFORE]\n",
    "\n",
    "\n",
    "        #NOTE: rule content: ((\\neg 0 and (2 and 6)) and after(6,0) and equal(2,0) \\to \\neg 0)\n",
    "        formula_idx = 1\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [0, 2, 6]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [-1, 1, 1]  # use 1 to indicate True; use -1 to indicate False\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [-1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[6, 0], [2, 0]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.AFTER, self.EQUAL]\n",
    "\n",
    "        head_predicate_idx = 1\n",
    "        logic_template[head_predicate_idx] = {}  # here 1 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: 5 and before(5,1) to 1\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [5]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[5, 1]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE]\n",
    "\n",
    "        #NOTE: rule content: (4 and 6) and before(6,1) to \\neg 1\n",
    "        formula_idx = 1\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [4, 6]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [-1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[6, 1]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE]\n",
    "\n",
    "\n",
    "        head_predicate_idx = 2\n",
    "        logic_template[head_predicate_idx] = {}  # here 2 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (\\neg 1 and 6) and after(1,2) to 2\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [1, 6]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [-1, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[1, 2]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.AFTER]\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Action (3-6)\n",
    "        '''\n",
    "        head_predicate_idx = 3\n",
    "        logic_template[head_predicate_idx] = {}  # here 3 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (0 and \\neg 1) and before(0,1) and before(1,3) \\to 3\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [0, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, -1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[0, 1], [1, 3]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE, self.BEFORE]\n",
    "\n",
    "\n",
    "        head_predicate_idx = 4\n",
    "        logic_template[head_predicate_idx] = {}  # here 4 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (2) and before(2,4) \\to 4\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [2]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[2, 4]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE]\n",
    "\n",
    "        \n",
    "        head_predicate_idx = 5\n",
    "        logic_template[head_predicate_idx] = {}  # here 5 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (0 and \\neg 1) and before(0,5) and after(1,5) \\to 5\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [0, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, -1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[0, 5], [1, 5]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE, self.AFTER]\n",
    "\n",
    "\n",
    "        head_predicate_idx = 6\n",
    "        logic_template[head_predicate_idx] = {}  # here 6 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (1 and 2) and before(1,6) and before(2,6) \\to \\neg 6\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [1, 2]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [-1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[1, 6], [2, 6]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE, self.BEFORE]\n",
    "\n",
    "\n",
    "        return logic_template\n",
    "\n",
    "    def intensity(self, cur_time, head_predicate_idx, history)->torch.tensor:\n",
    "        feature_formula = []\n",
    "        weight_formula = []\n",
    "        effect_formula = []\n",
    "        #TODO: Check if the head_prediate is a mental predicate\n",
    "        if head_predicate_idx in self.mental_predicate_set: flag = 0\n",
    "        else: flag = 1  #NOTE: action\n",
    "\n",
    "        for formula_idx in list(self.logic_template[head_predicate_idx].keys()):\n",
    "            weight_formula.append(self.model_parameter[head_predicate_idx][formula_idx]['weight'])\n",
    "\n",
    "            feature_formula.append(self.get_feature(cur_time=cur_time, head_predicate_idx=head_predicate_idx,\n",
    "                                                    history=history, template=self.logic_template[head_predicate_idx][formula_idx], flag=flag))\n",
    "            effect_formula.append(self.get_formula_effect(cur_time=cur_time, head_predicate_idx=head_predicate_idx,\n",
    "                                                       history=history, template=self.logic_template[head_predicate_idx][formula_idx]))\n",
    "        intensity = torch.exp(torch.cat(weight_formula, dim=0))/torch.sum(torch.exp(torch.cat(weight_formula, dim=0)), dim=0) * torch.cat(feature_formula, dim=0) * torch.cat(effect_formula, dim=0)\n",
    "        intensity = self.model_parameter[head_predicate_idx]['base'] + torch.sum(intensity)\n",
    "        intensity = torch.exp(intensity)\n",
    "\n",
    "        return intensity\n",
    "\n",
    "    def get_feature(self, cur_time, head_predicate_idx, history, template, flag:int):\n",
    "        #NOTE: flag: 0 or 1, denotes the head_predicate_idx is a mental or an action\n",
    "        #NOTE: 0 for mental and 1 for action\n",
    "        #NOTE: since for mental, we need to go through all the history information\n",
    "        #NOTE: while for action, we only care about the current time information\n",
    "        \n",
    "        transition_time_dic = {}\n",
    "        feature = torch.tensor([0], dtype=torch.float64)\n",
    "        for idx, body_predicate_idx in enumerate(template['body_predicate_idx']):\n",
    "            transition_time = np.array(history[body_predicate_idx]['time'])\n",
    "            transition_state = np.array(history[body_predicate_idx]['state'])\n",
    "            mask = (transition_time <= cur_time) * (transition_state == template['body_predicate_sign'][idx])\n",
    "            transition_time_dic[body_predicate_idx] = transition_time[mask]\n",
    "        transition_time_dic[head_predicate_idx] = [cur_time]\n",
    "        ### get weights\n",
    "        # compute features whenever any item of the transition_item_dic is nonempty\n",
    "        history_transition_len = [len(i) for i in transition_time_dic.values()]\n",
    "        if min(history_transition_len) > 0:\n",
    "            # need to compute feature using logic rules\n",
    "            time_combination = np.array(list(itertools.product(*transition_time_dic.values())))\n",
    "            time_combination_dic = {}\n",
    "            for i, idx in enumerate(list(transition_time_dic.keys())):\n",
    "                #TODO: this is where we distinguish mental and action\n",
    "                time_combination_dic[idx] = time_combination[:, i] if flag == 0 else time_combination[-1, i]\n",
    "            temporal_kernel = np.ones(len(time_combination))\n",
    "            for idx, temporal_relation_idx in enumerate(template['temporal_relation_idx']):       \n",
    "                #TODO: checkpoint\n",
    "                #print('head_predicate_idx: {}; temporal_relation_idx[0]: {}, temporal_relation_idx[1]: {}'.format(head_predicate_idx, temporal_relation_idx[0], temporal_relation_idx[1]))\n",
    "                #print('temporal combination dict: {}'.format(time_combination_dic))\n",
    "         \n",
    "                time_difference = time_combination_dic[temporal_relation_idx[0]] - time_combination_dic[temporal_relation_idx[1]]\n",
    "                if template['temporal_relation_type'][idx] == 'BEFORE':\n",
    "                    temporal_kernel *= (time_difference < - self.Time_tolerance) * np.exp(-self.decay_rate *(cur_time - time_combination_dic[temporal_relation_idx[0]]))\n",
    "                if template['temporal_relation_type'][idx] == 'EQUAL':\n",
    "                    temporal_kernel *= (abs(time_difference) <= self.Time_tolerance) * np.exp(-self.decay_rate*(cur_time - time_combination_dic[temporal_relation_idx[0]]))\n",
    "                if template['temporal_relation_type'][idx] == 'AFTER':\n",
    "                    temporal_kernel *= (time_difference > self.Time_tolerance) * np.exp(-self.decay_rate*(cur_time - time_combination_dic[temporal_relation_idx[1]]))\n",
    "            feature = torch.tensor([np.sum(temporal_kernel)], dtype=torch.float64)\n",
    "        return feature\n",
    "\n",
    "    def get_formula_effect(self, cur_time, head_predicate_idx, history, template):\n",
    "        ## Note this part is very important!! For generator, this should be np.sum(cur_time > head_transition_time) - 1\n",
    "        ## Since at the transition times, choose the intensity function right before the transition time\n",
    "        head_transition_time = np.array(history[head_predicate_idx]['time'])\n",
    "        head_transition_state = np.array(history[head_predicate_idx]['state'])\n",
    "        if len(head_transition_time) == 0:\n",
    "            cur_state = 0\n",
    "            counter_state = 1 - cur_state\n",
    "        else:\n",
    "            idx = np.sum(cur_time > head_transition_time) - 1\n",
    "            cur_state = head_transition_state[idx]\n",
    "            counter_state = 1 - cur_state\n",
    "        if counter_state == template['head_predicate_sign']:\n",
    "            formula_effect = torch.tensor([1], dtype=torch.float64)\n",
    "        else:\n",
    "            formula_effect = torch.tensor([-1], dtype=torch.float64)\n",
    "        return formula_effect\n",
    "\n",
    "    def log_likelihood(self, dataset, sample_ID_batch, T_max)->torch.tensor:\n",
    "        '''\n",
    "        This function calculates the log-likehood given the dataset\n",
    "        log-likelihood = \\sum log(intensity(transition_time)) + int_0^T intensity dt\n",
    "\n",
    "        Parameters:\n",
    "            dataset: \n",
    "            sample_ID_batch: list\n",
    "            T_max:\n",
    "        '''\n",
    "        log_likelihood = torch.tensor([0], dtype=torch.float64)\n",
    "        # iterate over samples\n",
    "        for sample_ID in sample_ID_batch:\n",
    "            # iterate over head predicates; each predicate corresponds to one intensity\n",
    "            data_sample = dataset[sample_ID]\n",
    "            for head_predicate_idx in self.head_predicate_set:\n",
    "                #NOTE: compute the summation of log intensities at the transition times\n",
    "                intensity_log_sum = self.intensity_log_sum(head_predicate_idx, data_sample)\n",
    "                #NOTE: compute the integration of intensity function over the time horizon\n",
    "                intensity_integral = self.intensity_integral(head_predicate_idx, data_sample, T_max)\n",
    "                log_likelihood += (intensity_log_sum - intensity_integral)\n",
    "        return log_likelihood\n",
    "\n",
    "    def intensity_log_sum(self, head_predicate_idx, data_sample):\n",
    "        intensity_transition = []\n",
    "        for t in data_sample[head_predicate_idx]['time'][1:]:\n",
    "            #NOTE: compute the intensity at transition times\n",
    "            cur_intensity:torch.tensor = self.intensity(t, head_predicate_idx, data_sample)\n",
    "            intensity_transition.append(cur_intensity)\n",
    "        if len(intensity_transition) == 0: # only survival term, no event happens\n",
    "            log_sum = torch.tensor([0], dtype=torch.float64)\n",
    "        else:\n",
    "            log_sum = torch.sum(torch.log(torch.cat(intensity_transition, dim=0)))\n",
    "        return log_sum\n",
    "\n",
    "    def intensity_integral(self, head_predicate_idx, data_sample, T_max):\n",
    "        start_time = 0\n",
    "        end_time = T_max\n",
    "        intensity_grid = []\n",
    "        for t in np.arange(start_time, end_time, self.integral_resolution):\n",
    "            #NOTE: evaluate the intensity values at the chosen time points\n",
    "            cur_intensity:torch.Tensor = self.intensity(t, head_predicate_idx, data_sample)\n",
    "            intensity_grid.append(cur_intensity)\n",
    "        #NOTE: approximately calculate the integral\n",
    "        integral = torch.sum(torch.cat(intensity_grid, dim=0) * self.integral_resolution)\n",
    "        return integral\n",
    "\n",
    "    def process_data(self, action_history:dict)->torch.tensor:\n",
    "        '''\n",
    "        Parameters:\n",
    "            action_history: dict\n",
    "        '''\n",
    "        #TODO: convert the action sequences into a numpy array\n",
    "        #NOTE: action_history = {\n",
    "        #                       3: {...}\n",
    "        #                       4: {...}\n",
    "        #                       5: {...}\n",
    "        #                       6: {...}\n",
    "        #                       }\n",
    "        # \"...\" stands for transition times for predicate 3,4,5,6. Recall that 3,4,5,6 are all action predicates\n",
    "        result = []\n",
    "        max_action_transition_time_length = 0       #NOTE: record the length of the transition time\n",
    "        for sample_id in action_history:            #NOTE: batch\n",
    "            for action_predicate_idx in self.action_predicate_set:\n",
    "                #print(sample_id, action_predicate_idx)\n",
    "                time = action_history[sample_id][action_predicate_idx]['time'][1:]\n",
    "                tmp = len(time)\n",
    "                if tmp > max_action_transition_time_length: max_action_transition_time_length = tmp\n",
    "                result.append(time)\n",
    "        #print(result)\n",
    "        data = np.zeros(shape=(len(action_history),len(self.action_predicate_set),max_action_transition_time_length))\n",
    "        for batch in range(data.shape[0]):\n",
    "            for row in range(data.shape[1]): \n",
    "                data[batch, row, :len(result[(batch+1)*row])] = result[(batch+1)*row]\n",
    "        return torch.tensor(data).float()\n",
    "\n",
    "    def ELBO(self, sample_ID_batch, temperature:float=1.0, device='cuda')->torch.tensor:\n",
    "        #TODO: compute the ELBO. \n",
    "        #TODO: Maximize the ELBO is equivalent to minimize the KL divergence between the variational posterior and the true posterior\n",
    "        #NOTE: in order to compute the ELBO, we need to 1. be able to sample from the variational posterior; 2. compute the entropy of q\n",
    "        \n",
    "        '''\n",
    "        compute the ELBO (MC estimate)\n",
    "\n",
    "        Parameters:\n",
    "            prob: \n",
    "            action_history: \n",
    "            sample_size: the number of samples we draw from the variational posterior\n",
    "        '''\n",
    "\n",
    "        time_intervals = np.arange(0,self.time_horizon+1e-4,step=self.partition_size)\n",
    "\n",
    "        #print(time_intervals)\n",
    "\n",
    "        #TODO: initialize. Store the complete data\n",
    "        complete_history = dict([(sample_id, self.action_history[sample_id]) for sample_id in sample_ID_batch])\n",
    "        for sample_id in complete_history:\n",
    "            for mental_predicate_idx in self.mental_predicate_set:\n",
    "                complete_history[sample_id][mental_predicate_idx] = {}\n",
    "                complete_history[sample_id][mental_predicate_idx]['time'] = [0]\n",
    "                complete_history[sample_id][mental_predicate_idx]['state'] = [0]\n",
    "        #print(complete_history)\n",
    "        mental_history = torch.zeros(size=(len(sample_ID_batch),1,len(self.mental_predicate_set))).to(device)\n",
    "\n",
    "        ELBO = (torch.tensor([0.0])).to(device)    #NOTE: initialize ELBO\n",
    "        #post_samples_collection = []\n",
    "\n",
    "        #TODO: encode the action history\n",
    "        h_a = self.LSTM_Action.forward(self.processed_data[sample_ID_batch,:,:])   # h_a (batch_size, num_predicate, output_size=hidden_size_m)\n",
    "        for sample_id in complete_history:\n",
    "            tmp = torch.tensor([0.0]).to(device)\n",
    "            for i in range(len(time_intervals)):\n",
    "                #TODO: encode the mental history before the i-th time interval (LSTMs)-> categorical distribution -> prob\n",
    "                prob = self.LSTM_History.forward(x=mental_history, action_embedding=h_a) # prob (1, num_mental_predicate+1)\n",
    "                logits = torch.log(prob)\n",
    "                #TODO: ELBO = ELBO + self.entropy_variational posterior\n",
    "                tmp += self.entropy_variational_posterior(logits,temperature,device=device)\n",
    "                #TODO: draw hard samples. post_samples = self.sample_variational_posterior_hard(size = sample_size, prob = prob)\n",
    "                post_samples:torch.tensor = self.sample_variational_posterior(size=len(sample_ID_batch),logits=logits,temperature=temperature,hard=True)\n",
    "                #print(post_samples)\n",
    "                #TODO: after sampling the mental transition time, update the history information\n",
    "                if i+1 >= len(time_intervals):break\n",
    "                event_time = (time_intervals[i] + time_intervals[i+1])/2\n",
    "                _, indices = post_samples.max(dim=1)\n",
    "                indices = indices.detach().cpu().numpy()\n",
    "                new_mental_information = torch.zeros(size=(len(sample_ID_batch),1,len(self.mental_predicate_set))).to(device)\n",
    "                for idx in indices:\n",
    "                    if idx == 0: continue\n",
    "                    #TODO: update the mental history\n",
    "                    new_mental_information[idx,0,idx-1] = event_time\n",
    "                    #TODO: update the complete history, which is a dict\n",
    "                    complete_history[sample_id][idx-1]['time'].append(event_time)\n",
    "                    if complete_history[sample_id][idx-1]['state'][-1] == 0: complete_history[sample_id][idx-1]['state'].append(1)\n",
    "                    else: complete_history[sample_id][idx-1]['state'].append(0)\n",
    "                #print(new_mental_information) #NOTE:checkpoint\n",
    "                #TODO: update mental_history\n",
    "                mental_history = torch.concat([mental_history,new_mental_information],dim=1)\n",
    "            #TODO: calculate mean of those ELBOs\n",
    "            ELBO += tmp/len(sample_ID_batch)\n",
    "    \n",
    "\n",
    "        #TODO: ELBO += 1/L * (\\sum log likelihood)\n",
    "        ELBO += 1/len(sample_ID_batch) * (self.log_likelihood(dataset=complete_history,sample_ID_batch=sample_ID_batch,T_max=self.time_horizon)).to(device)\n",
    "        #TODO: return ELBO\n",
    "        return ELBO*len(self.action_history) #NOTE: \\mathcal{L} * N\n",
    "\n",
    "    def sample_variational_posterior(self, size:int, logits: torch.tensor, temperature:float=1.0, hard=False)->torch.tensor:\n",
    "        #TODO: use gumbel-max trick to explicitly sample from the variational posterior defined by LSTMs, which is a categorical distribution\n",
    "        '''\n",
    "        draw explicit samples from variational posterior\n",
    "\n",
    "        Parameters:\n",
    "            size: number of samples\n",
    "            logits: \n",
    "            hard: boolean\n",
    "        '''\n",
    "    \n",
    "        result = []\n",
    "        for i in range(size):\n",
    "            tmp = self.gumbel_softmax(logits,temperature,hard)\n",
    "            result.append(tmp)\n",
    "        #NOTE: return one-hot vectors.\n",
    "        #print(result)\n",
    "        result = torch.stack(result,dim=0)\n",
    "        return result\n",
    "\n",
    "    def sample_Gumble(self, shape, eps:float=1e-20):\n",
    "        #TODO: sample from Gumbel(0,1). This is needed when we want to explicitly sample from the variational posterior\n",
    "        '''\n",
    "        Sample from Gumbel(0,1) with shape = 'shape'\n",
    "\n",
    "        Parameters:\n",
    "            shape: \n",
    "            eps: small perturbation to avoid log(0)\n",
    "            tens_type: \n",
    "        '''\n",
    "\n",
    "        U = torch.rand(shape)\n",
    "        U = U.cuda()\n",
    "        return -torch.log(-torch.log(U+eps)+eps)\n",
    "\n",
    "    def sample_Gumble_softmax(self, logits:torch.tensor, temperature=1.0):\n",
    "        #TODO: sample from the gumbel-softmax distribution\n",
    "        '''\n",
    "        Parameters:\n",
    "            prob: \n",
    "            temperature:\n",
    "        '''\n",
    "        y = logits + self.sample_Gumble(logits.shape)\n",
    "        return F.softmax(y/temperature,dim=-1)\n",
    "\n",
    "    def gumbel_softmax(self, logits:torch.tensor, temperature:float=1.0, hard=False):\n",
    "        #TODO: ST-gumbel-softmax\n",
    "        \"\"\"\n",
    "        ST-gumple-softmax\n",
    "        input: [*, n_class]\n",
    "        return: flatten --> [*, n_class] an one-hot vector\n",
    "        \"\"\"\n",
    "\n",
    "        y = self.sample_Gumble_softmax(logits,temperature)\n",
    "        if not hard: return y\n",
    "        shape = y.size()\n",
    "        _, idx = y.max(dim=-1)\n",
    "        y_hard = torch.zeros_like(y).view(-1,shape[-1])\n",
    "        y_hard.scatter_(1, idx.view(-1,1), 1)\n",
    "        y_hard = y_hard.view(*shape)\n",
    "        y_hard = (y_hard - y).detach() + y\n",
    "        return y_hard\n",
    "\n",
    "    def entropy_variational_posterior(self, logits:torch.tensor, temperature:float=1.0, MC_size:int=100, device='cuda')->float:\n",
    "        #TODO: approximately calculate the entropy of the variational posterior\n",
    "        #TODO: the true variational posterior (categorical) is approximated by a Gumbel-softmax distribution, controlled by 'tau' (temperature)\n",
    "        '''\n",
    "        Parameters:\n",
    "            temperature: temperature parameter\n",
    "            prob: probabilities for each category\n",
    "        '''\n",
    "        #TODO: draw 'MC_size' samples from gumble softmax distribution\n",
    "        gumbel_softmax_samples = self.sample_variational_posterior(size=MC_size,logits=logits,temperature=temperature).to(device)\n",
    "        #TODO: compute the log-densities\n",
    "        log_densities = torch.log(self.Gumbel_softmax_density(gumbel_softmax_samples,temperature,logits)).to(device)\n",
    "        #TODO: this is the Monte-Carlo estimate of the entropy\n",
    "        result = torch.mean(-log_densities)\n",
    "        return result\n",
    "\n",
    "    def Gumbel_softmax_density(self, y:torch.tensor, temperature:float, logits:torch.tensor)->torch.tensor:\n",
    "        #TODO: return the probability density of Gumbel softmax distribution at y\n",
    "        '''\n",
    "        Parameters:\n",
    "            y: input\n",
    "            temperature: temperature parameter\n",
    "            prob: probabilities for each category\n",
    "        '''\n",
    "        k = logits.size()[-1]\n",
    "        prob = torch.exp(logits)\n",
    "        #NOTE: compute the probability density. RHS is the density of gumbel softmax distribution\n",
    "        result = gamma(k) * (temperature)**(k-1) * (torch.multiply(prob,1/(y)**temperature))**(-k) * torch.sum(prob/y**(temperature+1))\n",
    "        return result\n",
    "\n",
    "    def optimize_ELBO(self, temperature, device, sample_ID_batch, optimizer_psi, optimizer_theta):\n",
    "        optimizer_theta.zero_grad()  # set gradient zero at the start of a new mini-batch\n",
    "        optimizer_psi.zero_grad()\n",
    "        #TODO: the loss function is just the -ELBO, since minimize the loss is equivalent to minimize the KL-divergence\n",
    "        loss = -self.ELBO(sample_ID_batch, temperature, device)\n",
    "        loss.backward()\n",
    "        optimizer_theta.step()\n",
    "        optimizer_psi.step()\n",
    "        return loss\n",
    "\n",
    "    def train_model(self, temperature:float=1.0, num_iter:int=10, lr:tuple=(0.01,0.02)):\n",
    "        #TODO: train the model from incomplete data by gradient descent\n",
    "        #TODO: 1. draw a minibatch ('batch_size') from the data, compute ELBO\n",
    "        #TODO: 2. compute gradient of ELBO w.r.t. to \\theta (model parameter) and \\psi (variational parameter, i.e. LSTM param)\n",
    "        #TODO: 3. gradient ascent, alternatively optimize \\theta and \\psi\n",
    "\n",
    "        model_parameters = [self.model_parameter[0]['base'],\n",
    "                    self.model_parameter[0][0]['weight'],\n",
    "                    self.model_parameter[0][1]['weight'],\n",
    "                    self.model_parameter[1]['base'],\n",
    "                    self.model_parameter[1][0]['weight'],\n",
    "                    self.model_parameter[1][1]['weight'],\n",
    "                    self.model_parameter[2]['base'],\n",
    "                    self.model_parameter[2][0]['weight'],\n",
    "                    self.model_parameter[3]['base'],\n",
    "                    self.model_parameter[3][0]['weight'],\n",
    "                    self.model_parameter[4]['base'],\n",
    "                    self.model_parameter[4][0]['weight'],\n",
    "                    self.model_parameter[5]['base'],\n",
    "                    self.model_parameter[5][0]['weight'],\n",
    "                    self.model_parameter[6]['base'],\n",
    "                    self.model_parameter[6][0]['weight']\n",
    "                    ]\n",
    "\n",
    "        num_batch = len(self.action_history) // self.batch_size\n",
    "        #print(num_batch)\n",
    "        losses = []\n",
    "        optimizer_theta = optim.Adam(params=model_parameters,lr=lr[0])\n",
    "        optimizer_psi = optim.SGD(params=[list(self.LSTM_Action.parameters())[0], list(self.LSTM_History.parameters())[0]], lr=lr[1])\n",
    "\n",
    "        for iter in tqdm(range(num_iter)):\n",
    "            for batch_idx in tqdm(np.arange(0, num_batch, 1)):\n",
    "                indices = np.arange(batch_idx*self.batch_size, (batch_idx+1)*self.batch_size, 1)\n",
    "                #NOTE: we want to minimize negative ELBO\n",
    "                loss = self.optimize_ELBO(temperature,self.device,indices,optimizer_psi,optimizer_theta) #NOTE:-ELBO, want to see it decreases\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            print('iter >> {}; loss >> {}'.format(iter+1, loss.detach().cpu().numpy()))\n",
    "            print('model parameter $\\\\theta$ >> {}'.format(model_parameters))\n",
    "            #print('LSTM parameters $\\psi$ >> {}'.format([list(self.LSTM_Action.parameters())[0], list(self.LSTM_History.parameters())[0]]))\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.15s/it]\n",
      "  2%|▏         | 1/50 [00:24<19:58, 24.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 1; loss >> [13057.362]\n",
      "model parameter $\\theta$ >> [tensor([-0.2700], dtype=torch.float64, requires_grad=True), tensor([0.0332], dtype=torch.float64, requires_grad=True), tensor([-0.0132], dtype=torch.float64, requires_grad=True), tensor([-0.2700], dtype=torch.float64, requires_grad=True), tensor([0.0143], dtype=torch.float64, requires_grad=True), tensor([0.0157], dtype=torch.float64, requires_grad=True), tensor([-0.1700], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.0705], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.2204], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5703], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0702], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.08s/it]\n",
      "  4%|▍         | 2/50 [00:48<19:27, 24.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 2; loss >> [13403.383]\n",
      "model parameter $\\theta$ >> [tensor([-0.2401], dtype=torch.float64, requires_grad=True), tensor([0.0416], dtype=torch.float64, requires_grad=True), tensor([-0.0216], dtype=torch.float64, requires_grad=True), tensor([-0.2399], dtype=torch.float64, requires_grad=True), tensor([0.0362], dtype=torch.float64, requires_grad=True), tensor([-0.0062], dtype=torch.float64, requires_grad=True), tensor([-0.1401], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.0414], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.1912], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5409], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0406], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.06s/it]\n",
      "  6%|▌         | 3/50 [01:12<19:00, 24.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 3; loss >> [13023.076]\n",
      "model parameter $\\theta$ >> [tensor([-0.2104], dtype=torch.float64, requires_grad=True), tensor([0.0513], dtype=torch.float64, requires_grad=True), tensor([-0.0313], dtype=torch.float64, requires_grad=True), tensor([-0.2099], dtype=torch.float64, requires_grad=True), tensor([0.0576], dtype=torch.float64, requires_grad=True), tensor([-0.0276], dtype=torch.float64, requires_grad=True), tensor([-0.1100], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.0124], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.1620], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5116], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0112], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.04s/it]\n",
      "  8%|▊         | 4/50 [01:37<18:33, 24.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 4; loss >> [12299.874]\n",
      "model parameter $\\theta$ >> [tensor([-0.1806], dtype=torch.float64, requires_grad=True), tensor([0.0504], dtype=torch.float64, requires_grad=True), tensor([-0.0304], dtype=torch.float64, requires_grad=True), tensor([-0.1801], dtype=torch.float64, requires_grad=True), tensor([0.0804], dtype=torch.float64, requires_grad=True), tensor([-0.0504], dtype=torch.float64, requires_grad=True), tensor([-0.0800], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.0166], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.1329], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4823], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0181], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.97s/it]\n",
      " 10%|█         | 5/50 [02:00<18:04, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 5; loss >> [12110.384]\n",
      "model parameter $\\theta$ >> [tensor([-0.1507], dtype=torch.float64, requires_grad=True), tensor([0.0517], dtype=torch.float64, requires_grad=True), tensor([-0.0317], dtype=torch.float64, requires_grad=True), tensor([-0.1502], dtype=torch.float64, requires_grad=True), tensor([0.1058], dtype=torch.float64, requires_grad=True), tensor([-0.0758], dtype=torch.float64, requires_grad=True), tensor([-0.0501], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.0454], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.1039], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4531], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0472], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.99s/it]\n",
      " 12%|█▏        | 6/50 [02:24<17:38, 24.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 6; loss >> [12165.336]\n",
      "model parameter $\\theta$ >> [tensor([-0.1208], dtype=torch.float64, requires_grad=True), tensor([0.0464], dtype=torch.float64, requires_grad=True), tensor([-0.0264], dtype=torch.float64, requires_grad=True), tensor([-0.1201], dtype=torch.float64, requires_grad=True), tensor([0.1346], dtype=torch.float64, requires_grad=True), tensor([-0.1046], dtype=torch.float64, requires_grad=True), tensor([-0.0202], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.0740], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.0751], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4240], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0760], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.04s/it]\n",
      " 14%|█▍        | 7/50 [02:49<17:15, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 7; loss >> [12406.336]\n",
      "model parameter $\\theta$ >> [tensor([-0.0907], dtype=torch.float64, requires_grad=True), tensor([0.0421], dtype=torch.float64, requires_grad=True), tensor([-0.0221], dtype=torch.float64, requires_grad=True), tensor([-0.0901], dtype=torch.float64, requires_grad=True), tensor([0.1600], dtype=torch.float64, requires_grad=True), tensor([-0.1300], dtype=torch.float64, requires_grad=True), tensor([0.0098], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.1025], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.0464], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3950], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1044], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.88s/it]\n",
      " 16%|█▌        | 8/50 [03:12<16:45, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 8; loss >> [11950.065]\n",
      "model parameter $\\theta$ >> [tensor([-0.0608], dtype=torch.float64, requires_grad=True), tensor([0.0403], dtype=torch.float64, requires_grad=True), tensor([-0.0203], dtype=torch.float64, requires_grad=True), tensor([-0.0601], dtype=torch.float64, requires_grad=True), tensor([0.1849], dtype=torch.float64, requires_grad=True), tensor([-0.1549], dtype=torch.float64, requires_grad=True), tensor([0.0398], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.1309], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.0178], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3661], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1325], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.98s/it]\n",
      " 18%|█▊        | 9/50 [03:36<16:21, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 9; loss >> [11758.396]\n",
      "model parameter $\\theta$ >> [tensor([-0.0309], dtype=torch.float64, requires_grad=True), tensor([0.0372], dtype=torch.float64, requires_grad=True), tensor([-0.0172], dtype=torch.float64, requires_grad=True), tensor([-0.0301], dtype=torch.float64, requires_grad=True), tensor([0.2081], dtype=torch.float64, requires_grad=True), tensor([-0.1781], dtype=torch.float64, requires_grad=True), tensor([0.0698], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.1590], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0105], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3374], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1602], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.99s/it]\n",
      " 20%|██        | 10/50 [04:00<15:58, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 10; loss >> [11984.389]\n",
      "model parameter $\\theta$ >> [tensor([-0.0010], dtype=torch.float64, requires_grad=True), tensor([0.0333], dtype=torch.float64, requires_grad=True), tensor([-0.0133], dtype=torch.float64, requires_grad=True), tensor([-2.9256e-05], dtype=torch.float64, requires_grad=True), tensor([0.2318], dtype=torch.float64, requires_grad=True), tensor([-0.2018], dtype=torch.float64, requires_grad=True), tensor([0.0998], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.1869], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0386], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3088], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1874], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.14s/it]\n",
      " 22%|██▏       | 11/50 [04:28<16:15, 25.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 11; loss >> [11407.76]\n",
      "model parameter $\\theta$ >> [tensor([0.0290], dtype=torch.float64, requires_grad=True), tensor([0.0318], dtype=torch.float64, requires_grad=True), tensor([-0.0118], dtype=torch.float64, requires_grad=True), tensor([0.0299], dtype=torch.float64, requires_grad=True), tensor([0.2570], dtype=torch.float64, requires_grad=True), tensor([-0.2270], dtype=torch.float64, requires_grad=True), tensor([0.1297], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.2146], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0665], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.2804], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.2141], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.04s/it]\n",
      " 24%|██▍       | 12/50 [04:55<16:15, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 12; loss >> [10993.996]\n",
      "model parameter $\\theta$ >> [tensor([0.0590], dtype=torch.float64, requires_grad=True), tensor([0.0352], dtype=torch.float64, requires_grad=True), tensor([-0.0152], dtype=torch.float64, requires_grad=True), tensor([0.0598], dtype=torch.float64, requires_grad=True), tensor([0.2852], dtype=torch.float64, requires_grad=True), tensor([-0.2552], dtype=torch.float64, requires_grad=True), tensor([0.1596], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.2420], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0941], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.2522], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.2403], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.90s/it]\n",
      " 26%|██▌       | 13/50 [05:21<16:01, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 13; loss >> [11230.803]\n",
      "model parameter $\\theta$ >> [tensor([0.0887], dtype=torch.float64, requires_grad=True), tensor([0.0403], dtype=torch.float64, requires_grad=True), tensor([-0.0203], dtype=torch.float64, requires_grad=True), tensor([0.0897], dtype=torch.float64, requires_grad=True), tensor([0.3151], dtype=torch.float64, requires_grad=True), tensor([-0.2851], dtype=torch.float64, requires_grad=True), tensor([0.1896], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.2692], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.1214], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.2242], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.2658], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.49s/it]\n",
      " 28%|██▊       | 14/50 [05:47<15:29, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 14; loss >> [11004.107]\n",
      "model parameter $\\theta$ >> [tensor([0.1183], dtype=torch.float64, requires_grad=True), tensor([0.0448], dtype=torch.float64, requires_grad=True), tensor([-0.0248], dtype=torch.float64, requires_grad=True), tensor([0.1196], dtype=torch.float64, requires_grad=True), tensor([0.3428], dtype=torch.float64, requires_grad=True), tensor([-0.3128], dtype=torch.float64, requires_grad=True), tensor([0.2196], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.2960], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.1484], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.1964], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.2906], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.50s/it]\n",
      " 30%|███       | 15/50 [06:12<15:00, 25.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 15; loss >> [10862.201]\n",
      "model parameter $\\theta$ >> [tensor([0.1477], dtype=torch.float64, requires_grad=True), tensor([0.0512], dtype=torch.float64, requires_grad=True), tensor([-0.0312], dtype=torch.float64, requires_grad=True), tensor([0.1496], dtype=torch.float64, requires_grad=True), tensor([0.3680], dtype=torch.float64, requires_grad=True), tensor([-0.3380], dtype=torch.float64, requires_grad=True), tensor([0.2495], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.3225], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.1751], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.1689], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.3147], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.55s/it]\n",
      " 32%|███▏      | 16/50 [06:38<14:34, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 16; loss >> [10530.671]\n",
      "model parameter $\\theta$ >> [tensor([0.1772], dtype=torch.float64, requires_grad=True), tensor([0.0566], dtype=torch.float64, requires_grad=True), tensor([-0.0366], dtype=torch.float64, requires_grad=True), tensor([0.1796], dtype=torch.float64, requires_grad=True), tensor([0.3908], dtype=torch.float64, requires_grad=True), tensor([-0.3608], dtype=torch.float64, requires_grad=True), tensor([0.2795], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.3487], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.2014], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.1416], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.3381], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.42s/it]\n",
      " 34%|███▍      | 17/50 [07:03<14:04, 25.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 17; loss >> [10850.061]\n",
      "model parameter $\\theta$ >> [tensor([0.2070], dtype=torch.float64, requires_grad=True), tensor([0.0577], dtype=torch.float64, requires_grad=True), tensor([-0.0377], dtype=torch.float64, requires_grad=True), tensor([0.2097], dtype=torch.float64, requires_grad=True), tensor([0.4129], dtype=torch.float64, requires_grad=True), tensor([-0.3829], dtype=torch.float64, requires_grad=True), tensor([0.3092], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.3745], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.2274], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.1145], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.3608], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.21s/it]\n",
      " 36%|███▌      | 18/50 [07:34<14:27, 27.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 18; loss >> [9970.026]\n",
      "model parameter $\\theta$ >> [tensor([0.2368], dtype=torch.float64, requires_grad=True), tensor([0.0627], dtype=torch.float64, requires_grad=True), tensor([-0.0427], dtype=torch.float64, requires_grad=True), tensor([0.2398], dtype=torch.float64, requires_grad=True), tensor([0.4337], dtype=torch.float64, requires_grad=True), tensor([-0.4037], dtype=torch.float64, requires_grad=True), tensor([0.3387], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.3999], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.2530], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.0878], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.3825], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.06s/it]\n",
      " 38%|███▊      | 19/50 [07:58<13:32, 26.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 19; loss >> [10598.629]\n",
      "model parameter $\\theta$ >> [tensor([0.2665], dtype=torch.float64, requires_grad=True), tensor([0.0665], dtype=torch.float64, requires_grad=True), tensor([-0.0465], dtype=torch.float64, requires_grad=True), tensor([0.2699], dtype=torch.float64, requires_grad=True), tensor([0.4535], dtype=torch.float64, requires_grad=True), tensor([-0.4235], dtype=torch.float64, requires_grad=True), tensor([0.3682], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.4250], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.2783], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.0613], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4035], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.93s/it]\n",
      " 40%|████      | 20/50 [08:25<13:11, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 20; loss >> [9612.775]\n",
      "model parameter $\\theta$ >> [tensor([0.2961], dtype=torch.float64, requires_grad=True), tensor([0.0731], dtype=torch.float64, requires_grad=True), tensor([-0.0531], dtype=torch.float64, requires_grad=True), tensor([0.3001], dtype=torch.float64, requires_grad=True), tensor([0.4756], dtype=torch.float64, requires_grad=True), tensor([-0.4456], dtype=torch.float64, requires_grad=True), tensor([0.3979], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.4496], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3031], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.0351], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4236], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.57s/it]\n",
      " 42%|████▏     | 21/50 [08:51<12:39, 26.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 21; loss >> [10143.4]\n",
      "model parameter $\\theta$ >> [tensor([0.3255], dtype=torch.float64, requires_grad=True), tensor([0.0764], dtype=torch.float64, requires_grad=True), tensor([-0.0564], dtype=torch.float64, requires_grad=True), tensor([0.3302], dtype=torch.float64, requires_grad=True), tensor([0.4989], dtype=torch.float64, requires_grad=True), tensor([-0.4689], dtype=torch.float64, requires_grad=True), tensor([0.4277], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.4738], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3275], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.0092], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4427], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.35s/it]\n",
      " 44%|████▍     | 22/50 [09:19<12:29, 26.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 22; loss >> [9555.602]\n",
      "model parameter $\\theta$ >> [tensor([0.3550], dtype=torch.float64, requires_grad=True), tensor([0.0769], dtype=torch.float64, requires_grad=True), tensor([-0.0569], dtype=torch.float64, requires_grad=True), tensor([0.3602], dtype=torch.float64, requires_grad=True), tensor([0.5225], dtype=torch.float64, requires_grad=True), tensor([-0.4925], dtype=torch.float64, requires_grad=True), tensor([0.4575], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.4975], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3515], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.0164], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4610], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.43s/it]\n",
      " 46%|████▌     | 23/50 [09:44<11:50, 26.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 23; loss >> [9630.955]\n",
      "model parameter $\\theta$ >> [tensor([0.3845], dtype=torch.float64, requires_grad=True), tensor([0.0730], dtype=torch.float64, requires_grad=True), tensor([-0.0530], dtype=torch.float64, requires_grad=True), tensor([0.3903], dtype=torch.float64, requires_grad=True), tensor([0.5464], dtype=torch.float64, requires_grad=True), tensor([-0.5164], dtype=torch.float64, requires_grad=True), tensor([0.4873], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.5208], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3750], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.0416], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4783], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.62s/it]\n",
      " 48%|████▊     | 24/50 [10:10<11:20, 26.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 24; loss >> [9688.427]\n",
      "model parameter $\\theta$ >> [tensor([0.4140], dtype=torch.float64, requires_grad=True), tensor([0.0742], dtype=torch.float64, requires_grad=True), tensor([-0.0542], dtype=torch.float64, requires_grad=True), tensor([0.4204], dtype=torch.float64, requires_grad=True), tensor([0.5687], dtype=torch.float64, requires_grad=True), tensor([-0.5387], dtype=torch.float64, requires_grad=True), tensor([0.5168], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.5436], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3981], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.0665], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4946], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.59s/it]\n",
      " 50%|█████     | 25/50 [10:39<11:14, 26.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 25; loss >> [9177.665]\n",
      "model parameter $\\theta$ >> [tensor([0.4433], dtype=torch.float64, requires_grad=True), tensor([0.0760], dtype=torch.float64, requires_grad=True), tensor([-0.0560], dtype=torch.float64, requires_grad=True), tensor([0.4505], dtype=torch.float64, requires_grad=True), tensor([0.5920], dtype=torch.float64, requires_grad=True), tensor([-0.5620], dtype=torch.float64, requires_grad=True), tensor([0.5466], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.5660], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.4207], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.0910], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5100], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.86s/it]\n",
      " 52%|█████▏    | 26/50 [11:08<11:06, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 26; loss >> [8950.231]\n",
      "model parameter $\\theta$ >> [tensor([0.4727], dtype=torch.float64, requires_grad=True), tensor([0.0806], dtype=torch.float64, requires_grad=True), tensor([-0.0606], dtype=torch.float64, requires_grad=True), tensor([0.4804], dtype=torch.float64, requires_grad=True), tensor([0.6131], dtype=torch.float64, requires_grad=True), tensor([-0.5831], dtype=torch.float64, requires_grad=True), tensor([0.5762], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.5878], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.4428], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.1151], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5244], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.70s/it]\n",
      " 54%|█████▍    | 27/50 [11:37<10:47, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 27; loss >> [8992.58]\n",
      "model parameter $\\theta$ >> [tensor([0.5024], dtype=torch.float64, requires_grad=True), tensor([0.0822], dtype=torch.float64, requires_grad=True), tensor([-0.0622], dtype=torch.float64, requires_grad=True), tensor([0.5102], dtype=torch.float64, requires_grad=True), tensor([0.6306], dtype=torch.float64, requires_grad=True), tensor([-0.6006], dtype=torch.float64, requires_grad=True), tensor([0.6057], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6091], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.4644], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.1389], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5379], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:31<00:00, 10.48s/it]\n",
      " 56%|█████▌    | 28/50 [12:09<10:41, 29.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 28; loss >> [8893.689]\n",
      "model parameter $\\theta$ >> [tensor([0.5322], dtype=torch.float64, requires_grad=True), tensor([0.0874], dtype=torch.float64, requires_grad=True), tensor([-0.0674], dtype=torch.float64, requires_grad=True), tensor([0.5397], dtype=torch.float64, requires_grad=True), tensor([0.6503], dtype=torch.float64, requires_grad=True), tensor([-0.6203], dtype=torch.float64, requires_grad=True), tensor([0.6353], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6298], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.4854], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.1622], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5504], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.26s/it]\n",
      " 58%|█████▊    | 29/50 [12:37<10:03, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 29; loss >> [8794.533]\n",
      "model parameter $\\theta$ >> [tensor([0.5619], dtype=torch.float64, requires_grad=True), tensor([0.0894], dtype=torch.float64, requires_grad=True), tensor([-0.0694], dtype=torch.float64, requires_grad=True), tensor([0.5694], dtype=torch.float64, requires_grad=True), tensor([0.6672], dtype=torch.float64, requires_grad=True), tensor([-0.6372], dtype=torch.float64, requires_grad=True), tensor([0.6649], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6500], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5060], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.1852], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5620], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.27s/it]\n",
      " 60%|██████    | 30/50 [13:02<09:11, 27.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 30; loss >> [8114.795]\n",
      "model parameter $\\theta$ >> [tensor([0.5917], dtype=torch.float64, requires_grad=True), tensor([0.0909], dtype=torch.float64, requires_grad=True), tensor([-0.0709], dtype=torch.float64, requires_grad=True), tensor([0.5990], dtype=torch.float64, requires_grad=True), tensor([0.6828], dtype=torch.float64, requires_grad=True), tensor([-0.6528], dtype=torch.float64, requires_grad=True), tensor([0.6944], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6697], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5260], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2077], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5727], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.81s/it]\n",
      " 62%|██████▏   | 31/50 [13:25<08:20, 26.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 31; loss >> [8125.856]\n",
      "model parameter $\\theta$ >> [tensor([0.6217], dtype=torch.float64, requires_grad=True), tensor([0.0946], dtype=torch.float64, requires_grad=True), tensor([-0.0746], dtype=torch.float64, requires_grad=True), tensor([0.6287], dtype=torch.float64, requires_grad=True), tensor([0.6994], dtype=torch.float64, requires_grad=True), tensor([-0.6694], dtype=torch.float64, requires_grad=True), tensor([0.7236], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6888], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5454], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2298], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5825], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.83s/it]\n",
      " 64%|██████▍   | 32/50 [13:48<07:38, 25.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 32; loss >> [8492.369]\n",
      "model parameter $\\theta$ >> [tensor([0.6517], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.0800], dtype=torch.float64, requires_grad=True), tensor([0.6583], dtype=torch.float64, requires_grad=True), tensor([0.7164], dtype=torch.float64, requires_grad=True), tensor([-0.6864], dtype=torch.float64, requires_grad=True), tensor([0.7528], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7073], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5643], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2514], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5915], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.94s/it]\n",
      " 66%|██████▌   | 33/50 [14:12<07:04, 24.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 33; loss >> [8171.044]\n",
      "model parameter $\\theta$ >> [tensor([0.6814], dtype=torch.float64, requires_grad=True), tensor([0.1004], dtype=torch.float64, requires_grad=True), tensor([-0.0804], dtype=torch.float64, requires_grad=True), tensor([0.6879], dtype=torch.float64, requires_grad=True), tensor([0.7352], dtype=torch.float64, requires_grad=True), tensor([-0.7052], dtype=torch.float64, requires_grad=True), tensor([0.7819], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7252], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5826], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2726], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5996], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.09s/it]\n",
      " 68%|██████▊   | 34/50 [14:40<06:50, 25.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 34; loss >> [8207.74]\n",
      "model parameter $\\theta$ >> [tensor([0.7110], dtype=torch.float64, requires_grad=True), tensor([0.0989], dtype=torch.float64, requires_grad=True), tensor([-0.0789], dtype=torch.float64, requires_grad=True), tensor([0.7174], dtype=torch.float64, requires_grad=True), tensor([0.7531], dtype=torch.float64, requires_grad=True), tensor([-0.7231], dtype=torch.float64, requires_grad=True), tensor([0.8111], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7426], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6004], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2933], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6069], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.17s/it]\n",
      " 70%|███████   | 35/50 [15:07<06:33, 26.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 35; loss >> [7851.0264]\n",
      "model parameter $\\theta$ >> [tensor([0.7402], dtype=torch.float64, requires_grad=True), tensor([0.0942], dtype=torch.float64, requires_grad=True), tensor([-0.0742], dtype=torch.float64, requires_grad=True), tensor([0.7471], dtype=torch.float64, requires_grad=True), tensor([0.7693], dtype=torch.float64, requires_grad=True), tensor([-0.7393], dtype=torch.float64, requires_grad=True), tensor([0.8401], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7593], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6175], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3135], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6135], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.33s/it]\n",
      " 72%|███████▏  | 36/50 [15:32<06:01, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 36; loss >> [7198.7065]\n",
      "model parameter $\\theta$ >> [tensor([0.7697], dtype=torch.float64, requires_grad=True), tensor([0.0879], dtype=torch.float64, requires_grad=True), tensor([-0.0679], dtype=torch.float64, requires_grad=True), tensor([0.7767], dtype=torch.float64, requires_grad=True), tensor([0.7854], dtype=torch.float64, requires_grad=True), tensor([-0.7554], dtype=torch.float64, requires_grad=True), tensor([0.8688], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7754], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6341], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3333], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6193], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.36s/it]\n",
      " 74%|███████▍  | 37/50 [15:57<05:33, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 37; loss >> [7338.2744]\n",
      "model parameter $\\theta$ >> [tensor([0.7991], dtype=torch.float64, requires_grad=True), tensor([0.0847], dtype=torch.float64, requires_grad=True), tensor([-0.0647], dtype=torch.float64, requires_grad=True), tensor([0.8062], dtype=torch.float64, requires_grad=True), tensor([0.8046], dtype=torch.float64, requires_grad=True), tensor([-0.7746], dtype=torch.float64, requires_grad=True), tensor([0.8977], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7909], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6501], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3525], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6246], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.40s/it]\n",
      " 76%|███████▌  | 38/50 [16:22<05:06, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 38; loss >> [7039.4453]\n",
      "model parameter $\\theta$ >> [tensor([0.8288], dtype=torch.float64, requires_grad=True), tensor([0.0772], dtype=torch.float64, requires_grad=True), tensor([-0.0572], dtype=torch.float64, requires_grad=True), tensor([0.8357], dtype=torch.float64, requires_grad=True), tensor([0.8175], dtype=torch.float64, requires_grad=True), tensor([-0.7875], dtype=torch.float64, requires_grad=True), tensor([0.9265], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8059], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6655], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3713], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6291], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.73s/it]\n",
      " 78%|███████▊  | 39/50 [16:49<04:42, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 39; loss >> [6955.9023]\n",
      "model parameter $\\theta$ >> [tensor([0.8581], dtype=torch.float64, requires_grad=True), tensor([0.0693], dtype=torch.float64, requires_grad=True), tensor([-0.0493], dtype=torch.float64, requires_grad=True), tensor([0.8650], dtype=torch.float64, requires_grad=True), tensor([0.8291], dtype=torch.float64, requires_grad=True), tensor([-0.7991], dtype=torch.float64, requires_grad=True), tensor([0.9557], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8202], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6802], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3895], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6332], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.15s/it]\n",
      " 80%|████████  | 40/50 [17:16<04:22, 26.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 40; loss >> [7181.3916]\n",
      "model parameter $\\theta$ >> [tensor([0.8872], dtype=torch.float64, requires_grad=True), tensor([0.0624], dtype=torch.float64, requires_grad=True), tensor([-0.0424], dtype=torch.float64, requires_grad=True), tensor([0.8944], dtype=torch.float64, requires_grad=True), tensor([0.8398], dtype=torch.float64, requires_grad=True), tensor([-0.8098], dtype=torch.float64, requires_grad=True), tensor([0.9852], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8338], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6944], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4072], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6367], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.59s/it]\n",
      " 82%|████████▏ | 41/50 [17:45<04:02, 26.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 41; loss >> [6478.3916]\n",
      "model parameter $\\theta$ >> [tensor([0.9164], dtype=torch.float64, requires_grad=True), tensor([0.0604], dtype=torch.float64, requires_grad=True), tensor([-0.0404], dtype=torch.float64, requires_grad=True), tensor([0.9239], dtype=torch.float64, requires_grad=True), tensor([0.8475], dtype=torch.float64, requires_grad=True), tensor([-0.8175], dtype=torch.float64, requires_grad=True), tensor([1.0145], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8469], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7080], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4244], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6397], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.34s/it]\n",
      " 84%|████████▍ | 42/50 [18:10<03:31, 26.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 42; loss >> [6627.542]\n",
      "model parameter $\\theta$ >> [tensor([0.9456], dtype=torch.float64, requires_grad=True), tensor([0.0586], dtype=torch.float64, requires_grad=True), tensor([-0.0386], dtype=torch.float64, requires_grad=True), tensor([0.9535], dtype=torch.float64, requires_grad=True), tensor([0.8551], dtype=torch.float64, requires_grad=True), tensor([-0.8251], dtype=torch.float64, requires_grad=True), tensor([1.0436], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8594], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7210], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4411], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6423], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.76s/it]\n",
      " 86%|████████▌ | 43/50 [18:36<03:04, 26.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 43; loss >> [6587.4775]\n",
      "model parameter $\\theta$ >> [tensor([0.9752], dtype=torch.float64, requires_grad=True), tensor([0.0592], dtype=torch.float64, requires_grad=True), tensor([-0.0392], dtype=torch.float64, requires_grad=True), tensor([0.9829], dtype=torch.float64, requires_grad=True), tensor([0.8610], dtype=torch.float64, requires_grad=True), tensor([-0.8310], dtype=torch.float64, requires_grad=True), tensor([1.0724], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8713], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7334], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4572], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6445], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.42s/it]\n",
      " 88%|████████▊ | 44/50 [19:01<02:36, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 44; loss >> [6578.3306]\n",
      "model parameter $\\theta$ >> [tensor([1.0047], dtype=torch.float64, requires_grad=True), tensor([0.0570], dtype=torch.float64, requires_grad=True), tensor([-0.0370], dtype=torch.float64, requires_grad=True), tensor([1.0123], dtype=torch.float64, requires_grad=True), tensor([0.8705], dtype=torch.float64, requires_grad=True), tensor([-0.8405], dtype=torch.float64, requires_grad=True), tensor([1.1012], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8826], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7452], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4728], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6463], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.37s/it]\n",
      " 90%|█████████ | 45/50 [19:27<02:08, 25.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 45; loss >> [6297.338]\n",
      "model parameter $\\theta$ >> [tensor([1.0342], dtype=torch.float64, requires_grad=True), tensor([0.0509], dtype=torch.float64, requires_grad=True), tensor([-0.0309], dtype=torch.float64, requires_grad=True), tensor([1.0417], dtype=torch.float64, requires_grad=True), tensor([0.8845], dtype=torch.float64, requires_grad=True), tensor([-0.8545], dtype=torch.float64, requires_grad=True), tensor([1.1299], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8933], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7564], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4879], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6479], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.75s/it]\n",
      " 92%|█████████▏| 46/50 [19:53<01:43, 25.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 46; loss >> [6213.596]\n",
      "model parameter $\\theta$ >> [tensor([1.0638], dtype=torch.float64, requires_grad=True), tensor([0.0472], dtype=torch.float64, requires_grad=True), tensor([-0.0272], dtype=torch.float64, requires_grad=True), tensor([1.0712], dtype=torch.float64, requires_grad=True), tensor([0.8972], dtype=torch.float64, requires_grad=True), tensor([-0.8672], dtype=torch.float64, requires_grad=True), tensor([1.1585], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9034], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7670], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5024], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6491], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.32s/it]\n",
      " 94%|█████████▍| 47/50 [20:18<01:16, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 47; loss >> [5682.2007]\n",
      "model parameter $\\theta$ >> [tensor([1.0931], dtype=torch.float64, requires_grad=True), tensor([0.0497], dtype=torch.float64, requires_grad=True), tensor([-0.0297], dtype=torch.float64, requires_grad=True), tensor([1.1007], dtype=torch.float64, requires_grad=True), tensor([0.9108], dtype=torch.float64, requires_grad=True), tensor([-0.8808], dtype=torch.float64, requires_grad=True), tensor([1.1870], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9130], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7771], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5163], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6502], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.44s/it]\n",
      " 96%|█████████▌| 48/50 [20:43<00:51, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 48; loss >> [5628.618]\n",
      "model parameter $\\theta$ >> [tensor([1.1226], dtype=torch.float64, requires_grad=True), tensor([0.0585], dtype=torch.float64, requires_grad=True), tensor([-0.0385], dtype=torch.float64, requires_grad=True), tensor([1.1300], dtype=torch.float64, requires_grad=True), tensor([0.9251], dtype=torch.float64, requires_grad=True), tensor([-0.8951], dtype=torch.float64, requires_grad=True), tensor([1.2153], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9220], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7867], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5298], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6510], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.63s/it]\n",
      " 98%|█████████▊| 49/50 [21:09<00:25, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 49; loss >> [5825.3135]\n",
      "model parameter $\\theta$ >> [tensor([1.1518], dtype=torch.float64, requires_grad=True), tensor([0.0597], dtype=torch.float64, requires_grad=True), tensor([-0.0397], dtype=torch.float64, requires_grad=True), tensor([1.1592], dtype=torch.float64, requires_grad=True), tensor([0.9372], dtype=torch.float64, requires_grad=True), tensor([-0.9072], dtype=torch.float64, requires_grad=True), tensor([1.2436], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9305], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7957], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5426], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6516], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.21s/it]\n",
      "100%|██████████| 50/50 [21:34<00:00, 25.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 50; loss >> [5657.096]\n",
      "model parameter $\\theta$ >> [tensor([1.1808], dtype=torch.float64, requires_grad=True), tensor([0.0601], dtype=torch.float64, requires_grad=True), tensor([-0.0401], dtype=torch.float64, requires_grad=True), tensor([1.1884], dtype=torch.float64, requires_grad=True), tensor([0.9480], dtype=torch.float64, requires_grad=True), tensor([-0.9180], dtype=torch.float64, requires_grad=True), tensor([1.2718], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9385], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.8042], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5550], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6521], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28628e1ab00>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKEAAAGwCAYAAABxdXa+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAABcSAAAXEgFnn9JSAAB1LElEQVR4nO3dd3gU1R7G8fekQ+hVOtJJQKVIlaIiTemigCCgAnbsFcu1oFiwV1BBURCkg6B0KSJKJ0jvHUILgfRz/9jNmoQEQpLNJtnv53n2Gc6ZOXN+i3cu5GXmjLHWCgAAAAAAAHAnH08XAAAAAAAAgLyPEAoAAAAAAABuRwgFAAAAAAAAtyOEAgAAAAAAgNsRQgEAAAAAAMDtCKEAAAAAAADgdoRQAAAAAAAAcDtCKAAAAAAAALgdIRQAAAAAAADcjhAKAAAAAAAAbkcIBQAAAAAAALcjhAIAAAAAAIDb+Xm6AGQfY8wRSfkl7fd0LQAAAAAAINepIOm8tfaqjAw21tosrgc5lTHmbGBgYMGqVat6uhQAAAAAAJDL7Ny5U9HR0RHW2kIZGc+dUN5lf9WqVUPCwsI8XQcAAAAAAMhlQkNDtXnz5gw/XcWaUAAAAAAAAHA7QigAAAAAAAC4HSEUAAAAAAAA3I4QCgAAAAAAAG5HCAUAAAAAAAC3I4QCAAAAAACA2xFCAQAAAAAAwO38PF0AAAAAAACAJFlrZa31dBlewRgjY0y2zkkIBQAAAAAAPCY+Pl7h4eGKiIhQTEyMp8vxKgEBASpYsKCKFy8uX19ft89HCAUAAAAAADwiPj5e+/btU1RUlKdL8UoxMTEKDw9XZGSkKlas6PYgihAKAAAAAAB4RHh4uKKiouTr66vSpUsrODhYPj4sX50dEhISFBkZqaNHjyoqKkrh4eEqVaqUW+ckhAIAAAAAAB4REREhSSpdurQKFy7s4Wq8i4+Pj+v3/NChQ4qIiHB7CEW8CK9zPPK4Hvn1Ed35y53acHSDp8sBAAAAAK9krXWtARUcHOzharxX4u99TEyM2xeF504oeJU52+do4PSBOhp5VJI0c+tMfXnbl7r72rs9XBkAAAAAeJekgQeP4HlO0t97a61b35jHf2V4hQuxF/TonEfV8aeOrgBKki7EXVD/af314OwHFR0X7cEKAQAAAADI2wihkOetP7Je14+6Xp+s+sTVF+gbqKJBRV3tL/75Qi3HtNT+M/s9USIAAAAAAHkeIRTyrASboJF/jlSj0Y0UdjzM1V+3VF39M/gfrR2yVg3LNnT1rzq4SvW/rq8FuxZ4olwAAAAAAPI0QijkSQfPHlS7ce305O9PKiY+xtX/eJPHtWrQKtUpVUeVilTS0oFLNbj+YNf+E+dPqO24tnpr6VtKsAmeKB0AAAAAgDyJEAp5zpR/p+iaL6/R/F3zXX1lCpTR731/18h2IxXkF+TqD/IL0ledvtK3nb919SfYBL2w8AV1+7mbTkedzu7yAQAAAADIkwihkGecizmne6ffqx4Te+jkhZOu/m61umnDAxt0S9Vb0hw7sN5Arbhnha4ucrWrb8bWGbp+1PXacHSDW+sGAAAAAMAbEEIhT1h1cJXqfVVP36771tWX3z+/Rncarcl3TFaJ/CUue456Zepp9eDV6li9o6tvx8kdajK6icZtGOeWugEAAAAAyAqLFi1S79691ahRIxUrVkwffPCBp0u6CCEUcrW4hDi9vuR1NfummXac3OHqv77s9Vo3ZJ3urX+vjDHpPl/RfEU1s/dM/a/1/2TkGHch7oL6Te2nh2Y/lGx9KQAAAAAAPC06OloDBgzQhx9+qFGjRmnVqlXq2rWrnn32WZ0+fdrT5SVDCIVca/ep3Wo9prVeXvyy4m28JMnH+GhYi2Fafs9yVS9ePUPn9TE+ernVy/r1rl9VLF8xV//n/3yuVmNa6cDZA1lSPwAAAAAAmdW/f3/Nnj1b33//vQoUKKBJkyZp7Nixio2NVXh4uKfLS4YQCrmOtVbjNozTtV9eq+X7l7v6KxeprCUDluj1m16Xv69/pudpX629Vg9erQZlGrj6Vh5Yqfpf1dfC3QszfX4AAAAAADLjl19+0c8//6w+ffqocOHCkqT4+HgZY3TXXXepatWqHq4wOT9PFwBcidNRp/XA7Ac0YdOEZP19r+mrTzt8qsJBhbN0vspFKmvZPcv0yK+PaPTa0ZKk4+eP65YfbtHwm4brmebPXNHjfgAAAACA9LHW6kz0GU+XccUKBxbOtp8Thw8fLkm65Zb/XsTVq1cv9ezZU76+vtlSw5UghEKusWTPEvWb2k/7z+539RUOLKwvb/tSver0ctu8QX5BGtV5lJpWaKoHZz+o6PhoJdgEPbfgOa08uFJjuozJ8vALAAAAALzdmegzKjqiqKfLuGKnnj2lIkFF3D7P7t27tXbtWhlj1Lx582T7cmIAJfE4HnKBmPgYPT//ed049sZkAVSrSq204YENbg2gkrqn3j1ace8KVS5S2dU3bcs0XT/qem08ujFbagAAAAAAQJLmz58vSQoJCVHRorkjrONOKOR4G49u1Dsr3pGVlST5+fjp9Rtf19PNnpavT/amu/XL1NfqwavVd0pfzdkxR5K0/eR2NfmmicZ0GaOeoT2ztR4AAAAAQN4zYMCAi/q6du2qrl27utpLliyRJN10003ZVFXmEUIhx2tQtoFeavmS/rfkf6pZvKZ+7P6jGpRtcPmBblIsXzHN6jNLry95Xf9b8j9ZWZ2PPa8+U/qoWrFqqlemnsdqAwAAAIC8onBgYZ169pSny7hihQMzv1zL2LFjL+qrXLlyqiFUmzZtMj1fdiGEQq4wrOUw5fPLp4cbPazggGBPlyMf46NXWr+ixuUbq8/kPjoVdUpxCXHqP62//h70twL9Aj1dIgAAAADkasaYbFlbKSey1l5y/86dO3XgwAEFBgaqdevW2VNUFmBNKOQKfj5+evaGZ3NEAJVU+2rtNfmOya72xmMb9dqS1zxYEQAAAAAgr0u8C+r2229XoUKFPFxN+hFCAZl049U36uHrH3a1317+tlYdXOXBigAAAAAAedmiRYsUGBiofv366bffftOCBQt0+vTpi4779ttvNWvWrOwvMA08jgdkgbfbvK05O+Zo56mdSrAJ6j+tv9YMXqN8/vk8XRoAAAAAIA85deqUZs6cqYSEBLVv397VX7BgQQ0ZMkQtW7bU0aNHNWPGDPXp00e33XabB6tNjjuhgCwQHBCsMV3HyMhIkrac2KKXFr3k4aoAAAAAAHlJWFiY+vTpowYNGqhv377q2bOnQkNDFRAQoIiICL333nsaMmSINm/erFGjRqlXr16eLjkZ7oQCssgNFW/Q400e18iVIyVJI/8cqa61uuqGijd4uDIAAAAAQF4QGhqqOXPmXNRvrdWRI0cUFBSkokWLeqCy9OFOKCALvXHTG6pVopYkycpqwLQBioyJ9HBVAAAAAIC8zBijMmXK5OgASiKEArJUPv98GtNljHyM49LaeWqnnpv/nIerAgAAAADA8wihgCzWuHxjPdv8WVf7078/1cLdCz1YEQAAAAAAnkcIBbjBK61eUd1SdV3te6bfo7PRZz1YEQAAAAAAnkUIBbhBoF+gxnYdKz8fx9r/e8/s1VO/P+XhqgAAAAAA8BxCKMBN6pWpp2Ethrnao9aM0twdcz1YEQAAAAAAnkMIBbjRCy1eUP0y9V3t+2bcp9NRpz1XEAAAAADkEMYY168TEhI8WIl3S/p7n/S/iTsQQgFu5O/rr7FdxyrAN0CSdDDioIbOHerhqgAAAADA84wxCghw/KwUGRnp4Wq8V+LvfUBAgNtDKD+3nh2A6pSqo/+1/p+eX/C8JOn79d+rR+0e6lyzs4crAwAAAADPKliwoMLDw3X06FFJUnBwsHx8uF8mOyQkJCgyMtL1e1+wYEG3z0kIBWSDp5o9pWlbpumvg39JkgbPHKzmFZqreP7iHq4MAAAAADynePHiioyMVFRUlA4dOuTpcrxWUFCQihd3/8+nxItANvDz8dPYrmMV5BckSToaeVQP/fqQh6sCAAAAAM/y9fVVxYoVVbx4cdejecg+AQEBKl68uCpWrChfX1+3z8edUEA2qVmipobfNFxP/P6EJOnnsJ/Vo3YP9Qzt6eHKAAAAAMBzfH19VapUKZUqVUrWWllrPV2SVzDGuH0NqJQIoYBsNLTJUE3dMlVL9y2VJD0w+wG1rNRSpQuU9nBlAAAAAOB5nghGkH14HA/IRj7GR991+U75/fNLksIvhOv+2feT9AMAAAAA8jxCKCCbVS1WVe/e8q6rPW3LNP248UcPVgQAAAAAgPsRQgEecH/D+3XT1Te52o/MeUQHzx70YEUAAAAAALgXIRTgAT7GR992/lYFAwpKkk5HndagmYO86rG8qLgoHY887ukyAAAAAADZhBAK8JBKRSppZLuRrvacHXP07dpvPVhR9jgeeVzPz39eJd8tqavev0rDFg7zqvANAAAAALwVIRTgQffWu1cdqnVwtR//7XHtO7PPgxW5z9FzR/X070+r8keV9fbyt3Uu5pwSbILeXPqmHpz9oOIT4j1dIgAAAADAjQihAA8yxmhUp1EqElREkhQRE6F7Z9ybp+4MOhxxWE/89oSu/uhqvffnezofe/6iY75c/aX6Tu2rmPgYD1QIAAAAAMgOhFCAh5UrVE4ft//Y1Z6/a76+/OdLD1aUNQ6ePahH5zyqqz+6Wh+s/EAX4i649pXIX0LDbxqupuWbuvombJqgrhO6phpSAQAAAAByP0IoIAfoe01fdanZxdV+at5TGrFshI6cO+LBqjJm35l9emj2Q6rycRV9suoTRcdHu/aVCi6ld295V3uG7tHzLZ7XvH7zdEuVW1z75+yYo/bj2utM1BlPlA4AAAAAcCOTlx77waUZY8JCQkJCwsLCPF0KUnH03FGFfh6q8Avhrj5f46vbatzmWDuqegf5+fh5sMJL23N6j95e9ra+XfutYhNik+27qsBVerb5sxrcYLDy++dPti86Llp9pvTRlH+nuPrqXVVPv/X9TSWDS2ZL7QAAAACAywsNDdXmzZs3W2tDMzKeO6GAHKJ0gdIa23WsgvyCXH3xNl7Tt05X5wmdVfGDinphwQvacXKHB6u82K5Tu3TfjPtU/ZPq+mr1V8kCqLIFy+rj9h9r16O79FiTxy4KoCQp0C9QP9/+swZeN9DVt/bIWrX4roX2n9mfLd8BAAAAAOB+3AnlRbgTKnfYe3qvvlv3nb5b912ab8prVamV7q13r3qE9Eg12MkO28O3a/iy4fph/Q+Kt8nfbFehUAU9f8PzGlhvYLJQ7VKstXrq96c0cuXIZOeZf/d81SheI0trBwAAAABcuczeCUUI5UUIoXKX+IR4zd81X9+s/UbTtky76BE3SSocWFh96vbRvfXuVf0y9WWMcXtdW09s1ZtL39SPG39Ugk1Itq9S4Up6ocULGnDdAAX4Blzxua21enPpm3pp0UuuvpL5S+q3vr+pXpl6ma4dAAAAAJBxhFBIN0Ko3Ot45HGN2zBO36z9RmHHU//vd23pa3Vf/ft0V927VDRf0UzPGR0XrQNnD+jA2QPaf3a/9p/ZrzVH1mjy5smySv7/G1WKVtGLLV5Uv2v6yd/XP9Nzf7rqUz0y5xFXu1BgIc3uM1s3VLwh0+cGAAAAAGSM14ZQxpgGkm6R1Mj5KSdJ1tqLbgUxxvhIai6pk6SbJdWQFCDpgKR5kkZYa3dfYq7mkl6U1MQ5brOkT621319iTHlJr0tqJ6mYpH2Sxkt6y1oblcaYfJKel9RLUkVJJyXNlfSStfZgWnOlFyFU7met1aqDq/TN2m80ftN4nYs5d9Exgb6B6l67u+6rf59aV24tH3Px0m+x8bE6GHHQETCd2e8KmQ5E/Nc+FnnssvVUL1Zdw1oOU5+6fbJ80fRxG8ZpwLQBrkf98vnl05Q7p6h9tfZZOg8AAAAAIH28OYSaJqlLyv40QqhqkrY7m0ckrZIUr//CqwhJHa21y1IZ20PSz3Is4v6HpBNyBFlFJL1vrX0qjfn+lFRC0iY5QquGkqpIWi7pZmttdIoxQZIWyRF0HZa0VFJlZ43HJTWx1u5K8zckHQih8pZzMec0KWySvln7jZbvX57qMVcXuVp3hN6hqLioZHc0HTl35KK7ma5ErRK1NKzFMN1Z5063vrFvxtYZumPSHYqOd1wu/j7+Gtd9nO4IvcNtcwIAAAAAUufNIdSzkoIl/e387JEUmEYIVVXSF5LelrTIOr+0MSZQ0peSBshxp1I1a21sknHFJO2WVEhSD2vtFGd/aUnLJFWTdKO1dnGK+ZbJcefVx9baoc4+P0kTJXWT9D9r7aspxrwhx91Wf0pqa6095+x/QtL7kpZYa1tf8W9U8jkIofKoLSe26Js13+j7Dd+n6w6m9DIyuqrAVapQuILKFyqvCoUqqEXFFupaq6t8fXyzbJ5LWbR7kTpP6Oy668vI6KvbvtKgBoOyZX4AAAAAgIPXhlApGWOilEYIdZlx+eS486iwpNbW2iVJ9j0jaYSk6dbarinGdZM0RdIsa22nJP2NJP0l6ZikiknveHKGV/slnZNUylob5+wPcB5fWFJ9a+3aFHOtl3SNpIbW2tVX8v1SnIcQKo+LjY/VrG2zNHrtaM3dMfeihcNTKpm/pCoUrqAKhZwf56/LFyqvCoUrqGzBshlaYDyr/X3wb7X/sb1OXjjp6hvRZoSeaf6MB6sCAAAAAO+S2RDKfc/R5BLW2gvGmG2SrpdUNsXuW53bX1IZOltSlKQ2xpigJOs8JY6ZmfKRO2vtUWPMUkk3SbpB0mLnruZyBFA7UwZQSea/Ro41rTIcQiHv8/f1V7fa3dStdjcdOHtA36//XuuOrFOJ/CVcdzIlBk3lCpVTkF+Qp0tOl+vLXa8/BvyhtuPa6lDEIUnSs/Of1akLpzT85uHZ8lZAAAAAAEDmeH0I5Vy0vJKzeSTF7mud2zUpx1lrY4wxm+RY66mGpA2XG5Ok/yY5QqXFVzBGzjFAupQvVF4vtHjB02VkmdBSoVo2cJlu+eEW7Ty1U5L09vK3dTrqtD679bNUF2AHAAAAAOQc/NQm9ZZUSo7Fv1ckdhpjCslxd5LkeIteahL7KyXpq5hNYwCvc3XRq7V04FLVLVXX1ffl6i/Vd0pfxcbHXmKk52wL36ZJYZNSfZMhAAAAAHgTr74TyhhTQdKHzubLKR6fK5Dk1+fTOEWkc1swlXHuHpMmY0xaiz5VTc94ICcrU7CMFg9YrFt/ulUrD6yUJI3fNF5no89qYs+Jyu+f38MVOqzYv0LvLH9H07dOlyTVLF5TK+5doWL5inm4MgAAAADwDK+9E8oYEyzHwuIlJE2z1n7p4ZIApFOxfMU0r988tanSxtU3e/tsNfi6gT7565NkC5hnpwSboJlbZ6rFdy3U/NvmrgBKkraGb1X3n7srJj7GI7UBAAAAgKd5ZQhljPGXNEmO9ZyWSeqTymFJn51J69aKYOc2IpVx7h6TJmttaGofSTvTMx7IDQoEFNCs3rPUvXZ3V9+WE1v06NxHVfb9suo7pa8W71ms7HgDaEx8jMasG6O6X9RV5wmdtWzfslSPW7J3ie6fdX+21AQAAAAAOY3XhVDOhcjHSuogaZ2kTtbaCymPs9aelXTG2SyfxukS+/cm6duXTWMArxfoF6ifb/9ZDzR8IFl/dHy0ftz4o24ce6NqflpTI5aN0NFzR7N8/rPRZ/X+ivdV5aMqGjh9oDYf35xsf4uKLTSz90z1u6afq++7dd/pneXvZHktAAAAAJDTeV0IJekTORYj3yapnbX29CWOXe/c1k+5w3k3VR1JUc5zXXZMiv4NSfoyMgaAJD8fP31+6+fa8tAWPd3saZXMXzLZ/u0nt+u5Bc+p/Afl1f3n7pqzfY7iE+IzNeeRc0f0woIXVPGDinpq3lM6GHHQtc/IqGutrlpxzwr9MfAP3VbjNo3qNEo3VLzBdcxzC57TlH+nZKoGAAAAAMhtTF55LMQYEyUp0FprLnHMG5JelOPOoxbW2n1pHes8/hlJIyRNt9Z2TbGvmxxrSs2y1nZK0t9I0l+SjkmqmHSxc2NMaUn75Xj8rrS1NtbZH+A8vrCketbadSnmWi/pGkkNrbWrL1XzZb5PWEhISEhYWFrrlgO5X0x8jGZunalRa0bp952/y+ri/4+rUKiC7ql3jwZeN1CViqT/pZPbwrfpvRXvaez6sRet7RTgG6C7r7lbTzZ7UrVK1Lpo7InzJ9R4dGPtOrVLkpTPL5+WDlyqBmUbXOE3BAAAAADPCA0N1ebNmzc7l/y5Yl4TQhljHpc0UtIRSS2ttdvTcc5iknZLKiSph7V2irO/lKTlkqpJutFauzjFuGWSmkv6yFr7mLPPT9LPkrpL+p+19tUUYxIDshWS2lprI539T0h6X9ISa23ry9V8me9DCAWvsvf0Xn279lt9u+5bHTh74KL9RkbtqrXTffXuU6eanRTgG5DqeVYdXKURy0do6r9TLwq1CgUW0gMNH9CjjR9V2YJlL1nPlhNb1GR0E52JdjzpW6ZAGa0atErlC6X1JC4AAAAA5BxeG0IZY26V9FKSrkaSjBx3ISV63Vo72xhznaQ1zv1/Kvnjc0mNttYmW1HYGNND0kTn2MWSwiW1kVRE0khr7ZOp1FbdOU9xSRslbZZ0vaQqcoRMNyW9Q8o5Jsh5/saSDktaKqmSs31cUhNr7a406k4XQih4q/iEeP228zeNXjNaM7fNVFxC3EXHlAoupf7X9td99e9TjeI1ZK3V3B1z9c6Kd7R4z+KLji9ToIweb/K4BjcYrMJBhdNdy/xd89V+XHvFW8cjgddddZ2WDlyqAgEFMvz9AAAAACA7eHMINUDSd5c5bKC1dowxprWkRek47UBr7ZhU5mouaZikJpIC5AiVPrXWjr1EfRUkvSapvaRicjwCOF7ScGttVBpj8kl6Xo639VWQdFLSXEkvWWsvvo3jChFCAY71nMauG6vRa0drx8kdqR7TslJLnbpwShuPbbxoX60StfR0s6d1V927FOgXmKEavl79tYbMGuJqd67ZWVPumCJfH98MnQ8AAAAAsoPXhlC4coRQwH+stVqyd4lGrRmlyZsnKzo++pLHN6vQTM82f1a31bhNPibz73R48rcnNXLlyP/aTZ/Ue23fy/R5AQAAAMBdMhtCeePb8QBAxhi1rtxaP3b/UYeePKSP23+suqXqXnRcpxqdtGzgMi2/Z7k61+ycJQGUJL1zyzvqVMP1TgO9/+f7GrV6VJacGwAAAAByIu6E8iLcCQVcmrVWfx/6W+M2jJMk3d/wfoWUDHHbfOdizumGb2/Q+qPrJUl+Pn6ae9dc3VzlZrfNCQAAAAAZxeN4SDdCKCDn2X9mvxqPbqzD5w5LkgoHFtbK+1aqVolaHq4MAAAAAJLjcTwAyMUqFK6gGb1nKJ9fPknSmegzuvWnW3Xi/AkPVwYAAAAAWYsQCgA8rGHZhhrXfZyrvevULnX7uZui4y69WDoAAAAA5CaEUACQA3Sv3V1v3fyWq71s3zINmjlIPDINAAAAIK8ghAKAHOLZ5s9q4HUDXe0fNvyg4UuHe7AiAAAAAMg6hFAAkEMYY/TlbV+qVaVWrr5hi4ZpYthED1YFAAAAAFmDEAoAcpAA3wBNvmOyqher7urrP62//jrwlwerAgAAAIDMI4QCgBymeP7imtVnlooGFZUkRcVFqcuELtp7eq+HKwMAAACAjCOEAoAcqEbxGpp8x2T5+fhJko5GHlWn8Z0UER3h4coAAAAAIGMIoQAgh7rx6hv15a1futobj21U78m9FZ8Q78GqAAAAACBjCKEAIAe7t/69errZ06727O2z9cRvT8ha68GqAAAAAODKEUIBQA73dpu31bVWV1f741Uf6+FfH1ZcQpznigIAAACAK0QIBQA5nI/x0bhu41S/TH1X3+f/fK5bf7pVZ6LOeLAyAAAAAEg/QigAyAWCA4L1a59f1ahcI1ff7zt/V7Nvm2n3qd0erAwAAAAA0ocQCgByidIFSmtx/8XqGdLT1bf5+GY1Ht1YK/av8GBlAAAAAHB5hFAAkIvk88+nCbdP0LAWw1x9x88f101jb9JPG3/yYGUAAAAAcGmEUACQy/gYH71+0+v6vuv3CvANkCRFx0frril36dXFr/LmPAAAAAA5EiEUAORS/a7tp/n95qt4vuKuvv8t+Z/umnKXouKisrWWfWf26bNVn2nZvmWEYAAAAABSRQgFALlYi0ot9Nd9f6lWiVquvvGbxuvGsTfq6Lmjbp9/x8kdum/Gfar6cVU9POdhtfiuhZp800RT/p2iBJvg9vkBAAAA5B6EUACQy1UtVlV/3vunbr76ZlffygMr1Xh0Y206tsktc24+vll9p/RVzU9r6pu13yguIc61b9XBVeoxsYdqf1Zbo9eMVnRctFtqAAAAAJC7EEIBQB5QJKiI5tw1R4PrD3b17T2zV82+aaa5O+Zm2TxrD6/V7RNvV53P6+jHjT8mu9upaFDRZMduC9+mQTMHqfJHlTVi2QidiTqTZXUAAAAAyH0IoQAgj/D39deXt32pkW1HyshIkiJiInTrT7fqs1WfZercKw+sVKfxnVT/6/qa/O9kWf237lO1YtX0bedvdeSpI1p13yrdHnK7a35JOnLuiJ5b8JwqflhRz857VocjDmeqFgAAAAC5k2EBWe9hjAkLCQkJCQsL83QpANxs5taZ6j25tyJjI119D1//sD5o/4H8fPzSdQ5rrf7Y+4feWPqG5u+af9H+0JKherHFi+oZ2vOic+44uUPvrXhPY9aNUXR88sfxAnwD1O+afnq62dOqWaJmBr4dAAAAAE8IDQ3V5s2bN1trQzMynhDKixBCAd5l3ZF16jS+kw6cPeDq61CtgybcPkGFAgulOc5aq993/q43lr6hZfuWXbS/3lX1NKzlMHWt1VU+5tI31B45d0Sf/PWJPv/nc52OOp1sn5FR11pd9WzzZ9W4fOMr+3IAAAAAsh0hFNKNEArwPocjDqvzhM7659A/rr46pepoVu9ZqlSkUrJjE2yCZm6dqTeWvpHs+ERNyzfVsJbD1KFaBxljLtp/KRHREfp69df6YOUHOhhx8KL9rSq10jPNn8nQuQEAAABkD0IopBshFOCdzsee191T79bkfye7+koFl9L0XtPVpHwTxSfE65fNv+jNpW9q47GNF42/sfKNGtZymG6sfGOmA6KY+Bj9uOFHvbPiHW05seWi/XVL1dUzzZ/RnaF3yt/XP1NzAQAAAMhahFBIN0IowHsl2AQNWzhMby17y9UX6BuoJ5o+ocn/Tta28G0XjelQrYNebPGimlds7pZ6Zm2bpRHLR2jF/hUX7a9YuKKGNh6qHrV7XHTHFgAAAADPIIRCuhFCARi7bqwGzRyk2ITYNI/pVqubXmzxohqUbZAtNS3bt0zvLH9HM7fNTHV/SMkQ3Vr9VnWs3lHNKzTnDikAAADAQwihkG6EUAAk6Y+9f6jbz9108sJJV5+P8dGdoXfqhRYvqE6pOh6pK+xYmN5d8a5+3Pij4hLiUj2mUGAhta3aVh2rdVSH6h10VYGrsrlKAAAAwHsRQiHdCKEAJNpxcod6T+6tsGNh6lWnl5674TnVKF7D02VJkvaf2a/P/v5M07ZM09bwrZc8tkGZBupYvaM6Vu+o68teL18f32yqEgAAAPA+hFBIN0IoAElZa2Vl5WN8PF1Kmnae3Kk5O+Zo9vbZWrR7kaLjo9M8tkT+Empfrb06VuuodtXaqVi+YtlYKQAAAJD3EUIh3QihAORm52PPa9HuRZq9fbZmb5+tfWf2pXmsj/FR0/JNXXdJXVv62ky/2Q8AAADwdoRQSDdCKAB5hbVW/574V7O3zdavO37Vsn3L0lxHSpLKFSynx5o8psebPJ6jHtnbf2a//j3xr1pXbq0A3wBPlwMAAABcEiEU0o0QCkBedSbqjObtmqdft/+qX7f/qqORR1M9rkn5JhrbdazH17+KjY/ViOUj9PofrysmPkZ96vbRj91/9GhNAAAAwOUQQiHdCKEAeIMEm6C1h9dq9vbZ+nX7r1p1cJWs/vuzLp9fPr3d5m093Ohhj6yHtfbwWt0z4x6tO7IuWf/i/ovVqnKrbK8HAAAASK/MhlA5dzVaAAAywMf4qEHZBnq51ctaed9KHX7ysPpd08+1/0LcBQ2dO1Q3f3+z9pzek211RcVF6YUFL+j6UddfFEBJ0pO/P6kEm5Bt9QAAAADZjRAKAJCnlS5QWt93+15T75yqUsGlXP2L9yxW3S/qatTqUXL3XcEr9q9Qva/q6a1lbynexrv6u9Xq5vr16sOrNX7jeLfWAQAAAHgSIRQAwCt0rdVVmx7YpB61e7j6zsWc0+BZg9Xxp446ePZgls8ZGROpx+Y+phu+vUFbTmxx9VcpWkUL716oKXdO0e0ht7v6X1j4gi7EXsjyOgAAAICcgBAKAOA1SgaX1KSek/RT959UNKioq3/ujrmq80UdjdswLsvuilqwa4HqflFXH/31kWtNKiOjxxo/pg33b9CNV98oSXr75rfl7+MvSdp3Zp8+/uvjLJkfAAAAyGkIoQAAXsUYo951e2vTg5t0a/VbXf2no06r39R+6jGxh45FHsvw+c9EndHgmYPV5oc22n16t6u/donaWn7Pcn3Q/gMFBwS7+qsWq6qHGz3sag9fNlzHI49neH4AAAAgpyKEAgB4pbIFy2pm75n6tvO3KhhQ0NU/dctUhX4eqsmbJ1/xOWdtm6XQz0M1as0oV5+v8dULN7ygNUPWqGmFpqmOG9ZymIoEFZEknY0+q9eWvHbFcwMAAAA5HSEUAMBrGWM0sN5AbXxgo266+iZX/4nzJ3T7pNt115S7dPLCycueJ/x8uPpO6atO4zvpYMR/a0tdd9V1+nvQ33rz5jcV5BeU5vhi+YrppZYvudpfrv5SW09szeC3AgAAAHImQigAgNerVKSS5vWbp087fKr8/vld/T9t/El1Pq+jX7f/muo4a60mhU1SyOch+nHjj67+AN8AvXHjG1p13yrVK1MvXTU8dP1DurrI1ZKkuIQ4PbfguUx8o8zbcmKLVuxf4dEaAAAAkLcQQgEAIMnH+OihRg9p/f3r1bxCc1f/4XOHdetPt2rQjEE6G332v/6Iw+oxsYfu+OWOZGtINS7XWGuHrNWLLV+Uv69/uucP9AvU223edrWnbZmmJXuWZPJbZczUf6eq7hd11fzb5np/xfseqQEAAAB5DyEUAABJVCtWTUsGLNG7t7yrQN9AV//otaNV94u6Wrh7ocauG6uQz0M0dctU1/58fvk0su1ILb9nuUJKhmRo7p4hPdWkfBNX+6l5TynBJmT8y2TA1hNb1X9af8UlxEmS/rfkf+l6JBEAAAC4HEIoAABS8PXx1VPNntKaIWvUsGxDV/++M/t08/c3a8D0ATodddrV37pya218YKMeb/q4fH18MzyvMUbvt/3vzqN/Dv2jCZsmZPh8VyoyJlI9JvZQREyEqy8iJkIfrvww22oAAABA3kUIBQBAGkJKhmjFPSv0WuvX5Ofjd9H+ggEF9eWtX2rB3QtUtVjVLJmzWYVmuj3kdlf7+QXPKyouKkvOfSnWWg2aOUhhx8Mu2vfRXx/p1IVTbq8BAAAAeRshFAAAl+Dv66+XWr2kVfetUt1SdV39Hap1UNiDYRrScIh8TNb+cfrWzW/J38exntS+M/v08V8fZ+n5U/Ppqk81ftN4V/vBhg+qSFARSdLZ6LP66K+P3F4DAAAA8jZCKAAA0qFemXr6e9DfmtBjgub1m6fZfWarQuEKbpmrWrFqeuj6h1ztN5e+qRPnT7hlLklasX+Fnvj9CVf7xso36qMOH+nxJo+7+j5c+WGyRxABAACAK0UIBQBAOgX6BerOOneqTZU2Msa4da5hLYcluxPptSWvuWWeo+eOqueknq6FyMsWLKvxPcbLz8dPjzZ+VIUDC0uSzkSfyZY7sgAAAJB3EUIBAJADFc9fXMNaDHO1v/jnC20L35alc8QlxKnX5F46FHFIkuTn46dJPSepdIHSkqQiQUU0tPFQ1/EfrPxAZ6LOZGkNAAAA8B6EUAAA5FAPN3pYVxe5WpIjMHp2/rNZev4XFrygxXsWu9oj245UswrNkh3zWJPHVCiwkCTpdNRpfbLqkyytAQAAAN6DEAoAgBwq0C9Qb7d529WetmWa/tj7R5ace8q/U/Tuindd7d51euvhRg9fdFzRfEX1aKNHXe2Rf45URHREltQAAAAA70IIBQBADtYzpKcal2vsaj/1+1NKsAmZOufWE1s1YNoAVzu0ZKhGdRqV5jpXjzd9XAUDCkqSTkWd0qerPs3U/AAAAPBOhFAAAORgxhi93/Z9V/vvQ3/r500/Z/h8kTGR6jGxhyJiHHczFQwoqCl3TlFwQHCaY4rlK6ZHGj3iar//5/s6F3MuwzUAAADAOxFCAQCQwzWv2Fw9avdwtZ9f8Lyi4qKu+DzWWg2aOUhhx8NcfWO6jlGN4jUuO/aJpk+oQEABSVL4hXB9tuqzK54fAAAA3o0QCgCAXODtNm/L38dfkrT3zF598teVLxD+6apPNX7TeFf76WZPq3vt7ukaWzx/cT18/X9rRr3353vcDQUAAIArQggFAEAuUK1YNT10/UOu9ptL39SJ8yfSPX7F/hV64vcnXO3WlVtr+M3Dr6iGJ5o+ofz++SVJJ86f0Bd/f3FF4wEAAODdCKEAAMglhrUcpiJBRSRJZ6LP6LUlr6Vr3NFzR9VzUk/FJcRJksoWLKsJPSbIz8fviuYvGVwyWRD27op3FRkTeUXnAAAAgPcihAIAIJconr+4hrUY5mp/8c8X2ha+7ZJj4hLi1GtyLx2KOCRJ8vPx06Sek1S6QOkM1fBUs6dcd0MdP39cX/7zZYbOAwAAAO9DCAUAQC7ycKOHVblIZUmOgOm5+c9d8vgXF7yoxXsWu9rvt31fzSo0y/D8pYJL6YGGD7ja7654V+djz2f4fBmxPXy79p7em61zAgAAIPNybQhljGlgjHnOGDPFGHPAGGONMTYd4wYYY1YZY84ZY04aY341xlzyb+PGmObO4046x60yxtx9mTHljTHfGWMOGWOijDHbjDH/M8YEXWJMPmPMa85jo5xjvzXGlLvc9wIAeIdAv0C9ffPbrvbULVO1dO/SVI+d+u9UvbPiHVe7d53eeqTRI5mu4elmTyufXz5J0tHIo/p69deZPmd6vbfiPdX8tKaqf1JdkzdPzrZ5AQAAkHm5NoSS9JKktyR1k5SukMYY86Gk7yTVkTRf0ipJt0j6wxjTNY0xPSQtkdRe0gZJcyVVlzTWGPNeGmOqSVoraYCkcEnTJflKelnSfGNMYCpjgiQtdH6vAs4x+yUNlLTWGFMlPd8RAJD33RF6hxqXa+xqP/n7k0qwCcmO2Ra+Tf2n9Xe1Q0qG6OtOX8sYk+n5Sxcorfsb3u9qj1g+QhdiL2T6vJczes1oPT3vaVlZxSbEqt/UflpzeI3b5wUAAEDWyM0h1J+SXpfUWVIZSdGXOtgY00bSUDlCoWuttV2tte0ltZQUL+k7Y0yRFGOKSfpWjgDpdmtta2vt7ZJqSdoh6UljTOtUphsjqYSkj621da21d0qqKWmqpOaSnk9lzDBJTZzfq4a19k5rbWNJT0oq6awDAAAZY/R+2/dd7b8P/a2JYRNd7ciYSPWY2EMRMRGSpIIBBTXljikqEFAgy2p4pvkzCvJz3Nx75NwRjVozKsvOnZop/07RkFlDkvVdiLugzuM763DEYbfODQAAgKyRa0Moa+0Ia+3L1tqZ1toj6RiS+F7qN6y125Oc509JX0oqIuneFGPuk1RI0nRr7ZQkY45KesbZfDLpAGNMIzmCpmNJjpG1Nk7SA5JiJT1qjPFLMiZA0sPO5kPW2nNJxo2U4w6sVsaYBun4ngAAL9C8YnP1qN3D1X5u/nOKiouStVaDZw3WpmObXPvGdB2jmiVqZun8VxW4SkMa/BcKjVg+QlFxUVk6R6JFuxep9+Terru9SuYvKV/jK0k6GHFQXX/umi13YgEAACBzcm0IdSWMMfkk3eRs/pLKIYl9nVL033qJMbMlRUlqk2Kdp8QxM621ye7OcoZXSyUVlXRDkl3NJRWWtNNau/YK6gMAeLG327wtPx/Hv2nsPbNXn/z1iT77+zP9tPEn1zFPN3ta3Wt3d8v8zzR/RoG+jifMD0Uc0ug1o7N8jn8O/aPOEzorJj5GklQkqIgW9l+oj9p/5Dpm1cFVunfGvbL2sktDAgAAwIO8IoSS41G4QEnHrbUHUtmfuKDENSn6r02x38VaGyNpk6QgSTXSM+YSc2VkDADAy1UrVk0PXf+Qq/36H6/rid+ecLVbV26t4TcPd9v8ZQuW1aD6g1ztt5e9rei4Sz4df0W2ntiqDj920LkYxw3C+fzyaXaf2apTqo4evP5B3d/gv3Wpxm8ar7eWvZVlcwMAACDreUsIVdG5TS2AkrU2UtJpSUWNMQUlyRhTSI67k9Icl6S/UnrnysIxaTLGhKX2kVQ1PeMBALnHSy1fUuFAxx9XETERik2IleQIiCb0mOC6U8pdnr3hWQX4BkhyPBr3zdpvsuS8B84e0C0/3KIT509Ikvx8/DT5jslqVsHxQltjjD7u8LFuuvom15gXF76oqf9OzZL5AQAAkPW8JYRKXIn1/CWOiXRuC6YYc6lxKcekZ66sGgMAgIrnL65hLYcl6/Pz8dOknpNUukBpt89fvlB53VfvPlf7rWVvZfpuqPDz4Wr7Q1vtP7tfkmRk9H3X79Wheodkx/n7+mtSz0mqVqyaq6/v1L5ad2RdpuYHAACAe3hLCOVVrLWhqX0k7fR0bQCArPdwo4d1dZGrXe33277vumMoOzx3w3Py9/GX5LiDacy6MRk+17mYc+r4U0f9e+JfV9/HHT5W77q9Uz2+WL5imtl7putusPOx59V5fGcdOZeed5YAAAAgO3lLCJX4trn8lzgm2LmNSDHmUuNSjknPXFk1BgAASVKQX5Dm3DVHfa/pq087fKpHGj2SrfNXKFxB99b77wWzw5cNdy0kfiWi46LV/efuWnVwlavvlVav6OFGD19ilFSrRC1N7DlRPsbx15r9Z/er28/d3Pa2PgAAAGSMt4RQ+5zb8qntNMYESyoi6ZS1NkKSrLVnJZ251Lgk/XvTO1cWjgEAwKVmiZr6odsPeqjRQzLGZPv8z7d43nU31L4z+zR23dgrGh+fEK9+U/tp3q55rr6Hrn9Ir7R6JV3j21Ztqw/afeBqrzywUoNnDuaNeQAAADmIt4RQWyVFSyppjCmXyv76zu2GFP3rU+x3Mcb4S6ojKUrStvSMucRcGRkDAECOUbFwRQ28bqCrPXzZcMXGx6ZrrLVWD/36kCZtnuTq612ntz7u8PEVBWqPNHok2dv6ftjwg95Z/k66xwMAAMC9vCKEstZekLTQ2eyZyiG3O7czU/TPTrE/qdskBUmab61Ner9/4phOxpjApAOMMaUltZB0StLyJLuWy3HXVVVjzHVXUB8AADnG8y2ed72Nb8/pPfp+/ffpGvfyopf11eqvXO12VdtpTNcxrsfr0ssYo087fqpWlVr9V9OC5zVj64wrOg8AAADcwytCKKeRzu0wY0z1xE5jTFNJQySdlpTyvdKjJZ2V1MUY0z3JmFKSEv9p9f2kA6y1q+QIlUpJGpFkjJ+kzyX5S/rYWhubZEyMpE+dzc+cjwcmjntC0jWSllhrV1/ZVwYAIPtULlJZ/a/t72q/ufTNy94N9eHKD/XG0jdc7Sblm2jyHZMV4BuQoRoCfAM0+Y7JqlK0iiTJyqrP5D7acJSbiQEAADwt14ZQxphbjTErEz+SApz9K5N8bk083lo7X9JHkopLWmeMmWaM+VXSH5L8JA201p5OOoe19qSkeyQlSPrFGLPQGDNJjsf7qkkaaa1dnEp5AyWFSxpqjNlgjJngHNNd0gpJb6Uy5g1Jf0lqJmm7MeZn5/d6X9JxZx0AAORoL7R4Qb7GV5K0+/RujdswLs1jf1j/gx7/7XFXO7RkqGb3ma3ggOA0x6RH8fzFNbP3TBUKLCRJioyNVOfxnXUs8limzgsAAIDMybUhlKSSkhon+SQuGpG0r2TSAdbax+QIiP6VdIukppLmS2pprZ2W2iTW2smSWkr6TVI9SR0l7ZA0wFr7ZBpjtjuPHeOsoZscQdbrkm621kanMiZK0o3OY85L6iqpkvMc9a21uy7xewEAQI5QpWgV3X3t3a72m0vfVFxC3EXHzd42WwOn/7eGVOUilfVb399ULF+xLKkjpGSIJvSY4Hqkb++Zver+c3dFx130RzAAAACyieGtMd7DGBMWEhISEhYW5ulSAAB52M6TO1Xz05qKt/GSpLFdxyYLppbuXaq249oqKs6xpGKp4FJaNnCZqhevnur5MmPknyP15O///ZvRgOsG6NvO33rkDYIAAAC5XWhoqDZv3rzZWhuakfHZeieUMaZjds4HAACyX9ViVdX3mr6u9ht/vOG6G2r9kfXqNL6TK4AqFFhIc++a65YASpIeb/K47rnuvyfax6wbo/f/fP8SI3KG6Lho7Ty5U/vO7PN0KQAAAFnGLytOYowpJKm4tXb3ZQ4tbYy5w1o7MSvmBQAAOdOLLV7UDxt+UIJN0PaT2zVh0wQ1Ld9U7ca105noM5KkQN9Azeg1Q/XK1HNbHcYYfXHbF9p+cruW7lsqSXpm3jOqVaKWbqtxm9vmvRRrrcIvhGvfmX2pfvae2asj5464jn+l1St6tfWrHqkVAAAgK2X6cTxjzFA53gLnL2mctbb/ZY6fLuk+a+3xTE2MK8bjeACA7HT31Lv1w4YfJEnVilVTgk3QrlOOJQ59ja+m3DlFnWt2zpZajkceV6PRjbTn9B5JUoGAAvrz3j9Vp1SdLJ8rOi5aB84euChYStq+EHfhis45/Kbher7F81leKwAAwJXI7ON4WRFChUuaJqm/HItvB9pLnNQYc6+k2tbapzI1Ma4YIRQAIDttPbFVIZ+HKMEmXLRvTJcx6n/dJf/dKsttOrZJTb9pqnMx5yRJVxe5WqsGrVKJ/CWu+FzxCfHad2aftpzYoq3hW13brSe26vC5w1lduiTpw3YfamiToW45NwAAQHpkNoTKisfxdlhr7zXGzJHke6kAyumopP9JIoQCACAPq1mipnrV6aWfNv6UrP+9W97L9gBKkuqUqqPxPcar8/jOsrLafXq3ekzsoXn95inANyDVMRHREf+FTCe2aku4Y7stfJui4zP3pr1g/2BVKlJJFQtXVMVCFR3bwhVdfX4+frr5+5u1LXybJOmx3x5TcECw7qt/X6bmBQAA8JSsCKF2GmPyWWt/SefxLSWVMcYUttaeyYL5AQBADjWsxTCN3zheVo5/o3qu+XN6stmTlxnlPrfVuE0j2ozQM/OfkST9sfcPPTj7QQ1rOcwRMqW4s+lQxKEMzWNkVLZgWVewlPJTqXAlFQkqctm39M3vN18tvmuhvWf2SpIGzxysfH75dNc1d2WoLgAAAE/KisfxWksaKqmftfbcZY4tLGmfpAKSylprj2ZqclwRHscDAHjCZ6s+08erPlafOn30cquXLxu8uJu1VgOnD9TY9WMzfa6KhSuqZvGaqlWilmoWr6maJWqqatGqKleoXJp3V12pXad2qcV3LVyBmK/x1aSek9StdrcsOT8AAEB6eXxNKEkyxoyR1EHSj5LmS1qe2l1OxpibnPujrbX5Mj0xrgghFAAADtFx0br5+5u1fP/yyx6b3z+/K2CqVbyWY1uilqoXq67ggOBsqFbacmKLWn7XUsfPO97r4u/jr+m9pqtD9Q7ZMj8AAICUc0KoAEnfS7pDknV+NktaKEfotNhae84Y01bSXEmbrLXXZHpiXBFCKAAA/nMs8phajWmlLSe2SJIqFKqQLGhKvMOpXKFy8jE+Hq5WWn9kvW4ce6NORZ2SJAX5BWnOXXPUunJrzxYGAAC8Ro4IoVwnM+Z2SS9Ius7ZlXjyaEmTJI2T9JukidbaXlk2MdKFEAoAgOSi4qK078w+lStYLtvuasqMVQdXqc33bRQREyHJsbj5vH7z1LRCUw9XBgAAvEFmQ6gs/Wc9a+0v1tr6kqpIGizpJ0kHJQVJ6idpuqQYSZdcOwoAACA7BPkFqUbxGrkigJKkRuUaaVafWcrn51jVIDI2Uh1+7KA1h9d4uDIAAIDLc8u95dbaPdba0dbaftbaipKqSbpX0mRJFyRVcse8AAAAeV3LSi01rdc018LnZ6LPqO0PbRV2jDudAQBAzpYtCxxYa3dZa7+z1vaT4y6p2OyYFwAAIC9qW7WtJt4+Ub7GV5IUfiFct/xwi3ac3OHhygAAANKW7atsWmtPSXoqu+cFAADIS7rU6qJx3cfJyEiSDp87rJu/v1l7T+/1cGUAAACpc2sIZYzpYox5OWW/tXazO+cFAADwBr3q9NI3nb9xtfed2ac2P7TR4YjDHqwKAAAgde6+E6qrpFfcPAcAAIDXGlhvoD7t8KmrvePkDrX5oY2ORx73YFUAAAAXy/bH8QAAAJC1Hmr0kEa0GeFqbz6+We3GtdPpqNOeKwoAACAFQigAAIA84Jnmz+jllv+tgrD2yFp1+LGDIqIjPFgVAADAfwihAAAA8ohXW7+qJ5o84WqvPLBSnSd01oXYCx6sCgAAwMHdIZRxfgAAAOBmxhi91/Y93d/gflff4j2L1X1id0XHRXuwMgAAADeHUNbaAdZa7rYCAADIJsYYfXbrZ7r72rtdfXN3zFXvyb0VlxDnwcoAAIC3IyACAADIY3yMj77p/I16hvR09U3dMlWdx3fWuiPrPFcYAADwaoRQAAAAeZCfj5/GdR+nW6vf6uqbs2OO6n1VT+3GtdPC3QtlrfVghQAAwNsQQgEAAORRAb4B+uWOX9Suartk/b/v/F03f3+zGo9urMmbJys+Id5DFQIAAG9CCAUAAJCHBfkFaXaf2Zp4+0TVL1M/2b6/D/2t2yfdrtqf1dao1aNYvBwAALgVIRQAAEAe5+vjq56hPfXPoH80r988tanSJtn+7Se3a/Cswar8UWWNWDZCZ6LOeKhSAACQlxFCAQAAeAljjNpUaaN5/ebpn0H/6I7QO+Rj/vvr4JFzR/TcgudU8cOKem7+czoccdiD1QIAgLyGEAoAAMALNSjbQD/f/rO2PrxVQxoMUaBvoGvf2eizGrF8hCp/VFmDZw7W9vDtHqwUAADkFYa3ongPY0xYSEhISFhYmKdLAQAAOcyRc0f08V8f6/O/P9eZ6OSP4xkZda/dXc82f1bXl7s+Q+e31ups9Fkdizx20edczDnVLllbDcs2VK0SteTn45cVXwkAAGSx0NBQbd68ebO1NjQj4wmhvAghFAAAuJyz0Wf19eqv9cHKD3Qo4tBF+2+6+iY92/xZ3VLlFsUmxOp45PFkgdLRyKOpBk3HIo8pOv7yC5/n98+velfVU4MyDdSwbEM1LNtQNYrXkK+Przu+LgAAuAKEUEg3QigAAJBe0XHRGrdhnN5d8a62hm+9aH+wf7AiYyOzpZYCAQVUv0z9ZMFUtWLVkq1nBQAA3I8QCulGCAUAAK5Ugk3Q9C3TNWL5CP118K9Mn8/H+Khk/pIqFVzK9fHz8dP6o+sVdixM8TY+XecpFFjIFUolbqsUrSJjTKZrBAAAqSOEQroRQgEAgIyy1uqPvX9oxPIRmrNjTrJ9BQIKqFRwKZUOLp0sXEqtr1i+Ymk+Wnch9oLWH12vfw794/r8e+JfJdiEdNVYNKioGpRtoIZlGrrumKpYuCLBFAAAWYQQCulGCAUAALLC3tN7dSzymEoFl1LJ4JLK75/fbXNFxkRq3ZF1jlDqsCOY2npiq6zS93fYEvlLOAKpJMFU2YJlCaYAAMgAQiikGyEUAADIC85Gn9Xaw2u1+vBq1x1T209uT/f4qwpcdVEwVbpAaTdWDABA3kAIhXQjhAIAAHnV6ajTWnN4jf459I8rnNp1ale6x5cvVD5ZMNWgbAOVyF/CjRUDAJD7EEIh3QihAACANzl54aRWH1qd7FG+fWf2pXt85SKV1apSK71505sqV6icGysFACB3yGwI5ZfVBQEAAAA5QbF8xXRL1Vt0S9VbXH3HIo9p9aHVyR7lOxhxMNXxe07v0Z7Te/TngT+1ZvAaBQcEZ1fpAADkSYRQAAAA8BqlgkupQ/UO6lC9g6vvcMThZKHU34f+1rHIY67928K36bG5j2lU51GeKBkAgDyDEAoAAABerUzBMrqt4G26rcZtkiRrrQ5GHNSIZSP06d+fSpJGrx2tdtXa6faQ2z1ZKgAAuZqPpwsAAAAAchJjjMoXKq+R7Ubq+rLXu/oHzRyk/Wf2e7AyAAByN0IoAAAAIBX+vv76qcdPKhBQQJLjDXx9p/ZVfEK8hysDACB3IoQCAAAA0lCtWDV91vEzV/uPvX/o7WVve7AiAAByL0IoAAAA4BL6XdNPvev0drVfWfyKVh5Y6cGKAADInQihAAAAgEswxuiLW79Q5SKVJUnxNl59JvfR2eizni0MAIBchhAKAAAAuIzCQYX1Y/cf5WMcf33efXq3Hvr1IQ9XBQBA7kIIBQAAAKRDswrN9EqrV1ztcRvGadyGcR6sCACA3IUQCgAAAEinF1q8oBsq3uBqPzj7Qe06tcuDFQEAkHsQQgEAAADp5Ofjp3HdxqlwYGFJUkRMhPpM7qPY+FgPV5Zx07ZM073T79WsbbM8XQoAII8jhAIAAACuQKUilfR1p69d7b8O/qXXlrzmwYoy5nzsed034z51+7mbvl33rTqN76Q7f7lTxyKPebo0AEAeRQgFAAAAXKE7Qu/QwOsGutpvLn1TS/Ys8WBFV2bLiS1qPLqxvln7TbL+iWETFfp5qCZsmiBrrYeqAwDkVYRQAAAAQAZ83OFjVS9WXZJkZdV3al+dvHDSw1Vd3rgN49Tw64badGyTq69IUBHXr0+cP6Hek3ur28/ddDjisAcqBADkVYRQAAAAQAYUCCign3r8JD8fP0nSgbMHNGjmoBx7B1Hi43f9pvZTZGykq//Jpk/qyJNH9EmHTxTsH+zqn751ukI+D9HYdWNz7HcCAOQuhFAAAABABjUs21Bv3vSmqz3l3ykXPeKWE6T2+F3RoKKa3mu63mv7ngL9AvVwo4e18YGNuunqm1zHnI46rQHTB6jjTx21/8x+T5QOAMhDCKEAAACATHiq2VPJgpuhc4dqy4ktHqwoudQev2tcrrHWDlmrzjU7Jzv26qJXa36/+frqtq9UMKCgq3/ujrkK/TxUX6/+mruiAAAZRggFAAAAZIKP8dH3Xb9X8XzFJTkee+szuY+i46I9WtelHr/7Y+AfqlSkUqrjjDEa3GCwwh4MU/tq7V39ETERGjJriNr80Ea7Tu1ye/0AgLyHEAoAAADIpHKFyumbzv896rb2yFq9uPBFj9VzucfvAnwDLnuOCoUr6Nc+v2pMlzHJFi5fuHuh6n5RV5/89YkSbII7ygcA5FGEUAAAAEAW6FKrix5o+ICr/f6f7+v3nb9nex1X8vjd5Rhj1P+6/tr84GZ1qdnF1X8+9rwenfuoWo1ppW3h27KsdgBA3kYIBQAAAGSR99q+p5CSIa723VPv1rHIY9kyd0Yfv0uPMgXLaOqdUzW+x3jXY4eStGzfMl375bV6b8V7ik+Iz1T9AIC8jxAKAAAAyCL5/fNrfI/xCvQNlCQdjTyqe6bf4/bFvLPi8bvLMcaoV51e2vzQZt0ReoerPyouSk/Pe1rNvm2msGNhmZojKi5KB88e1Poj67Vw90JNCpukuTvmKiouKrPlAwByAMPbLbyHMSYsJCQkJCwsc385AAAAwKV9/NfHGjp3qKv9SYdP9HCjh90y17gN43T/rPuT3f3UuFxj/Xz7z5m6++lypvw7RQ/OflBHI4+6+gJ8A/Ryy5f1TPNndCHugsLPh+vE+RMKvxCu8PPhCr/gbDt/ndifeMz52POpzhVSMkQTekxQ3dJ13fZ9AACXFxoaqs2bN2+21oZmZDwhlBchhAIAAMge1lrd+tOtmrNjjiQp0DdQfw/6O0tDlPOx5/XonEeT3f0kOR6/G37z8Cy5++lyws+H6/HfHtcPG35I1m9kZJW1P2cE+QVpZNuRur/h/TLGZOm5AQDpk9kQyusexzPGXG+MmWiMOWSMiTXGnDbGLDXGDDSp/GlmjPE1xjxujNlojLlgjDnuHF/7MvN0MsYsMcacdX4WG2NuvcyYUGPMJOccF5xzPmaM8br/TgAAALmZMUZjuo5R6eDSkqTo+Gj1ntxbF2IvXPG5EmyCouOiFREdofDz4ToccVh/H/zb7Y/fpUfx/MX1fbfvNav3LJUrWM7Vn9kAKr9/flUsXFHXlL7G1RcVF6UHf31QPSb20MkLJzN1fgCAZ3jVnVDGmB6SfpbkK2mNpB2SSkpqIclP0k/W2ruSHO8j6RdJ3SSdlrRAUglJLSVdkHSjtXZVKvM8JukDSXGS5kuKltRWUj5Jj1hrP01lTFPn+fNJWiVpj3OeqyRNknSnzeR/LO6EAgAAyF5zd8xVhx87uNrXXXWdiucrrpj4GMUmxComPibZJzb+4r54e/kFv7Pj8bvLORN1Rk/9/pRGrx2drL9oUFEVz19cxfMVd21L5C+RrF08f/K+IL8g1/i5O+aq/7T+yRZ4r1Cogn7q8ZNuqHhDtn0/AACP46WbMcZP0kFJpSTdZa39Kcm+2pKWSSom6SZr7SJn/32SRknaLqmFtfaos7+HHOHUDkm1rbVxSc5VU1KYHAHUjdbaP539NSStkFTYOWZHkjH+krZKulrSE9baD5z9BST9LqmppIHW2jGZ/D0ghAIAAMhmT/z2hD5Y+YHbzp+dj9+lx4nzJ3Ti/AkVz1dcRfMVlZ+PX6bPeeTcEfWb2k/zd8139fkYH73a6lW90OIF+fr4ZnoOAMDl8The+tWSI4DamjSAkiRr7b+Sxjmb1yfZ9YRz+0xiAOU8frKkGZKqSeqSYp6hctxp9WViAOUcs03Sm3LccTU0xZhucgRQ6xMDKOeYc5ISV7B8Mn1fEwAAADnJWze/pfpl6mf5easXq57tj9+lR4n8JVSrRC2VDC6ZJQGUJF1V4Cr91vc3vX3z265zJtgEvbz4ZbX5oY0Onj2YJfMAANwra/5UyB2i03lcuCQZY66WVFuOx+5mp3LcL5I6S+okaXKS/luT7E9tzEjnmEfSM8Zau8YYs0tSHWNMZWvtnnR+DwAAAOQAgX6BWnD3Ak35d4qi4qIU4BugAN8A+fv4u37t6vNN3pfymMT9/j7+Xnf3j4/x0bM3PKvWlVur9+Te2n16tyRp8Z7FuubLa/Rdl+/UuWZnD1cJALgUbwqhdknaKammMaZPKo/j9ZV0StJUZ/e1zu0ma21sKudb49y6Vks0xhSRVNHZXJtygLV2vzHmhKRKxphC1tqzKeZak3JMkv4qzrn2pPUFAQAAkDMVCSqie+rd4+ky8oTG5Rtr7ZC1GjJriH4O+1mSdPLCSXWZ0EWPNHpE79zyTrI1pQAAOYfXPI5nrY2X1F+OBcZ/NMasNsZMMMYslLRB0gFJN1trE1+1kRgmHUjjlIn9SVd/TBxzylobmYFxVzJXmowxYal9JFVNz3gAAAAgJyscVFjje4zXN52/UX7//K7+T1Z9oqbfNNXWE1s9WB0AIC1eE0JJkrV2uaRWctwVVV/SnZJulJQgaZ6zP1EB5/Z8GqdLDJkKXsGYjI5LbQwAAADgtYwxuqfePfpn0D+6prTr4QStO7JO9b+ur+/WfidveQkTAOQWXhVCGWN6S1olab+kxnKEPzUkjZFj4e+FxphAjxWYRay1oal95HgcEQAAAMgzapesrb/u+0sPX/+wq+987HndM+Me3TXlLp2NPnuJ0QCA7OQ1IZQxprqksZJOSLrNWrvKWhtprd1urR0iaZYcd0clPqx/zrnNf/HZJEnBzm1Ekr7LjcnouNTGAAAAAJAU5BekTzp+oml3TlOxfMVc/eM3jVe9r+pp1cFVHqwOAJDIa0IoSb0k+Uuaa609l8r+ic5tS+d2n3NbPo3zJfbvTdKXOKaoMSZYqbvUuCuZCwAAAEASXWp10fr716tlpZauvl2ndqn5t8317vJ3lWATPFgdAMCbQqjEIOdMGvsT+4s6t+ud2zrGGP9Ujq/v3G5I7LDWntZ/gVK9lAOMMRUklZC0N8mb8ZLOVT/lmLTmAgAAAHCx8oXKa+HdC/W/1v+Tj3H8uBOXEKdn5j+jjj921NFzRz1cIQB4L28KoY44tw3T2H+9c7tHkqy1uyX9KymfpFtTOf5253Zmiv7ZKfZnaowxpp6kKpI2WWv3pF46AAAAgES+Pr56udXLWtx/scoX+u9hg992/qYGXzfQoYhDHqwOALyXN4VQ053blsaYB5LuMMY0kfS4s/lLkl0jndt3jDGlkhzfXVJnSTuSnDfRR5LiJd3vPG/imOqSXpQU5zwmqamSdku61hjzeJIxwZI+czbfT8d3BAAAAODUolILrb9/vbrW6urqOxhxUH0m91FcQpznCgMAL+U1IZS1do2k95zNz40xm4wxE40xyyQtl2Px76+ttfOTDPtWjoCouqQtxphJxphFcgRVFyT1tdYm+9PLWrtV0tOSAiUtNcb8aoyZJscjd8UlPWGt3ZFiTKykvs5zjjTGrDTG/Cxpu6SmzvnGZtXvBQAAAOAtiuUrpil3TNFbN7/l6luyd4leW/KaB6sCAO/kNSGUJFlrn5bUXdLvkq6S1E1SiKQlkvo435KX9PgEST0lPSnpkKTbJNWVNFlSQ2vtX2nM84Ecd0r9KamFpJsl/SOpk7X2kzTGrJDjkcDJkqo5x5+U9ISkO621NsNfHAAAAPBixhg92/xZ9a7T29X3xh9vaP6u+ZcYBQDIaoZsw3sYY8JCQkJCwsLCPF0KAAAAkO0ioiPU4OsG2n5yuySpVHAprRuyTmUKlvFwZQCQO4SGhmrz5s2brbWhGRnvVXdCAQAAAPBeBQMLamLPiQr0DZQkHYs8pj5T+ig+Id7DlQGAdyCEAgAAAOA1rrvqOn3U/r/3BC3es5j1oQAgmxBCAQAAAPAqgxsMVq86vVzt1/94XQt2LfBgRQDgHQihAAAAAHgVY4y+uu0rVStWTZJkZXXXlLt05NwRD1cGAHkbIRQAAAAAr1MosJAm3v7f+lBHI4+qz2TWhwIAdyKEAgAAAOCV6pWppw/bf+hqL9qzSK//8brnCgKAPI4QCgAAAIDXGtJgiO4MvdPVfm3Ja1q4e6EHKwKAvIsQCgAAAIDXMsbo605fJ1sfqs/kPqwPBQBuQAgFAAAAwKslrg8V4BsgybE+1F1T7mJ9KADIYoRQAAAAALxevTL19GG7D13thbsX6s2lb3quIADIgwihAAAAAEDS/Q3v1x2hd7jary5+lfWhACALEUIBAAAAgBzrQ43qNEpVi1aVxPpQAJDVCKEAAAAAwKlQYCFN7Jl8fai+U/qyPhQAZAFCKAAAAABIon6Z+vqg3Qeu9oLdCzR86XAPVgQAeQMhFAAAAACk8EDDB9QzpKer/eqSV7Vo9yIPVgQAuR8hFAAAAACkkLg+VJWiVSRJCTZBfab00dFzR7NsjtNRpzUpbJLumX6PGn7dUK8uflUXYi9k2fkBIKfx83QBAAAAAJATFQ4qrIm3T1Szb5spJj5GR84dUd+pfTX3rrny9fG94vNZa7X+6HrN2T5Hv+74VX/u/1Px9r+1plYfXq3v13+vTzt+qo7VO2blVwGAHIE7oQAAAAAgDQ3KNtDItiNd7fm75uutZW+le3zSu53KjSynel/V0wsLX9CyfcuSBVCJdp/erVt/ulXdf+6u/Wf2Z8l3AICcwlhrPV0DsokxJiwkJCQkLCzM06UAAAAAuYa1Vnf8cod+2fyLJMnH+GjB3QvUunLrVI+91N1OKZXIX0LtqrZT4cDC+mr1V8mODfYP1qutX9XQxkPl7+uf5d8LAK5UaGioNm/evNlaG5qR8YRQXoQQCgAAAMiYM1FnVP/r+tp1apck6aoCV2ndkHUqXaC0Tked1ryd8zRnxxzN3TFXh88dTvM8RkaNyjVSh2od1KF6BzUs21A+xvGAysajG/XA7Ae0fP/yZGPqlKqjL279QjdUvMF9XxAA0oEQCulGCAUAAABk3OpDq13rQ0lSgzINlM8/X7rudmpfrb06VOugtlXbqkT+Emkem2ATNHbdWD0972mFXwhPtm/AdQP0Tpt3VDK4ZNZ8IQC4QoRQSDdCKAAAACBzPl31qR6Z88glj0l6t1PH6h3VoGwD191O6RV+PlzPL3heo9aMStZfNKio3m7ztu6rf98Vn9PT1hxeoxlbZ6jeVfXUpVYXT5cDIAMIoZBuhFAAAABA5lhr1XNST03+d3Ky/pL5S6pdtXbputvpSqw8sFL3z7pf64+uT9bfuFxjfXHrF6pXpl6WzOMu1lrN3zVf76x4R/N3zXf1T+gxQXfWudODlQHICEIopBshFAAAAJB5Z6PP6vG5j2vvmb1qWamlOlTrkKG7ndIrLiFOn676VC8teknnYs65+n2Mjx5p9Iheu/E1FQos5Ja5MyouIU6TwibpnRXvaN2RdRftLxpUVBsf2Khyhcplf3EAMowQCulGCAUAAADkXgfPHtQTvz+hiWETk/WXKVBGH7T7QHeE3iFjjIeqc4iMidS3a7/VyJUjtef0nov2GxlZOX4GvaXKLZrbd26ue6wQ8GaZDaG42gEAAAAgFyhXqJx+vv1n/db3N1UrVs3Vf/jcYfWa3EvtxrXT9vDtHqnteORxvbLoFVX8sKIenfvoRQFUh2odtKj/In3d6WtX37xd8/T5359nc6UAPIk7obwId0IBAAAAeUNUXJTeWf6Ohi8druj4aFd/gG+Anmv+nJ674Tnl88/n9jp2ndqlkX+O1Ldrv9WFuAvJ9vn5+Kl3nd56qtlTuqb0NZIca0R1/bmrZmydIUkK8gvS2iFrVatELbfXCiDzeBwP6UYIBQAAAOQtO07u0MO/Pqzfdv6WrL9E/hKqd1U91SlVR6ElQ1WnVB2FlAxRwcCCWTLv6kOr9e6KdzVp8yQl2IRk+4L9gzWo/iA93vRxVSxc8aKxxyKPqc7ndXT8/HFJUoMyDfTnvX/K39c/S2oD4D6EUEg3QigAAAAg77HWavK/k/XY3Md0MOLgJY+tXKRysmCqTqk6qlWiloL8gtI1z/xd8zVi+Qgt2L3gov0l85fU0MZD9cD1D6hYvmKXPNeMrTPUZUIXV/ulli/ptRtfu2wNADyLEArpRggFAAAA5F0R0RF6dfGr+njVx4pLiEv3OB/jo2rFqjlCqZJ1XOFUtWLV5O/rf9k33VUrVk1PNX1Kd1979xU9AjhoxiCNXjvaVcPye5arSfkm6R4PIPsRQiHdCKEAAACAvO/E+RNac3iNNh3b5PpsPr5ZkbGRV3Qefx9/1SpRS2ejz2rvmb0X7W9YtqGebf6sutXqJl8f3yuuMyI6Qtd9dZ12ndolyRFmrR2yVgUCClzxuQBkD0IopBshFAAAAOCdEmyC9p7e+18wdXyTwo6F6d8T/yomPuaKztWhWgc90/wZtarUSsaYTNW1fN9ytRzT0rWu1JAGQ/TlbV9m6pwA3IcQCulGCAUAAAAgqbiEOO04ucMVToUdD9OmY5u0PXy74m286zhf46vedXvr6WZPu950l1VeXPCihi8b7mrP7jNbHat3zNI5AGQNQiikGyEUAAAAgPSIiovS1hNbtenYJkXGRqpd1XaqVKSSW+aKiY9Rk9FNtPbIWklS6eDS2vTgJpXIX8It8wHIuMyGUD5ZXRAAAAAAIHcL8gvStVddq7uuuUuDGwx2WwAlSQG+ARrXfZwCfQMlSUcjj2rwzMHihgkg7yGEAgAAAAB4VEjJEI1oM8LVnrplqr5f/70HKwLgDoRQAAAAAACPe6TxI7r56pv/a895RHtO7/FcQQCyHCEUAAAAAMDjfIyPxnQdoyJBRSRJETERunvq3YpPiL/0QAC5BiEUAAAAACBHKF+ovD7v+LmrvXTfUo38c6QHKwKQlQihAAAAAAA5Ru+6vdWrTi9X+8WFL2r9kfUerAhAViGEAgAAAADkKJ91/ExlC5aVJMUmxKrf1H6KiovycFUAMosQCgAAAACQoxTLV0xjuoxxtTce26iXFr7kuYIAZAlCKAAAAABAjnNL1Vv0SKNHXO33/3xfS/Ys8WBFADLLz9MFAAAAAACQmrfbvK15u+Zpy4ktsrK6e9rd2nD/BhUOKpxlc5y6cEpzdszRn/v/VD7/fCqZv6RKBpe8aBvsHyxjTJbNC3gjQigAAAAAQI6U3z+/fuj2g5p+01RxCXHad2afhs4dqjFdx2TqvLtO7dKMrTM0Y+sM/bH3D8Xb+MuOCfILSj2gSiO0KhRYSD6Gh4+ApAihAAAAAAA5VsOyDfVKq1f00iLHmlBj149Vpxqd1COkR7rPkWAT9PfBvzV963TN2DpDYcfDrriOqLgo7T+7X/vP7k/3GB/jI38ff/n5+Mnf11/+Pv7y93W2nb9Oz/4iQUXU95q+al259RXXDeQkxlrr6RqQTYwxYSEhISFhYVf+f7gAAAAA4ClxCXFq8V0LrTywUpJUPF9xbXxgo8oULJPmmPOx57Vg1wLN2DpDM7fN1NHIo2keWyq4lDpU66AA3wAdP39cxyOPu7anok5l+ffJqG61uum9tu+pStEqni4FXio0NFSbN2/ebK0Nzch4QigvQggFAAAAILfacXKHrv3yWp2PPS9J6lCtg2b3mZ1snaaj545q1rZZmrFthubtnKcLcRfSPF9IyRB1rtFZnWt2VqNyjeTr45vqcbHxsQq/EJ4smEq2TdEXfiFcCTYha798EgG+AXqiyRN6ocULKhhY0G3zAKkhhEK6EUIBAAAAyM2+Xv21hswa4mp/3vFztarcyrW+08oDK2WV+s+4vsZXLSq1UOcandWpZidVK1bNLTUm2ASdvHBSkTGRikuIU2xCrGLjY13blH1xCXHJ9qfWN23rNK3YvyLZPFcVuErDbxqu/tf1Z+0pZBtCKKQbIRQAAACA3Mxaq07jO2n29tnpOr5gQEG1r9ZeXWp2UYfqHVQsXzE3V+ge1lpN2DRBz8x/RgfOHki2r0GZBvqw/Ye6oeINHqoO3oQQCulGCAUAAAAgtzty7ojqflFXJ86fSHV/hUIV1Lmm4zG7VpVaKdAvMJsrdJ/zsef1zvJ39M7ydy561PDO0Dv1zi3vqGLhih6qDt6AEArpRggFAAAAIC+YvmW6uk/s7lp7qUGZBq7g6drS1yZbJyov2n9mv56d/6zGbxqfrD/IL0jPNHtGzzR/RsEBwR6qDnkZIRTSjRAKAAAAQF7x14G/tPPUTrWs1FLlC5X3dDkesXzfcg2dO1SrD69O1l+uYDmNaDNCfer2yfOBHLJXZkMoVi8DAAAAAOQ6jcs3Vp+6fbw2gJKk5hWba9WgVfquy3e6qsBVrv6DEQfVd2pfNfu2mVYdXOXBCoHkCKEAAAAAAMilfIyPBlw3QNse3qbnb3heAb4Brn0rD6xU49GN1X9afx2KOOTBKgEHQigAAAAAAHK5goEFNfzm4fr3oX/VvXb3ZPu+X/+9anxSQ2/+8aYuxF5I4wyA+xFCAQAAAACQR1QpWkWT75ishXcv1DWlr3H1R8ZGatiiYar9WW19tuoz/bn/T52NPuvBSuGNWJjci7AwOQAAAAB4j/iEeI1eM1rDFg3TifMnUj2mYuGKqlOqjuqUrKPQUqGqU6qOapeorXz++bK5WuQGvB0P6UYIBQAAAADe53TUab2+5HV9vOpjxSXEXfZ4H+OjqkWrOsKpUnUUWtIRTtUoXkP+vv7ZUDFyKkIopBshFAAAAAB4r23h2/TRyo+05sgahR0LU0RMxBWN9/fxV80SNZPdOdWwbEOvfkOht8lsCOWX1QUBAAAAAICcp0bxGvrs1s8kSdZa7T+7X5uObUr22Xx8s6Ljo1MdH5sQ6zouka/x1Ws3vqYXWryQLd8BuRshFAAAAAAAXsYYo4qFK6pi4YrqWL2jqz8+IV47T+28KJzaFr5N8Tb+ovPE23i9uPBFFQgooEcbP5qdXwG5ECEUAAAAAACQJPn6+KpG8RqqUbyGutfu7uqPjovWtvBt/wVTxzfpz/1/6vj545KkoXOHqni+4rrrmrs8VTpyAR9PF+AJxpiSxpj3jDFbjTEXjDEnjTFrjDHvpnF8J2PMEmPMWednsTHm1svMEWqMmWSMOe6cY6Mx5jFjTJq/58aYosaYj4wxe40x0c7th8aYIpn8ygAAAAAAZFigX6Dqlq6r3nV7682b39T0XtO1dshaVSpcyXXMgOkD9Ov2Xz1YJXI6rwuhjDENJP0r6UlJsZKmS1opqZikx1M5/jFJMyQ1k7Rc0kJJjSTNMsY8nMYcTSX9Lel2Sbuc40tI+kDSBGOMSWVMCUmrJD0qKU7SNEkRkoZK+ssYUyyDXxkAAAAAgCxXrlA5/d7vd5XMX1KSFJcQp9sn3q7l+5Z7uDLkVF4VQhljSkqaKymfpC7W2jrW2l7W2o7W2spyBE1Jj68p6T1J0ZJaWms7WGu7SrpOUrikD4wx1VKM8Zf0o3OOJ6y1ja21d0qqLulPST0l9U+lvA8lVZM0RVJNa+2d1to6kj6RVEPSyMz/DgAAAAAAkHVqFK+hOXfNUcGAgpKkC3EXdNv427Tx6EYPV4acyKtCKEn/k+OOpKettTNS7rTWrkrRNVSSr6QvrbV/Jjlum6Q35VhTa2iKMd0kXS1pvbX2gyRjzklKvHPqyaQDjDFlJPWWFCPpQWttXJLdT0s6LqmvMaZUOr8nAAAAAADZokHZBprea7oCfAMkSaejTqvduHbafWq3hytDTuM1IZQxJp+kvpIiJX2XzmGJ6z79ksq+xL5O6R1jrV0jx+N5dYwxlZPsai/Hf4ul1tqjKcZES5opRxjWUQAAAAAA5DA3Xn2jJvSYIB/nMsiHzx3WLT/coqPnjl5mJLyJ14RQkhpKKihprbX2gjGmgzFmpDHmc+eC4WWTHuxcDLyis7k25cmstfslnZBUyRhTKMmua53bNWnUkdh/TSbHAAAAAACQY3Sr3U1f3/a1q73z1E61/7G9zkSd8WBVyEn8PF1ANgpxbo8ZY6ZJ6pJi/3BjzL3W2vHOdmIAdcpaG5nGOQ/I8XhfJUmJD7xWTLIvrTFyjkmUkTFpMsaEpbGranrGAwAAAACQEffWv1cnzp/QcwuekyStO7JOnSd01ty75iqffz4PVwdP86Y7oYo6t53lePztIUmlJFWWY/HxfJLGGmOucx5XwLk9f4lzJoZTBZP0XW5cVo0BAAAAACDHeab5M3qq6VOu9h97/1Cvyb0UlxB3iVHwBt4UQiV+Vz9JL1trP7fWHrfW7rXWPi1pkiR/ORYCz9WstaGpfSTt9HRtAAAAAIC8zRijd255RwOuG+Dqm7F1hgbNHCRrrecKg8d5Uwh1LsmvU1uYPLGvVYrj81/inMHObUQq86Q1LqvGAAAAAACQIxljNKrTKHWu2dnVN2bdGD0z7xkPVgVP86YQaq9ze95aezyV/Xuc21LO7T7ntqgxJvjiwyVJ5VOcO+m48kpdVo0BAAAAACDH8vPx04QeE9SyUktX33t/vqd3lr/jwargSd4UQiW+4S6fMSYwlf3FnNtzkmStPa3/wqF6KQ82xlSQY1Hyvdbas0l2rXdu66dRR2L/hkyOAQAAAAAgR8vnn08zes3QdVdd5+p7dv6z+mbNN54rCh7jNSGUtXafHGGP0X+P3CWV2Lc2Sd9s5/b2VI5P7JuZoj/NMcaYepKqSNpkrd2TZNdcSQmSWhhjSqUYEyipk6R4Sb+mUgcAAAAAADlW4aDCmnvXXFUrVs3VN3jWYE39d6oHq0qfwxGHNXzpcN015S69vext7T6129Ml5WpeE0I5Jd7z954xpkxip/ONeE86m18mOf4jOcKf+40xTZIcX13Si5LinMckNVXSbknXGmMeTzImWNJnzub7SQdYaw9LGi8pQNLnxhi/FDWXlDTOWnss3d8UAAAAAIAconSB0vq97+8qU8Dxo3iCTVDvyb21aPciD1d2sQSboN93/q4eE3uo4ocV9eLCF/XTxp/0/ILnVeXjKmr6TVN9tPIjHYo45OlScx3jbSvTG2PGSOov6bSkFZLySWomKVDSKGvt4BTHPy5ppByB0zxJMZLaOsc9aq39JJU5mkma7zzmLznWcmohqYykXyTdYVP8xhtjSkhaKamqHG+x+0dSqKQ6krZLamKtPZnJ7x4WEhISEhYWlpnTAAAAAACQIRuPblTLMS11Ouq0JKlgQEEtHrBY9cuktTpN9jl67qi+W/edRq0ZpV2ndl32eCOjVpVbqVdoL/UI6aES+UtkQ5WeFRoaqs2bN2+21oZmZLw3hlBG0n2ShkiqLcnKsdbSV9basWmM6STpaf23NtRaSe9Ya2ddYp5QSf+T1FqOt9vtlPSNpI+stQlpjCkm6VVJXSWVlnRUjjurXnGuUZUphFAAAAAAAE9bvm+5bvnhFl2IuyBJKpm/pJbds0w1itfI9loSbIIW7V6kr1Z/pWlbpik2IfaiYyoUqqDbatymRXsWacuJLamex9f46paqt6h3nd7qUrOLCgcVdnfpHkEIhXQjhAIAAAAA5AS/bv9VXSZ0UVxCnCSpUuFKWn7PcpUrVC5b5j8eeVxj1o3R12u+1o6TOy7a72N8dGv1WzWkwRC1r9Zevj6+stZqw9ENmrBpgiaETdCe03tSPXegb6A6Vu+oXnV66bYatym/f343f5vsQwiFdCOEAgAAAADkFD9u+FF9p/Z1tUNKhmjpwKUqlq/YJUZlnLVWS/Yu0Verv9KUf6coJj7momPKFSyn++rfp3vr3asKhStc8lyrDq7ShE0T9HPYzzp87nCqxwX7B6tzzc7qVaeX2lVtp0C/wCz7Pp5ACIV0I4QCAAAAAOQkH//1sYbOHepqB/kFqXyh8v99CpZP3i5UXiWDS8rHpP89a+HnwzV2/Vh9vfprbQ3fetF+I6P21drr/ob3q2P1jvLz8UvlLGmLT4jX0n1LNWHTBP2y+ReFXwhP9bgiQUXUvVZ39arTSzdefeMVz5MTEEIh3QihAAAAAAA5zUsLX9IbS99I9/H+Pv4qV6jcRUFVhcIVXH2lg0trxf4V+mr1V/pl8y+Kjo++6DxXFbhK99a7V/fVv0+Vi1TOku8SGx+rBbsXaPym8Zr671RFxESkelzJ/CU1tPFQvdjyxSyZN7tkNoTKfbEbAAAAAADIM1678TUl2AS9u+LdVBcGTyk2IVZ7Tu9Jc00myXF3k1XqN920rdpWQxoMUacaneTv65/RslPl7+uv9tXaq3219vrqtq80Z/scTQiboJlbZ7oWYpek4+ePJ2t7C+6E8iLcCQUAAAAAyKnORJ3R3jN7deDsgVQ/+8/u17mYcxk6d6ngUrrnuns0qMEgVSlaJYsrv7xzMec0c+tMTQiboDnb5yg2IVYbH9ioOqXqZHstmcGdUAAAAAAAINcrHFRY1wRdo2tKX5PmMWejz6YZUiV+TkWdch1/89U3a0iDIepSq4sCfAOy42ukqkBAAfWu21u96/bWqQunNG/XvFwXQGUFQigAAAAAAJArFAospJCSIQopGZLmMZExkToYcVCFAgvpqgJXZWN16VM0X1HdEXqHp8vwCEIoAAAAAACQZwQHBKtG8RqeLgOpSP87DQEAAAAAAIAMIoQCAAAAAACA2xFCAQAAAAAAwO0IoQAAAAAAAOB2hFAAAAAAAABwO0IoAAAAAAAAuB0hFAAAAAAAANyOEAoAAAAAAABuRwgFAAAAAAAAtyOEAgAAAAAAgNsRQgEAAAAAAMDtjLXW0zUgmxhjzgYGBhasWrWqp0sBAAAAAAC5zM6dOxUdHR1hrS2UkfGEUF7EGHNEUn5J+7NpysS0a2c2zQfkRFwHgAPXAsB1AEhcB4CUu6+DCpLOW2uvyshgQii4jTEmTJKstaGergXwFK4DwIFrAeA6ACSuA0Dy7uuANaEAAAAAAADgdoRQAAAAAAAAcDtCKAAAAAAAALgdIRQAAAAAAADcjhAKAAAAAAAAbsfb8QAAAAAAAOB23AkFAAAAAAAAtyOEAgAAAAAAgNsRQgEAAAAAAMDtCKEAAAAAAADgdoRQAAAAAAAAcDtCKAAAAAAAALgdIRQAAAAAAADcjhAKWc4Yk88Y85oxZpsxJsoYc8gY860xppynawOyijGmgTHmOWPMFGPMAWOMNcbYdIwbYIxZZYw5Z4w5aYz51RjTLDtqBrKaMSa/MaarMeYbY8xW5//nRxpj1htjXjbGFLjEWK4F5BnGmCecfx5sN8acMcZEG2P2GmO+N8bUvcQ4rgPkWcaY4saYY86/I+24zLFcC8gTjDGLE38uSOPTPo1xXnMNGGsv+zMTkG7GmCBJiyQ1kXRY0lJJlSU1knRcUhNr7S6PFQhkEWPMNEldUvZba80lxnwoaaikC5J+lxQk6WZJRtLt1tppbigVcBtjzH2SRjmb/0raJKmQpGaSCkraIqmVtfZYinEfimsBeYgx5oSkYEkbJB10dodKqiEpVlJ3a+2sFGM+FNcB8jBjzBhJd8vxv+md1tpqaRz3obgWkEcYYxZLaiVpsqRzqRzyvrV2Y4oxH8qLrgFCKGQpY8wbkl6U9Kekttbac87+JyS9L2mJtba15yoEsoYx5lk5fuD42/nZIykwrRDKGNNG0jxJ4ZKaWmu3O/ubSlos6bykq621p91dO5BVjDH95QicPrTW/pukv4yk2ZLqSRpvre2TZB/XAvIcY0xzSauttVEp+h+U9Jmko5LKW2vjnP1cB8jTjDE3S5ov6WtJg5VGCMW1gLwmSQh1tbV2TzqO97prgMfxkGWMMQGSHnY2H0oMoCTJWjtSjn8dbGWMaeCJ+oCsZK0dYa192Vo701p7JB1DnnBu30j8w8V5nj8lfSmpiKR7s75SwH2stWOttUOSBlDO/sOSHnI2uzv/fEjEtYA8x1q7PGUA5ez/XNJOSaUlhSTZxXWAPMsYk0/SV5I2S3rvModzLcDbed01QAiFrNRcUmE5/qVjbSr7f3FuO2VfSYDnOf8ydpOz+Usqh3BtIC9a79wGSioucS3Aa8U6tzES1wG8wiuSqki6X//97/8iXAvwdt56Dfh5ugDkKdc6t2vS2J/Yf0021ALkJDXl+EH8uLX2QCr7uTaQF1VxbmMlnXT+mmsBXsUY00+O/91vd34krgPkYcaYayQ9Kek7a+1SY0zlSxzOtYC87F5jTHFJCZK2SZpmrd2X4hivvAYIoZCVKjq3qV1ASfsrZUMtQE5yyWvDWhtpjDktqagxpqC1NiLbKgPcZ6hzO9daG+38NdcC8jRjzNNyLEgeLKm289eHJPW21sY7D+M6QJ5kjPGRNFrSaUnPpGMI1wLysmEp2u8ZY1631r6epM8rrwEex0NWSnwV9/k09kc6twWzoRYgJ7nctSFxfSAPMcZ0lGP9glhJLyXZxbWAvK6dpP6SbpcjgNorRwC1OskxXAfIqx6RdL2kp6214ek4nmsBedEfkvpJqiopvxx3O70oKU7Sa8aYoUmO9cprgBAKAABkGWNMLUnj5Hit8NPW2vWXGQLkGdbaNs63pBaV1FKOR/CWGGNe9GxlgHsZYypKekOON2GP8XA5gMc4X1w0zlq7y1p7wVq7zVo7XFJX5yGvOteC8lqEUMhKiW/Dy5/G/mDnNk/cRghcgctdGxLXB/IAY0w5SXPl+AF8pLX2oxSHcC3AK1hrT1trl0rqKGm1pNeNMdc7d3MdIC/6TFKAHIuRpxfXAryGtfZ3Sf/I8ba7xs5ur7wGWBMKWSlxobXyaexP7N+bDbUAOcklrw1jTLAcfyCdyivPesP7GGOKSfpdjnX/vpP0VCqHcS3Aq1hrY40xP0tqIMfbjf4W1wHyptvkWAvqS2NM0v4g57acMWax89e9rLVHxLUA77NdUkNJZZxtr7wGCKGQlRIfuaifxv7E/g3ZUAuQk2yVFC2ppDGmnLX2YIr9XBvI1YwxBSTNkRQiaYqkQdZam8qhXAvwRiec25LOLdcB8qoiklqlsS8oyb7EYIprAd6mqHObuM6TV14DPI6HrLRc0hlJVY0x16Wy/3bndma2VQTkANbaC5IWOps9UzmEawO5ljEmUNJ0SY0k/abkbwFLhmsBXirxB++dEtcB8iZrrUntI+lq5yE7k/TvcY7hWoDXMMaUlNTC2Vwjee81YFL/h0ogY4wxb8ix+v8KSW2ttZHO/ickvS/HYoWtPVch4B7GmChJgc6/cKW2v42keZLCJTW11m539jeVtEjSBUlXW2tPZ0/FQOYZY3wlTZLUTdJSSe2ttZd6wwvXAvIcY0xzOd5a9Lu1NiFJv78c6+N8KMe/dNe01u537uM6gFcwxlSWtFuOEKpaKvu5FpBnGGOaSSolaWbSf5BzXgfjJDWXNMNa2yXJPq+7BgihkKWMMUGSFsux2NphOX4oqeRsH5fUxFq7y2MFAlnEGHOrkr96vpEcbwP7K0nf69ba2UnGfChpqByvYZ0nxwKetzjH3W6tnebeqoGs5XzN8IfO5lRJZ9M49ClrbeIjSVwLyFOMMQPkWAfthByLkIdLKiGprhzrfkRJ6m+tnZhi3IfiOkAed7kQynnMh+JaQB6Q5M+DI3Lc7XRajp+FG8jxGGqYpJustcdSjPtQXnQNEEIhyzlfOfm8pD6SKkg6Kcfbkl6y1h7wZG1AVknyh8ylDEz5mmLnuIcl1ZYUI2mlHGHViqyvEnAvY8yrkl5Jx6FXJz5+kWTsAHEtIA8wxlwt6T45HrurIkcAFSNpjxyPWXxsrd2RxtgB4jpAHpaeEMp53ABxLSCXM8bUlvSIHDdgVJBjDahISf/Kcef4F85H8FIbO0Becg0QQgEAAAAAAMDtWJgcAAAAAAAAbkcIBQAAAAAAALcjhAIAAAAAAIDbEUIBAAAAAADA7QihAAAAAAAA4HaEUAAAAAAAAHA7QigAAAAAAAC4HSEUAAAAAAAA3I4QCgAAAAAAAG5HCAUAAAAAAAC3I4QCAAAAAACA2xFCAQAAAAAAwO0IoQAAAPIYY4w1xuzxdB0AAABJEUIBAAB4AWNMa2c4NcbTtQAAAO/k5+kCAAAAkOVqS4r1dBEAAABJEUIBAADkMdbaLZ6uAQAAICUexwMAAMhjUq4J5XwEb5Gz2d+5P/HzaoqxFYwxnxpjdhpjoowxJ40xs4wxzVKZx/WInzHmKmPMaGPMAWNMnDHmMfd9QwAAkBtxJxQAAEDet0zSVZLaSdrpbCdal/gLY0xTSbMlFZW01fnrks5x7Y0xd1lrf07l/CUl/S3H3y2XSQqSdD7LvwUAAMjVjLXW0zUAAAAgCxljrKS91trKSfpay3E31Fhr7YBUxhSStEVSKUn9rbU/JtnXUNLvkvwlVbHWHk9xTkmaKqmPtTYqq78PAADIG3gcDwAAAJJ0j6Qykj5MGkBJkrX2H0mvSyogqW8qY6MlPUIABQAALoUQCgAAAJLU1rmdksb+pc5to1T2rbHWHsz6kgAAQF7CmlAAAACQpMrO7XJjzKWOK5FK374srwYAAOQ5hFAAAACQ/rtD/hdJkZc4bksqfTyGBwAALosQCgAAAJJ0QFJNSW9ba1d7uhgAAJD3sCYUAACAd4hxbtP6R8h5zm23bKgFAAB4IUIoAAAA73DIua2Zxv6vJB2T9IwxZrAxJtnfE40xfsaYdsaYOu4sEgAA5F08jgcAAOAFrLV7jDEbJDU0xqySFCYpXtIMa+0Ma+1pY0wXSTPlCKSGGWM2STol6SpJ9SUVkeNOqU2e+A4AACB3I4QCAADwHj0kvSuphaQGctwVf0DSDEmy1q40xtSV9LikWyW1co47LGmJpKmS5mdzzQAAII8w1lpP1wAAAAAAAIA8jjWhAAAAAAAA4HaEUAAAAAAAAHA7QigAAAAAAAC4HSEUAAAAAAAA3I4QCgAAAAAAAG5HCAUAAAAAAAC3I4QCAAAAAACA2xFCAQAAAAAAwO0IoQAAAAAAAOB2hFAAAAAAAABwO0IoAAAAAAAAuB0hFAAAAAAAANyOEAoAAAAAAABuRwgFAAAAAAAAtyOEAgAAAAAAgNsRQgEAAAAAAMDtCKEAAAAAAADgdv8H/Hf0SM0XIOIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1350x450 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = Logic_Model_Generator()\n",
    "num_sample = 48\n",
    "data = gen.generate_data(num_sample=num_sample, time_horizon=3)\n",
    "#print(data)\n",
    "action_history = {}\n",
    "for i in range(num_sample):\n",
    "    action_history_ = dict([(key, data[i][key]) for key in [3,4,5,6]])\n",
    "    action_history[i] = action_history_\n",
    "#print(data)\n",
    "learn = Logic_Model_Incomplete_Data(time_horizon=1,action_history=action_history,hidden_size=(15,10),output_size=(10,4),batch_size=16)\n",
    "num_iter = 50\n",
    "losses = learn.train_model(temperature=0.8,num_iter=num_iter,lr=(0.01,0.002))\n",
    "\n",
    "X = np.arange(1,num_iter+1,1)\n",
    "plt.figure(figsize=(9,3),dpi=150)\n",
    "plt.plot(X, losses, c='green',label='-$\\mathcal{L}$')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('-$\\mathcal{L}$')\n",
    "plt.legend(bbox_to_anchor=(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "271aaf9a14ca8aef692edd0e58d89184235237d981934b751bc9762a3149e378"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
