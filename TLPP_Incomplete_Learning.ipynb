{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import gamma\n",
    "from TLPP_Generation import Logic_Model_Generator\n",
    "from tqdm import *\n",
    "import itertools\n",
    "\n",
    "class LSTM_Encoding_Action(nn.Module):\n",
    "\n",
    "    '''\n",
    "    input: [batch_size, num_predicate, seq_length]\n",
    "    Parameters:\n",
    "        input_size:\n",
    "        hidden_size:\n",
    "        output_size:\n",
    "        num_layers:\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, device, num_layers:int = 1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_directions = 1 # one-directional LSTM\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x:torch.tensor):\n",
    "        batch_size, num_predicate, seq_length = x.shape\n",
    "        h_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        c_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        x, _  = self.lstm(x, (h_0, c_0)) #NOTE: x:(batch_size, seq_length, num_directions * hidden_size)\n",
    "        x = self.linear(x)\n",
    "        x = x.view(batch_size, num_predicate, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTM_Encoding_History(nn.Module):\n",
    "\n",
    "    '''\n",
    "    NOTE:Returns a categorical distribution\n",
    "\n",
    "    Parameters:\n",
    "        input_size:\n",
    "        hidden_size:\n",
    "        output_size:\n",
    "        num_layers\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, device, num_layers: int = 3) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_directions = 1 # one-directional LSTM\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x:torch.tensor, action_embedding: torch.tensor):\n",
    "        '''\n",
    "        Parameters:\n",
    "            x: mental history\n",
    "            action_embedding: encoding of action history. This should be the output of LSTM_Encoding_Action\n",
    "        '''\n",
    "        batch_size, num_predicate, seq_length = x.shape\n",
    "        h_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        c_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        x, _ = self.lstm(x,(h_0,c_0))                              #NOTE: x:(batch_size, seq_length, num_directions * hidden_size)\n",
    "        x = torch.concat(tensors=[x, action_embedding], dim=1)     #NOTE: concatenate the action info and the mental info\n",
    "        batch_size, num_predicate, hidden_size = x.shape           #NOTE: num_predicate is changed\n",
    "        x = self.linear(x)                                         #NOTE: x:(batch_size, seq_length, num_directions * output_size)\n",
    "        x = x.view(batch_size, num_predicate, -1)\n",
    "        #TODO: return a vector with dimension (I+1), (I represents the number of types of mental states)\n",
    "        #TODO: the i-th (i=0,1,2,...,I) component of the output x represents the probability of the i-th mental type\n",
    "        x = self.softmax(x)\n",
    "        return x.view(batch_size,-1,self.output_size).mean(axis=1)\n",
    "        \n",
    "\n",
    "class Logic_Model_Incomplete_Data:\n",
    "\n",
    "    def __init__(self, time_horizon:float, action_history:dict, hidden_size:tuple, output_size:tuple, batch_size:int, partition_size:float=0.1, device:str='cuda') -> None:\n",
    "        self.time_horizon = time_horizon\n",
    "        self.partition_size = partition_size            # num of small time intervals\n",
    "        self.action_history = action_history\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        #TODO:\n",
    "        ### the following parameters are used to manually define the logic rules\n",
    "        self.num_predicate = 7                  # num_predicate is same as num_node\n",
    "        self.num_formula = 8                    # num of prespecified logic rules\n",
    "        self.BEFORE = 'BEFORE'\n",
    "        self.EQUAL = 'EQUAL'\n",
    "        self.AFTER = 'AFTER'\n",
    "        self.Time_tolerance = 0.3               \n",
    "        self.body_predicate_set = []                        # the index set of all body predicates\n",
    "        self.mental_predicate_set = [0, 1, 2]\n",
    "        self.action_predicate_set = [3, 4, 5, 6]\n",
    "        self.head_predicate_set = [0, 1, 2, 3, 4, 5, 6]     # the index set of all head predicates\n",
    "        self.decay_rate = 1                                 # decay kernel\n",
    "        self.integral_resolution = 0.03\n",
    "\n",
    "        #TODO: convert the action_history:dict to a numpy array 'processed_data':np.array to put in the LSTMs\n",
    "        self.processed_data = self.process_data(action_history=self.action_history).to(device)\n",
    "        self.INPUT_SIZE_A = self.processed_data.shape[-1]\n",
    "        #self.INPUT_SIZE_M = int(self.time_horizon / self.partition_size)\n",
    "\n",
    "        #TODO: construct two LSTMs to encode the past history\n",
    "        #NOTE: encoding action history\n",
    "        self.LSTM_Action = LSTM_Encoding_Action(input_size=self.INPUT_SIZE_A,hidden_size=hidden_size[0],output_size=output_size[0],batch_size=batch_size,device=device)\n",
    "        self.LSTM_Action.to(device)\n",
    "        #NOTE: encoding whole history\n",
    "        self.LSTM_History = LSTM_Encoding_History(input_size=len(self.mental_predicate_set),hidden_size=hidden_size[1],output_size=output_size[1],batch_size=batch_size ,device=device)\n",
    "        self.LSTM_History.to(device)\n",
    "\n",
    "\n",
    "        ### the following parameters are used to generate synthetic data\n",
    "        ### for the learning part, the following is used to claim variables\n",
    "        ### self.model_parameter = {0:{},1:{},...,6:{}}\n",
    "        self.model_parameter = {}\n",
    "\n",
    "\n",
    "        '''\n",
    "        mental\n",
    "        '''\n",
    "\n",
    "        head_predicate_idx = 0\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.3).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.01).double(), requires_grad=True)\n",
    "        formula_idx = 1\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.01).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 1\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.3).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.02).double(), requires_grad=True)\n",
    "        formula_idx = 1\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.01).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 2\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.2).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.1).double(), requires_grad=True)\n",
    "\n",
    "\n",
    "        '''\n",
    "        action\n",
    "        '''\n",
    "        head_predicate_idx = 3\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.1).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.01).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 4\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.25).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.05).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 5\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.6).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.8).double(), requires_grad=True)\n",
    "\n",
    "        head_predicate_idx = 6\n",
    "        self.model_parameter[head_predicate_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx]['base'] = torch.autograd.Variable((torch.ones(1) * -0.1).double(), requires_grad=True)\n",
    "\n",
    "        formula_idx = 0\n",
    "        self.model_parameter[head_predicate_idx][formula_idx] = {}\n",
    "        self.model_parameter[head_predicate_idx][formula_idx]['weight'] = torch.autograd.Variable((torch.ones(1) * 0.05).double(), requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #NOTE: set the content of logic rules\n",
    "        self.logic_template = self.logic_rule()\n",
    "    \n",
    "    def logic_rule(self):\n",
    "        #TODO: the logic rules encode the prior knowledge\n",
    "        # encode rule information\n",
    "        '''\n",
    "        This function encodes the content of logic rules\n",
    "        logic_template = {0:{},1:{},...,6:{}}\n",
    "        '''\n",
    "        logic_template = {}\n",
    "\n",
    "\n",
    "        '''\n",
    "        Mental (0-2)\n",
    "        '''\n",
    "\n",
    "        head_predicate_idx = 0\n",
    "        logic_template[head_predicate_idx] = {} # here 0 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (2 and 3 and 4) and before(2,0) and before(3,0) and before(4,0) \\to 0\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [2,3,4]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, 1, 1]  # use 1 to indicate True; use -1 to indicate False\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[2, 0], [3, 0], [4, 0]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE, self.BEFORE, self.BEFORE]\n",
    "\n",
    "\n",
    "        #NOTE: rule content: ((\\neg 0 and (2 and 6)) and after(6,0) and equal(2,0) \\to \\neg 0)\n",
    "        formula_idx = 1\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [0, 2, 6]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [-1, 1, 1]  # use 1 to indicate True; use -1 to indicate False\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [-1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[6, 0], [2, 0]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.AFTER, self.EQUAL]\n",
    "\n",
    "        head_predicate_idx = 1\n",
    "        logic_template[head_predicate_idx] = {}  # here 1 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: 5 and before(5,1) to 1\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [5]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[5, 1]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE]\n",
    "\n",
    "        #NOTE: rule content: (4 and 6) and before(6,1) to \\neg 1\n",
    "        formula_idx = 1\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [4, 6]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [-1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[6, 1]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE]\n",
    "\n",
    "\n",
    "        head_predicate_idx = 2\n",
    "        logic_template[head_predicate_idx] = {}  # here 2 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (\\neg 1 and 6) and after(1,2) to 2\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [1, 6]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [-1, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[1, 2]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.AFTER]\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Action (3-6)\n",
    "        '''\n",
    "        head_predicate_idx = 3\n",
    "        logic_template[head_predicate_idx] = {}  # here 3 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (0 and \\neg 1) and before(0,1) and before(1,3) \\to 3\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [0, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, -1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[0, 1], [1, 3]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE, self.BEFORE]\n",
    "\n",
    "\n",
    "        head_predicate_idx = 4\n",
    "        logic_template[head_predicate_idx] = {}  # here 4 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (2) and before(2,4) \\to 4\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [2]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[2, 4]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE]\n",
    "\n",
    "        \n",
    "        head_predicate_idx = 5\n",
    "        logic_template[head_predicate_idx] = {}  # here 5 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (0 and \\neg 1) and before(0,5) and after(1,5) \\to 5\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [0, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, -1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[0, 5], [1, 5]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE, self.AFTER]\n",
    "\n",
    "\n",
    "        head_predicate_idx = 6\n",
    "        logic_template[head_predicate_idx] = {}  # here 6 is the index of the head predicate; we could have multiple head predicates\n",
    "\n",
    "        #NOTE: rule content: (1 and 2) and before(1,6) and before(2,6) \\to \\neg 6\n",
    "        formula_idx = 0\n",
    "        logic_template[head_predicate_idx][formula_idx] = {}\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_idx'] = [1, 2]\n",
    "        logic_template[head_predicate_idx][formula_idx]['body_predicate_sign'] = [1, 1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['head_predicate_sign'] = [-1]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_idx'] = [[1, 6], [2, 6]]\n",
    "        logic_template[head_predicate_idx][formula_idx]['temporal_relation_type'] = [self.BEFORE, self.BEFORE]\n",
    "\n",
    "\n",
    "        return logic_template\n",
    "\n",
    "    def intensity(self, cur_time, head_predicate_idx, history)->torch.tensor:\n",
    "        feature_formula = []\n",
    "        weight_formula = []\n",
    "        effect_formula = []\n",
    "        #TODO: Check if the head_prediate is a mental predicate\n",
    "        if head_predicate_idx in self.mental_predicate_set: flag = 0\n",
    "        else: flag = 1  #NOTE: action\n",
    "\n",
    "        for formula_idx in list(self.logic_template[head_predicate_idx].keys()):\n",
    "            weight_formula.append(self.model_parameter[head_predicate_idx][formula_idx]['weight'])\n",
    "\n",
    "            feature_formula.append(self.get_feature(cur_time=cur_time, head_predicate_idx=head_predicate_idx,\n",
    "                                                    history=history, template=self.logic_template[head_predicate_idx][formula_idx], flag=flag))\n",
    "            effect_formula.append(self.get_formula_effect(cur_time=cur_time, head_predicate_idx=head_predicate_idx,\n",
    "                                                       history=history, template=self.logic_template[head_predicate_idx][formula_idx]))\n",
    "        intensity = torch.exp(torch.cat(weight_formula, dim=0))/torch.sum(torch.exp(torch.cat(weight_formula, dim=0)), dim=0) * torch.cat(feature_formula, dim=0) * torch.cat(effect_formula, dim=0)\n",
    "        intensity = self.model_parameter[head_predicate_idx]['base'] + torch.sum(intensity)\n",
    "        intensity = torch.exp(intensity)\n",
    "\n",
    "        return intensity\n",
    "\n",
    "    def get_feature(self, cur_time, head_predicate_idx, history, template, flag:int):\n",
    "        #NOTE: flag: 0 or 1, denotes the head_predicate_idx is a mental or an action\n",
    "        #NOTE: 0 for mental and 1 for action\n",
    "        #NOTE: since for mental, we need to go through all the history information\n",
    "        #NOTE: while for action, we only care about the current time information\n",
    "        \n",
    "        transition_time_dic = {}\n",
    "        feature = torch.tensor([0], dtype=torch.float64)\n",
    "        for idx, body_predicate_idx in enumerate(template['body_predicate_idx']):\n",
    "            transition_time = np.array(history[body_predicate_idx]['time'])\n",
    "            transition_state = np.array(history[body_predicate_idx]['state'])\n",
    "            mask = (transition_time <= cur_time) * (transition_state == template['body_predicate_sign'][idx])\n",
    "            transition_time_dic[body_predicate_idx] = transition_time[mask]\n",
    "        transition_time_dic[head_predicate_idx] = [cur_time]\n",
    "        ### get weights\n",
    "        # compute features whenever any item of the transition_item_dic is nonempty\n",
    "        history_transition_len = [len(i) for i in transition_time_dic.values()]\n",
    "        if min(history_transition_len) > 0:\n",
    "            # need to compute feature using logic rules\n",
    "            time_combination = np.array(list(itertools.product(*transition_time_dic.values())))\n",
    "            time_combination_dic = {}\n",
    "            for i, idx in enumerate(list(transition_time_dic.keys())):\n",
    "                #TODO: this is where we distinguish mental and action\n",
    "                time_combination_dic[idx] = time_combination[:, i] if flag == 0 else time_combination[-1, i]\n",
    "            temporal_kernel = np.ones(len(time_combination))\n",
    "            for idx, temporal_relation_idx in enumerate(template['temporal_relation_idx']):       \n",
    "                #TODO: checkpoint\n",
    "                #print('head_predicate_idx: {}; temporal_relation_idx[0]: {}, temporal_relation_idx[1]: {}'.format(head_predicate_idx, temporal_relation_idx[0], temporal_relation_idx[1]))\n",
    "                #print('temporal combination dict: {}'.format(time_combination_dic))\n",
    "         \n",
    "                time_difference = time_combination_dic[temporal_relation_idx[0]] - time_combination_dic[temporal_relation_idx[1]]\n",
    "                if template['temporal_relation_type'][idx] == 'BEFORE':\n",
    "                    temporal_kernel *= (time_difference < - self.Time_tolerance) * np.exp(-self.decay_rate *(cur_time - time_combination_dic[temporal_relation_idx[0]]))\n",
    "                if template['temporal_relation_type'][idx] == 'EQUAL':\n",
    "                    temporal_kernel *= (abs(time_difference) <= self.Time_tolerance) * np.exp(-self.decay_rate*(cur_time - time_combination_dic[temporal_relation_idx[0]]))\n",
    "                if template['temporal_relation_type'][idx] == 'AFTER':\n",
    "                    temporal_kernel *= (time_difference > self.Time_tolerance) * np.exp(-self.decay_rate*(cur_time - time_combination_dic[temporal_relation_idx[1]]))\n",
    "            feature = torch.tensor([np.sum(temporal_kernel)], dtype=torch.float64)\n",
    "        return feature\n",
    "\n",
    "    def get_formula_effect(self, cur_time, head_predicate_idx, history, template):\n",
    "        ## Note this part is very important!! For generator, this should be np.sum(cur_time > head_transition_time) - 1\n",
    "        ## Since at the transition times, choose the intensity function right before the transition time\n",
    "        head_transition_time = np.array(history[head_predicate_idx]['time'])\n",
    "        head_transition_state = np.array(history[head_predicate_idx]['state'])\n",
    "        if len(head_transition_time) == 0:\n",
    "            cur_state = 0\n",
    "            counter_state = 1 - cur_state\n",
    "        else:\n",
    "            idx = np.sum(cur_time > head_transition_time) - 1\n",
    "            cur_state = head_transition_state[idx]\n",
    "            counter_state = 1 - cur_state\n",
    "        if counter_state == template['head_predicate_sign']:\n",
    "            formula_effect = torch.tensor([1], dtype=torch.float64)\n",
    "        else:\n",
    "            formula_effect = torch.tensor([-1], dtype=torch.float64)\n",
    "        return formula_effect\n",
    "\n",
    "    def log_likelihood(self, dataset, sample_ID_batch, T_max)->torch.tensor:\n",
    "        '''\n",
    "        This function calculates the log-likehood given the dataset\n",
    "        log-likelihood = \\sum log(intensity(transition_time)) + int_0^T intensity dt\n",
    "\n",
    "        Parameters:\n",
    "            dataset: \n",
    "            sample_ID_batch: list\n",
    "            T_max:\n",
    "        '''\n",
    "        log_likelihood = torch.tensor([0], dtype=torch.float64)\n",
    "        # iterate over samples\n",
    "        for sample_ID in sample_ID_batch:\n",
    "            # iterate over head predicates; each predicate corresponds to one intensity\n",
    "            data_sample = dataset[sample_ID]\n",
    "            for head_predicate_idx in self.head_predicate_set:\n",
    "                #NOTE: compute the summation of log intensities at the transition times\n",
    "                intensity_log_sum = self.intensity_log_sum(head_predicate_idx, data_sample)\n",
    "                #NOTE: compute the integration of intensity function over the time horizon\n",
    "                intensity_integral = self.intensity_integral(head_predicate_idx, data_sample, T_max)\n",
    "                log_likelihood += (intensity_log_sum - intensity_integral)\n",
    "        return log_likelihood\n",
    "\n",
    "    def intensity_log_sum(self, head_predicate_idx, data_sample):\n",
    "        intensity_transition = []\n",
    "        for t in data_sample[head_predicate_idx]['time'][1:]:\n",
    "            #NOTE: compute the intensity at transition times\n",
    "            cur_intensity:torch.tensor = self.intensity(t, head_predicate_idx, data_sample)\n",
    "            intensity_transition.append(cur_intensity)\n",
    "        if len(intensity_transition) == 0: # only survival term, no event happens\n",
    "            log_sum = torch.tensor([0], dtype=torch.float64)\n",
    "        else:\n",
    "            log_sum = torch.sum(torch.log(torch.cat(intensity_transition, dim=0)))\n",
    "        return log_sum\n",
    "\n",
    "    def intensity_integral(self, head_predicate_idx, data_sample, T_max):\n",
    "        start_time = 0\n",
    "        end_time = T_max\n",
    "        intensity_grid = []\n",
    "        for t in np.arange(start_time, end_time, self.integral_resolution):\n",
    "            #NOTE: evaluate the intensity values at the chosen time points\n",
    "            cur_intensity:torch.Tensor = self.intensity(t, head_predicate_idx, data_sample)\n",
    "            intensity_grid.append(cur_intensity)\n",
    "        #NOTE: approximately calculate the integral\n",
    "        integral = torch.sum(torch.cat(intensity_grid, dim=0) * self.integral_resolution)\n",
    "        return integral\n",
    "\n",
    "    def process_data(self, action_history:dict)->torch.tensor:\n",
    "        '''\n",
    "        Parameters:\n",
    "            action_history: dict\n",
    "        '''\n",
    "        #TODO: convert the action sequences into a numpy array\n",
    "        #NOTE: action_history = {\n",
    "        #                       3: {...}\n",
    "        #                       4: {...}\n",
    "        #                       5: {...}\n",
    "        #                       6: {...}\n",
    "        #                       }\n",
    "        # \"...\" stands for transition times for predicate 3,4,5,6. Recall that 3,4,5,6 are all action predicates\n",
    "        result = []\n",
    "        max_action_transition_time_length = 0       #NOTE: record the length of the transition time\n",
    "        for sample_id in action_history:            #NOTE: batch\n",
    "            for action_predicate_idx in self.action_predicate_set:\n",
    "                #print(sample_id, action_predicate_idx)\n",
    "                time = action_history[sample_id][action_predicate_idx]['time'][1:]\n",
    "                tmp = len(time)\n",
    "                if tmp > max_action_transition_time_length: max_action_transition_time_length = tmp\n",
    "                result.append(time)\n",
    "        #print(result)\n",
    "        #NOTE: shape (batch_size:len(action_history), num_predicate:len(self.action_predicate_set), seq_length:max_action_transition_time_length)\n",
    "        data = np.zeros(shape=(len(action_history),len(self.action_predicate_set),max_action_transition_time_length))\n",
    "        #TODO: store the action history in a tensor\n",
    "        for batch in range(data.shape[0]):\n",
    "            for row in range(data.shape[1]): \n",
    "                data[batch, row, :len(result[(batch+1)*row])] = result[(batch+1)*row]\n",
    "        return torch.tensor(data).float()\n",
    "\n",
    "    def ELBO(self, sample_ID_batch:list, temperature:float=1.0, device='cuda')->torch.tensor:\n",
    "        #TODO: compute the ELBO. \n",
    "        #TODO: Maximize the ELBO is equivalent to minimize the KL divergence between the variational posterior and the true posterior\n",
    "        #NOTE: in order to compute the ELBO, we need to 1. be able to sample from the variational posterior; 2. compute the entropy of q\n",
    "        \n",
    "        '''\n",
    "        compute the ELBO (MC estimate)\n",
    "\n",
    "        Parameters:\n",
    "            sample_ID_batch: the collection of batch indices\n",
    "            action_history: action information\n",
    "            temperature: \n",
    "        '''\n",
    "        #NOTE: we add a small time shift 1e-4 so that we can include the end time point in 'time_intervals'\n",
    "        time_intervals = np.arange(0,self.time_horizon+1e-4,step=self.partition_size)\n",
    "        #print(time_intervals) #NOTE: checkpoint\n",
    "\n",
    "        #TODO: initialize. Store the complete data\n",
    "        complete_history = dict([(sample_id, self.action_history[sample_id]) for sample_id in sample_ID_batch])\n",
    "        for sample_id in complete_history:\n",
    "            for mental_predicate_idx in self.mental_predicate_set:\n",
    "                complete_history[sample_id][mental_predicate_idx] = {}\n",
    "                complete_history[sample_id][mental_predicate_idx]['time'] = [0]\n",
    "                complete_history[sample_id][mental_predicate_idx]['state'] = [0]\n",
    "        #print(complete_history) #NOTE: checkpoint\n",
    "        #TODO: initilize, store mental history, this will be fed into the LSTM\n",
    "        mental_history = torch.zeros(size=(len(sample_ID_batch),1,len(self.mental_predicate_set))).to(device)\n",
    "\n",
    "        ELBO = (torch.zeros(size=(1,self.batch_size))).to(device)    #NOTE: initialize ELBO\n",
    "        \n",
    "        #TODO: encode the mental history\n",
    "        h_a = self.LSTM_Action.forward(self.processed_data[sample_ID_batch,:,:]) #h_a (batch_size, num_predicate, output_size=hidden_size_m)\n",
    "        for i in range(len(time_intervals)-1):\n",
    "            #TODO: encode the mental history before the i-th time interval (LSTMs) -> categorical distribution -> prob\n",
    "            # prob (batch_size, 1, num_mental_predicate+1)\n",
    "            prob:torch.tensor = self.LSTM_History.forward(x=mental_history,action_embedding=h_a)\n",
    "            # logits (batch_size, 1, num_mental_predicate+1)\n",
    "            logits:torch.tensor = torch.log(prob)\n",
    "            #TODO: ELBO = ELBO + self.entropy_variational posterior\n",
    "            ELBO += self.entropy_variational_posterior(logits,temperature,device=device)\n",
    "            #TODO: draw hard samples. post_samples = self.sample_variational_posterior_hard(size = sample_size, prob = prob)\n",
    "            post_samples:torch.tensor = self.sample_variational_posterior(size=len(sample_ID_batch),logits=logits,temperature=temperature,hard=True)\n",
    "            #TODO: after sampling the mental transition time, update the history information\n",
    "            event_time = (time_intervals[i] + time_intervals[i+1])/2\n",
    "            _, indices = post_samples.max(dim=2)\n",
    "            indices = indices.detach().cpu().numpy()\n",
    "            new_mental_information = torch.zeros(size=(len(sample_ID_batch),1,len(self.mental_predicate_set))).to(device)\n",
    "            \n",
    "            #print(indices[0,:])\n",
    "            for batch_idx in range(indices.shape[0]):\n",
    "                for idx in indices[batch_idx,:]:\n",
    "                    if idx == 0: continue\n",
    "                    #TODO: update the mental history\n",
    "                    new_mental_information[batch_idx,0,idx-1] = event_time\n",
    "                    #TODO: update the complete history, which is a dict\n",
    "                    sample_id = sample_ID_batch[batch_idx]\n",
    "                    complete_history[sample_id][idx-1]['time'].append(event_time)\n",
    "                    if complete_history[sample_id][idx-1]['state'][-1] == 0: complete_history[sample_id][idx-1]['state'].append(1)\n",
    "                    else: complete_history[sample_id][idx-1]['state'].append(0)\n",
    "            #print(new_mental_information) #NOTE:checkpoint\n",
    "            #TODO: update mental_history\n",
    "            mental_history = torch.concat([mental_history,new_mental_information],dim=1)\n",
    "            \n",
    "            #TODO: calculate mean of those ELBOs\n",
    "            ELBO = torch.mean(ELBO).view(-1,)\n",
    "\n",
    "            #TODO: ELBO += 1/L * (\\sum log likelihood)\n",
    "            ELBO += (self.log_likelihood(dataset=complete_history,sample_ID_batch=sample_ID_batch,T_max=self.time_horizon)).to(device)\n",
    "            #print(ELBO) #NOTE: checkpoint\n",
    "            #TODO: return ELBO\n",
    "            return ELBO*len(self.action_history) #NOTE: \\mathcal{L} * N\n",
    "\n",
    "\n",
    "    def sample_variational_posterior(self, size:int, logits: torch.tensor, temperature:float=1.0, hard=False)->torch.tensor:\n",
    "        #TODO: use gumbel-max trick to explicitly sample from the variational posterior defined by LSTMs, which is a categorical distribution\n",
    "        '''\n",
    "        draw explicit samples from variational posterior\n",
    "\n",
    "        Parameters:\n",
    "            size: number of samples\n",
    "            logits: \n",
    "            hard: boolean\n",
    "        '''\n",
    "    \n",
    "        result = []\n",
    "        for i in range(size):\n",
    "            tmp = self.gumbel_softmax(logits,temperature,hard)\n",
    "            result.append(tmp)\n",
    "        #NOTE: return one-hot vectors.\n",
    "        #print(result)\n",
    "        result = torch.stack(result,dim=0)\n",
    "        return result\n",
    "\n",
    "    def sample_Gumble(self, shape, eps:float=1e-20):\n",
    "        #TODO: sample from Gumbel(0,1). This is needed when we want to explicitly sample from the variational posterior\n",
    "        '''\n",
    "        Sample from Gumbel(0,1) with shape = 'shape'\n",
    "\n",
    "        Parameters:\n",
    "            shape: \n",
    "            eps: small perturbation to avoid log(0)\n",
    "            tens_type: \n",
    "        '''\n",
    "\n",
    "        U = torch.rand(shape)\n",
    "        U = U.cuda()\n",
    "        return -torch.log(-torch.log(U+eps)+eps)\n",
    "\n",
    "    def sample_Gumble_softmax(self, logits:torch.tensor, temperature=1.0):\n",
    "        #TODO: sample from the gumbel-softmax distribution\n",
    "        '''\n",
    "        Parameters:\n",
    "            prob: \n",
    "            temperature:\n",
    "        '''\n",
    "        y = logits + self.sample_Gumble(logits.shape)\n",
    "        return F.softmax(y/temperature,dim=-1)\n",
    "\n",
    "    def gumbel_softmax(self, logits:torch.tensor, temperature:float=1.0, hard=False):\n",
    "        #TODO: ST-gumbel-softmax\n",
    "        \"\"\"\n",
    "        ST-gumple-softmax\n",
    "        input: [*, n_class]\n",
    "        return: flatten --> [*, n_class] an one-hot vector\n",
    "        \"\"\"\n",
    "\n",
    "        y = self.sample_Gumble_softmax(logits,temperature)\n",
    "        if not hard: return y\n",
    "        shape = y.size()\n",
    "        _, idx = y.max(dim=-1)\n",
    "        y_hard = torch.zeros_like(y).view(-1,shape[-1])\n",
    "        y_hard.scatter_(1, idx.view(-1,1), 1)\n",
    "        y_hard = y_hard.view(*shape)\n",
    "        y_hard = (y_hard - y).detach() + y\n",
    "        return y_hard\n",
    "\n",
    "    def entropy_variational_posterior(self, logits:torch.tensor, temperature:float=1.0, MC_size:int=100, device='cuda')->float:\n",
    "        #TODO: approximately calculate the entropy of the variational posterior\n",
    "        #TODO: the true variational posterior (categorical) is approximated by a Gumbel-softmax distribution, controlled by 'tau' (temperature)\n",
    "        '''\n",
    "        Parameters:\n",
    "            temperature: temperature parameter\n",
    "            prob: probabilities for each category\n",
    "        '''\n",
    "        #TODO: draw 'MC_size' samples from gumble softmax distribution\n",
    "        gumbel_softmax_samples = self.sample_variational_posterior(size=MC_size,logits=logits,temperature=temperature).to(device)\n",
    "        #TODO: compute the log-densities\n",
    "        log_densities = torch.log(self.Gumbel_softmax_density(gumbel_softmax_samples,temperature,logits)).to(device)\n",
    "        #TODO: this is the Monte-Carlo estimate of the entropy\n",
    "        result = torch.mean(-log_densities,dim=[0,-1])\n",
    "        return result\n",
    "\n",
    "    def Gumbel_softmax_density(self, y:torch.tensor, temperature:float, logits:torch.tensor)->torch.tensor:\n",
    "        #TODO: return the probability density of Gumbel softmax distribution at y\n",
    "        '''\n",
    "        Parameters:\n",
    "            y: input\n",
    "            temperature: temperature parameter\n",
    "            prob: probabilities for each category\n",
    "        '''\n",
    "        k = logits.size()[-1]\n",
    "        prob = torch.exp(logits)\n",
    "        #NOTE: compute the probability density. RHS is the density of gumbel softmax distribution\n",
    "        result = gamma(k) * (temperature)**(k-1) * (torch.multiply(prob,1/(y)**temperature))**(-k) * torch.sum(prob/y**(temperature+1))\n",
    "        return result\n",
    "\n",
    "    def optimize_ELBO(self, temperature, device, sample_ID_batch, optimizer_psi, optimizer_theta):\n",
    "        optimizer_theta.zero_grad()  # set gradient zero at the start of a new mini-batch\n",
    "        optimizer_psi.zero_grad()\n",
    "        #TODO: the loss function is just the -ELBO, since minimize the loss is equivalent to minimize the KL-divergence\n",
    "        loss = -self.ELBO(sample_ID_batch, temperature, device)\n",
    "        loss.backward()\n",
    "        optimizer_theta.step()\n",
    "        optimizer_psi.step()\n",
    "        return loss\n",
    "\n",
    "    def train_model(self, temperature:float=1.0, num_iter:int=10, lr:tuple=(0.01,0.02)):\n",
    "        #TODO: train the model from incomplete data by gradient descent\n",
    "        #TODO: 1. draw a minibatch ('batch_size') from the data, compute ELBO\n",
    "        #TODO: 2. compute gradient of ELBO w.r.t. to \\theta (model parameter) and \\psi (variational parameter, i.e. LSTM param)\n",
    "        #TODO: 3. gradient ascent, alternatively optimize \\theta and \\psi\n",
    "\n",
    "        model_parameters = [self.model_parameter[0]['base'],\n",
    "                    self.model_parameter[0][0]['weight'],\n",
    "                    self.model_parameter[0][1]['weight'],\n",
    "                    self.model_parameter[1]['base'],\n",
    "                    self.model_parameter[1][0]['weight'],\n",
    "                    self.model_parameter[1][1]['weight'],\n",
    "                    self.model_parameter[2]['base'],\n",
    "                    self.model_parameter[2][0]['weight'],\n",
    "                    self.model_parameter[3]['base'],\n",
    "                    self.model_parameter[3][0]['weight'],\n",
    "                    self.model_parameter[4]['base'],\n",
    "                    self.model_parameter[4][0]['weight'],\n",
    "                    self.model_parameter[5]['base'],\n",
    "                    self.model_parameter[5][0]['weight'],\n",
    "                    self.model_parameter[6]['base'],\n",
    "                    self.model_parameter[6][0]['weight']\n",
    "                    ]\n",
    "\n",
    "        num_batch = len(self.action_history) // self.batch_size\n",
    "        #print(num_batch)\n",
    "        losses = []\n",
    "        optimizer_theta = optim.Adam(params=model_parameters,lr=lr[0])\n",
    "        optimizer_psi = optim.SGD(params=[list(self.LSTM_Action.parameters())[0], list(self.LSTM_History.parameters())[0]], lr=lr[1])\n",
    "\n",
    "        for iter in tqdm(range(num_iter)):\n",
    "            for batch_idx in tqdm(np.arange(0, num_batch, 1)):\n",
    "                indices = np.arange(batch_idx*self.batch_size, (batch_idx+1)*self.batch_size, 1)\n",
    "                #NOTE: we want to minimize negative ELBO\n",
    "                loss = self.optimize_ELBO(temperature,self.device,indices,optimizer_psi,optimizer_theta) #NOTE:-ELBO, want to see it decreases\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            print('iter >> {}; loss >> {}'.format(iter+1, loss.detach().cpu().numpy()))\n",
    "            print('model parameter $\\\\theta$ >> {}'.format(model_parameters))\n",
    "            #print('LSTM parameters $\\psi$ >> {}'.format([list(self.LSTM_Action.parameters())[0], list(self.LSTM_History.parameters())[0]]))\n",
    "        return losses\n",
    "\n",
    "    def plot_loss(self,losses:list):\n",
    "        #TODO: plot the losses\n",
    "        plt.figure(figsize=(9,3),dpi=150)\n",
    "        X = np.arange(1,len(losses)+1,1)\n",
    "        plt.plot(X,losses,label='$-\\mathcal{L}(\\\\theta,\\psi,\\mathcal{H}_a(T))$')\n",
    "        plt.legend(bbox_to_anchor=(1,1))\n",
    "        plt.xlabel('iter')\n",
    "        plt.ylabel('negative ELBO')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.15s/it]\n",
      "  2%|▏         | 1/50 [00:24<19:58, 24.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 1; loss >> [13057.362]\n",
      "model parameter $\\theta$ >> [tensor([-0.2700], dtype=torch.float64, requires_grad=True), tensor([0.0332], dtype=torch.float64, requires_grad=True), tensor([-0.0132], dtype=torch.float64, requires_grad=True), tensor([-0.2700], dtype=torch.float64, requires_grad=True), tensor([0.0143], dtype=torch.float64, requires_grad=True), tensor([0.0157], dtype=torch.float64, requires_grad=True), tensor([-0.1700], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.0705], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.2204], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5703], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0702], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.08s/it]\n",
      "  4%|▍         | 2/50 [00:48<19:27, 24.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 2; loss >> [13403.383]\n",
      "model parameter $\\theta$ >> [tensor([-0.2401], dtype=torch.float64, requires_grad=True), tensor([0.0416], dtype=torch.float64, requires_grad=True), tensor([-0.0216], dtype=torch.float64, requires_grad=True), tensor([-0.2399], dtype=torch.float64, requires_grad=True), tensor([0.0362], dtype=torch.float64, requires_grad=True), tensor([-0.0062], dtype=torch.float64, requires_grad=True), tensor([-0.1401], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.0414], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.1912], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5409], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0406], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.06s/it]\n",
      "  6%|▌         | 3/50 [01:12<19:00, 24.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 3; loss >> [13023.076]\n",
      "model parameter $\\theta$ >> [tensor([-0.2104], dtype=torch.float64, requires_grad=True), tensor([0.0513], dtype=torch.float64, requires_grad=True), tensor([-0.0313], dtype=torch.float64, requires_grad=True), tensor([-0.2099], dtype=torch.float64, requires_grad=True), tensor([0.0576], dtype=torch.float64, requires_grad=True), tensor([-0.0276], dtype=torch.float64, requires_grad=True), tensor([-0.1100], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.0124], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.1620], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5116], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0112], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.04s/it]\n",
      "  8%|▊         | 4/50 [01:37<18:33, 24.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 4; loss >> [12299.874]\n",
      "model parameter $\\theta$ >> [tensor([-0.1806], dtype=torch.float64, requires_grad=True), tensor([0.0504], dtype=torch.float64, requires_grad=True), tensor([-0.0304], dtype=torch.float64, requires_grad=True), tensor([-0.1801], dtype=torch.float64, requires_grad=True), tensor([0.0804], dtype=torch.float64, requires_grad=True), tensor([-0.0504], dtype=torch.float64, requires_grad=True), tensor([-0.0800], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.0166], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.1329], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4823], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0181], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.97s/it]\n",
      " 10%|█         | 5/50 [02:00<18:04, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 5; loss >> [12110.384]\n",
      "model parameter $\\theta$ >> [tensor([-0.1507], dtype=torch.float64, requires_grad=True), tensor([0.0517], dtype=torch.float64, requires_grad=True), tensor([-0.0317], dtype=torch.float64, requires_grad=True), tensor([-0.1502], dtype=torch.float64, requires_grad=True), tensor([0.1058], dtype=torch.float64, requires_grad=True), tensor([-0.0758], dtype=torch.float64, requires_grad=True), tensor([-0.0501], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.0454], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.1039], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4531], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0472], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.99s/it]\n",
      " 12%|█▏        | 6/50 [02:24<17:38, 24.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 6; loss >> [12165.336]\n",
      "model parameter $\\theta$ >> [tensor([-0.1208], dtype=torch.float64, requires_grad=True), tensor([0.0464], dtype=torch.float64, requires_grad=True), tensor([-0.0264], dtype=torch.float64, requires_grad=True), tensor([-0.1201], dtype=torch.float64, requires_grad=True), tensor([0.1346], dtype=torch.float64, requires_grad=True), tensor([-0.1046], dtype=torch.float64, requires_grad=True), tensor([-0.0202], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.0740], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.0751], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4240], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0760], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.04s/it]\n",
      " 14%|█▍        | 7/50 [02:49<17:15, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 7; loss >> [12406.336]\n",
      "model parameter $\\theta$ >> [tensor([-0.0907], dtype=torch.float64, requires_grad=True), tensor([0.0421], dtype=torch.float64, requires_grad=True), tensor([-0.0221], dtype=torch.float64, requires_grad=True), tensor([-0.0901], dtype=torch.float64, requires_grad=True), tensor([0.1600], dtype=torch.float64, requires_grad=True), tensor([-0.1300], dtype=torch.float64, requires_grad=True), tensor([0.0098], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.1025], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.0464], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3950], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1044], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.88s/it]\n",
      " 16%|█▌        | 8/50 [03:12<16:45, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 8; loss >> [11950.065]\n",
      "model parameter $\\theta$ >> [tensor([-0.0608], dtype=torch.float64, requires_grad=True), tensor([0.0403], dtype=torch.float64, requires_grad=True), tensor([-0.0203], dtype=torch.float64, requires_grad=True), tensor([-0.0601], dtype=torch.float64, requires_grad=True), tensor([0.1849], dtype=torch.float64, requires_grad=True), tensor([-0.1549], dtype=torch.float64, requires_grad=True), tensor([0.0398], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.1309], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.0178], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3661], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1325], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.98s/it]\n",
      " 18%|█▊        | 9/50 [03:36<16:21, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 9; loss >> [11758.396]\n",
      "model parameter $\\theta$ >> [tensor([-0.0309], dtype=torch.float64, requires_grad=True), tensor([0.0372], dtype=torch.float64, requires_grad=True), tensor([-0.0172], dtype=torch.float64, requires_grad=True), tensor([-0.0301], dtype=torch.float64, requires_grad=True), tensor([0.2081], dtype=torch.float64, requires_grad=True), tensor([-0.1781], dtype=torch.float64, requires_grad=True), tensor([0.0698], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.1590], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0105], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3374], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1602], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.99s/it]\n",
      " 20%|██        | 10/50 [04:00<15:58, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 10; loss >> [11984.389]\n",
      "model parameter $\\theta$ >> [tensor([-0.0010], dtype=torch.float64, requires_grad=True), tensor([0.0333], dtype=torch.float64, requires_grad=True), tensor([-0.0133], dtype=torch.float64, requires_grad=True), tensor([-2.9256e-05], dtype=torch.float64, requires_grad=True), tensor([0.2318], dtype=torch.float64, requires_grad=True), tensor([-0.2018], dtype=torch.float64, requires_grad=True), tensor([0.0998], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.1869], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0386], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3088], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1874], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.14s/it]\n",
      " 22%|██▏       | 11/50 [04:28<16:15, 25.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 11; loss >> [11407.76]\n",
      "model parameter $\\theta$ >> [tensor([0.0290], dtype=torch.float64, requires_grad=True), tensor([0.0318], dtype=torch.float64, requires_grad=True), tensor([-0.0118], dtype=torch.float64, requires_grad=True), tensor([0.0299], dtype=torch.float64, requires_grad=True), tensor([0.2570], dtype=torch.float64, requires_grad=True), tensor([-0.2270], dtype=torch.float64, requires_grad=True), tensor([0.1297], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.2146], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0665], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.2804], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.2141], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.04s/it]\n",
      " 24%|██▍       | 12/50 [04:55<16:15, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 12; loss >> [10993.996]\n",
      "model parameter $\\theta$ >> [tensor([0.0590], dtype=torch.float64, requires_grad=True), tensor([0.0352], dtype=torch.float64, requires_grad=True), tensor([-0.0152], dtype=torch.float64, requires_grad=True), tensor([0.0598], dtype=torch.float64, requires_grad=True), tensor([0.2852], dtype=torch.float64, requires_grad=True), tensor([-0.2552], dtype=torch.float64, requires_grad=True), tensor([0.1596], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.2420], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0941], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.2522], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.2403], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.90s/it]\n",
      " 26%|██▌       | 13/50 [05:21<16:01, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 13; loss >> [11230.803]\n",
      "model parameter $\\theta$ >> [tensor([0.0887], dtype=torch.float64, requires_grad=True), tensor([0.0403], dtype=torch.float64, requires_grad=True), tensor([-0.0203], dtype=torch.float64, requires_grad=True), tensor([0.0897], dtype=torch.float64, requires_grad=True), tensor([0.3151], dtype=torch.float64, requires_grad=True), tensor([-0.2851], dtype=torch.float64, requires_grad=True), tensor([0.1896], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.2692], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.1214], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.2242], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.2658], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.49s/it]\n",
      " 28%|██▊       | 14/50 [05:47<15:29, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 14; loss >> [11004.107]\n",
      "model parameter $\\theta$ >> [tensor([0.1183], dtype=torch.float64, requires_grad=True), tensor([0.0448], dtype=torch.float64, requires_grad=True), tensor([-0.0248], dtype=torch.float64, requires_grad=True), tensor([0.1196], dtype=torch.float64, requires_grad=True), tensor([0.3428], dtype=torch.float64, requires_grad=True), tensor([-0.3128], dtype=torch.float64, requires_grad=True), tensor([0.2196], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.2960], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.1484], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.1964], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.2906], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.50s/it]\n",
      " 30%|███       | 15/50 [06:12<15:00, 25.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 15; loss >> [10862.201]\n",
      "model parameter $\\theta$ >> [tensor([0.1477], dtype=torch.float64, requires_grad=True), tensor([0.0512], dtype=torch.float64, requires_grad=True), tensor([-0.0312], dtype=torch.float64, requires_grad=True), tensor([0.1496], dtype=torch.float64, requires_grad=True), tensor([0.3680], dtype=torch.float64, requires_grad=True), tensor([-0.3380], dtype=torch.float64, requires_grad=True), tensor([0.2495], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.3225], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.1751], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.1689], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.3147], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.55s/it]\n",
      " 32%|███▏      | 16/50 [06:38<14:34, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 16; loss >> [10530.671]\n",
      "model parameter $\\theta$ >> [tensor([0.1772], dtype=torch.float64, requires_grad=True), tensor([0.0566], dtype=torch.float64, requires_grad=True), tensor([-0.0366], dtype=torch.float64, requires_grad=True), tensor([0.1796], dtype=torch.float64, requires_grad=True), tensor([0.3908], dtype=torch.float64, requires_grad=True), tensor([-0.3608], dtype=torch.float64, requires_grad=True), tensor([0.2795], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.3487], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.2014], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.1416], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.3381], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.42s/it]\n",
      " 34%|███▍      | 17/50 [07:03<14:04, 25.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 17; loss >> [10850.061]\n",
      "model parameter $\\theta$ >> [tensor([0.2070], dtype=torch.float64, requires_grad=True), tensor([0.0577], dtype=torch.float64, requires_grad=True), tensor([-0.0377], dtype=torch.float64, requires_grad=True), tensor([0.2097], dtype=torch.float64, requires_grad=True), tensor([0.4129], dtype=torch.float64, requires_grad=True), tensor([-0.3829], dtype=torch.float64, requires_grad=True), tensor([0.3092], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.3745], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.2274], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.1145], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.3608], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.21s/it]\n",
      " 36%|███▌      | 18/50 [07:34<14:27, 27.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 18; loss >> [9970.026]\n",
      "model parameter $\\theta$ >> [tensor([0.2368], dtype=torch.float64, requires_grad=True), tensor([0.0627], dtype=torch.float64, requires_grad=True), tensor([-0.0427], dtype=torch.float64, requires_grad=True), tensor([0.2398], dtype=torch.float64, requires_grad=True), tensor([0.4337], dtype=torch.float64, requires_grad=True), tensor([-0.4037], dtype=torch.float64, requires_grad=True), tensor([0.3387], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.3999], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.2530], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.0878], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.3825], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.06s/it]\n",
      " 38%|███▊      | 19/50 [07:58<13:32, 26.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 19; loss >> [10598.629]\n",
      "model parameter $\\theta$ >> [tensor([0.2665], dtype=torch.float64, requires_grad=True), tensor([0.0665], dtype=torch.float64, requires_grad=True), tensor([-0.0465], dtype=torch.float64, requires_grad=True), tensor([0.2699], dtype=torch.float64, requires_grad=True), tensor([0.4535], dtype=torch.float64, requires_grad=True), tensor([-0.4235], dtype=torch.float64, requires_grad=True), tensor([0.3682], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.4250], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.2783], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.0613], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4035], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.93s/it]\n",
      " 40%|████      | 20/50 [08:25<13:11, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 20; loss >> [9612.775]\n",
      "model parameter $\\theta$ >> [tensor([0.2961], dtype=torch.float64, requires_grad=True), tensor([0.0731], dtype=torch.float64, requires_grad=True), tensor([-0.0531], dtype=torch.float64, requires_grad=True), tensor([0.3001], dtype=torch.float64, requires_grad=True), tensor([0.4756], dtype=torch.float64, requires_grad=True), tensor([-0.4456], dtype=torch.float64, requires_grad=True), tensor([0.3979], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.4496], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3031], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.0351], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4236], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.57s/it]\n",
      " 42%|████▏     | 21/50 [08:51<12:39, 26.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 21; loss >> [10143.4]\n",
      "model parameter $\\theta$ >> [tensor([0.3255], dtype=torch.float64, requires_grad=True), tensor([0.0764], dtype=torch.float64, requires_grad=True), tensor([-0.0564], dtype=torch.float64, requires_grad=True), tensor([0.3302], dtype=torch.float64, requires_grad=True), tensor([0.4989], dtype=torch.float64, requires_grad=True), tensor([-0.4689], dtype=torch.float64, requires_grad=True), tensor([0.4277], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.4738], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3275], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.0092], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4427], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.35s/it]\n",
      " 44%|████▍     | 22/50 [09:19<12:29, 26.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 22; loss >> [9555.602]\n",
      "model parameter $\\theta$ >> [tensor([0.3550], dtype=torch.float64, requires_grad=True), tensor([0.0769], dtype=torch.float64, requires_grad=True), tensor([-0.0569], dtype=torch.float64, requires_grad=True), tensor([0.3602], dtype=torch.float64, requires_grad=True), tensor([0.5225], dtype=torch.float64, requires_grad=True), tensor([-0.4925], dtype=torch.float64, requires_grad=True), tensor([0.4575], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.4975], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3515], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.0164], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4610], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.43s/it]\n",
      " 46%|████▌     | 23/50 [09:44<11:50, 26.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 23; loss >> [9630.955]\n",
      "model parameter $\\theta$ >> [tensor([0.3845], dtype=torch.float64, requires_grad=True), tensor([0.0730], dtype=torch.float64, requires_grad=True), tensor([-0.0530], dtype=torch.float64, requires_grad=True), tensor([0.3903], dtype=torch.float64, requires_grad=True), tensor([0.5464], dtype=torch.float64, requires_grad=True), tensor([-0.5164], dtype=torch.float64, requires_grad=True), tensor([0.4873], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.5208], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3750], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.0416], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4783], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.62s/it]\n",
      " 48%|████▊     | 24/50 [10:10<11:20, 26.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 24; loss >> [9688.427]\n",
      "model parameter $\\theta$ >> [tensor([0.4140], dtype=torch.float64, requires_grad=True), tensor([0.0742], dtype=torch.float64, requires_grad=True), tensor([-0.0542], dtype=torch.float64, requires_grad=True), tensor([0.4204], dtype=torch.float64, requires_grad=True), tensor([0.5687], dtype=torch.float64, requires_grad=True), tensor([-0.5387], dtype=torch.float64, requires_grad=True), tensor([0.5168], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.5436], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.3981], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.0665], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.4946], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.59s/it]\n",
      " 50%|█████     | 25/50 [10:39<11:14, 26.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 25; loss >> [9177.665]\n",
      "model parameter $\\theta$ >> [tensor([0.4433], dtype=torch.float64, requires_grad=True), tensor([0.0760], dtype=torch.float64, requires_grad=True), tensor([-0.0560], dtype=torch.float64, requires_grad=True), tensor([0.4505], dtype=torch.float64, requires_grad=True), tensor([0.5920], dtype=torch.float64, requires_grad=True), tensor([-0.5620], dtype=torch.float64, requires_grad=True), tensor([0.5466], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.5660], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.4207], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.0910], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5100], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.86s/it]\n",
      " 52%|█████▏    | 26/50 [11:08<11:06, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 26; loss >> [8950.231]\n",
      "model parameter $\\theta$ >> [tensor([0.4727], dtype=torch.float64, requires_grad=True), tensor([0.0806], dtype=torch.float64, requires_grad=True), tensor([-0.0606], dtype=torch.float64, requires_grad=True), tensor([0.4804], dtype=torch.float64, requires_grad=True), tensor([0.6131], dtype=torch.float64, requires_grad=True), tensor([-0.5831], dtype=torch.float64, requires_grad=True), tensor([0.5762], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.5878], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.4428], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.1151], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5244], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.70s/it]\n",
      " 54%|█████▍    | 27/50 [11:37<10:47, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 27; loss >> [8992.58]\n",
      "model parameter $\\theta$ >> [tensor([0.5024], dtype=torch.float64, requires_grad=True), tensor([0.0822], dtype=torch.float64, requires_grad=True), tensor([-0.0622], dtype=torch.float64, requires_grad=True), tensor([0.5102], dtype=torch.float64, requires_grad=True), tensor([0.6306], dtype=torch.float64, requires_grad=True), tensor([-0.6006], dtype=torch.float64, requires_grad=True), tensor([0.6057], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6091], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.4644], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.1389], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5379], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:31<00:00, 10.48s/it]\n",
      " 56%|█████▌    | 28/50 [12:09<10:41, 29.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 28; loss >> [8893.689]\n",
      "model parameter $\\theta$ >> [tensor([0.5322], dtype=torch.float64, requires_grad=True), tensor([0.0874], dtype=torch.float64, requires_grad=True), tensor([-0.0674], dtype=torch.float64, requires_grad=True), tensor([0.5397], dtype=torch.float64, requires_grad=True), tensor([0.6503], dtype=torch.float64, requires_grad=True), tensor([-0.6203], dtype=torch.float64, requires_grad=True), tensor([0.6353], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6298], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.4854], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.1622], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5504], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.26s/it]\n",
      " 58%|█████▊    | 29/50 [12:37<10:03, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 29; loss >> [8794.533]\n",
      "model parameter $\\theta$ >> [tensor([0.5619], dtype=torch.float64, requires_grad=True), tensor([0.0894], dtype=torch.float64, requires_grad=True), tensor([-0.0694], dtype=torch.float64, requires_grad=True), tensor([0.5694], dtype=torch.float64, requires_grad=True), tensor([0.6672], dtype=torch.float64, requires_grad=True), tensor([-0.6372], dtype=torch.float64, requires_grad=True), tensor([0.6649], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6500], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5060], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.1852], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5620], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.27s/it]\n",
      " 60%|██████    | 30/50 [13:02<09:11, 27.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 30; loss >> [8114.795]\n",
      "model parameter $\\theta$ >> [tensor([0.5917], dtype=torch.float64, requires_grad=True), tensor([0.0909], dtype=torch.float64, requires_grad=True), tensor([-0.0709], dtype=torch.float64, requires_grad=True), tensor([0.5990], dtype=torch.float64, requires_grad=True), tensor([0.6828], dtype=torch.float64, requires_grad=True), tensor([-0.6528], dtype=torch.float64, requires_grad=True), tensor([0.6944], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6697], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5260], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2077], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5727], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.81s/it]\n",
      " 62%|██████▏   | 31/50 [13:25<08:20, 26.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 31; loss >> [8125.856]\n",
      "model parameter $\\theta$ >> [tensor([0.6217], dtype=torch.float64, requires_grad=True), tensor([0.0946], dtype=torch.float64, requires_grad=True), tensor([-0.0746], dtype=torch.float64, requires_grad=True), tensor([0.6287], dtype=torch.float64, requires_grad=True), tensor([0.6994], dtype=torch.float64, requires_grad=True), tensor([-0.6694], dtype=torch.float64, requires_grad=True), tensor([0.7236], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.6888], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5454], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2298], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5825], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.83s/it]\n",
      " 64%|██████▍   | 32/50 [13:48<07:38, 25.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 32; loss >> [8492.369]\n",
      "model parameter $\\theta$ >> [tensor([0.6517], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.0800], dtype=torch.float64, requires_grad=True), tensor([0.6583], dtype=torch.float64, requires_grad=True), tensor([0.7164], dtype=torch.float64, requires_grad=True), tensor([-0.6864], dtype=torch.float64, requires_grad=True), tensor([0.7528], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7073], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5643], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2514], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5915], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.94s/it]\n",
      " 66%|██████▌   | 33/50 [14:12<07:04, 24.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 33; loss >> [8171.044]\n",
      "model parameter $\\theta$ >> [tensor([0.6814], dtype=torch.float64, requires_grad=True), tensor([0.1004], dtype=torch.float64, requires_grad=True), tensor([-0.0804], dtype=torch.float64, requires_grad=True), tensor([0.6879], dtype=torch.float64, requires_grad=True), tensor([0.7352], dtype=torch.float64, requires_grad=True), tensor([-0.7052], dtype=torch.float64, requires_grad=True), tensor([0.7819], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7252], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.5826], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2726], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.5996], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.09s/it]\n",
      " 68%|██████▊   | 34/50 [14:40<06:50, 25.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 34; loss >> [8207.74]\n",
      "model parameter $\\theta$ >> [tensor([0.7110], dtype=torch.float64, requires_grad=True), tensor([0.0989], dtype=torch.float64, requires_grad=True), tensor([-0.0789], dtype=torch.float64, requires_grad=True), tensor([0.7174], dtype=torch.float64, requires_grad=True), tensor([0.7531], dtype=torch.float64, requires_grad=True), tensor([-0.7231], dtype=torch.float64, requires_grad=True), tensor([0.8111], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7426], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6004], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.2933], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6069], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.17s/it]\n",
      " 70%|███████   | 35/50 [15:07<06:33, 26.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 35; loss >> [7851.0264]\n",
      "model parameter $\\theta$ >> [tensor([0.7402], dtype=torch.float64, requires_grad=True), tensor([0.0942], dtype=torch.float64, requires_grad=True), tensor([-0.0742], dtype=torch.float64, requires_grad=True), tensor([0.7471], dtype=torch.float64, requires_grad=True), tensor([0.7693], dtype=torch.float64, requires_grad=True), tensor([-0.7393], dtype=torch.float64, requires_grad=True), tensor([0.8401], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7593], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6175], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3135], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6135], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.33s/it]\n",
      " 72%|███████▏  | 36/50 [15:32<06:01, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 36; loss >> [7198.7065]\n",
      "model parameter $\\theta$ >> [tensor([0.7697], dtype=torch.float64, requires_grad=True), tensor([0.0879], dtype=torch.float64, requires_grad=True), tensor([-0.0679], dtype=torch.float64, requires_grad=True), tensor([0.7767], dtype=torch.float64, requires_grad=True), tensor([0.7854], dtype=torch.float64, requires_grad=True), tensor([-0.7554], dtype=torch.float64, requires_grad=True), tensor([0.8688], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7754], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6341], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3333], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6193], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.36s/it]\n",
      " 74%|███████▍  | 37/50 [15:57<05:33, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 37; loss >> [7338.2744]\n",
      "model parameter $\\theta$ >> [tensor([0.7991], dtype=torch.float64, requires_grad=True), tensor([0.0847], dtype=torch.float64, requires_grad=True), tensor([-0.0647], dtype=torch.float64, requires_grad=True), tensor([0.8062], dtype=torch.float64, requires_grad=True), tensor([0.8046], dtype=torch.float64, requires_grad=True), tensor([-0.7746], dtype=torch.float64, requires_grad=True), tensor([0.8977], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.7909], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6501], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3525], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6246], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.40s/it]\n",
      " 76%|███████▌  | 38/50 [16:22<05:06, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 38; loss >> [7039.4453]\n",
      "model parameter $\\theta$ >> [tensor([0.8288], dtype=torch.float64, requires_grad=True), tensor([0.0772], dtype=torch.float64, requires_grad=True), tensor([-0.0572], dtype=torch.float64, requires_grad=True), tensor([0.8357], dtype=torch.float64, requires_grad=True), tensor([0.8175], dtype=torch.float64, requires_grad=True), tensor([-0.7875], dtype=torch.float64, requires_grad=True), tensor([0.9265], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8059], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6655], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3713], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6291], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.73s/it]\n",
      " 78%|███████▊  | 39/50 [16:49<04:42, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 39; loss >> [6955.9023]\n",
      "model parameter $\\theta$ >> [tensor([0.8581], dtype=torch.float64, requires_grad=True), tensor([0.0693], dtype=torch.float64, requires_grad=True), tensor([-0.0493], dtype=torch.float64, requires_grad=True), tensor([0.8650], dtype=torch.float64, requires_grad=True), tensor([0.8291], dtype=torch.float64, requires_grad=True), tensor([-0.7991], dtype=torch.float64, requires_grad=True), tensor([0.9557], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8202], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6802], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.3895], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6332], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.15s/it]\n",
      " 80%|████████  | 40/50 [17:16<04:22, 26.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 40; loss >> [7181.3916]\n",
      "model parameter $\\theta$ >> [tensor([0.8872], dtype=torch.float64, requires_grad=True), tensor([0.0624], dtype=torch.float64, requires_grad=True), tensor([-0.0424], dtype=torch.float64, requires_grad=True), tensor([0.8944], dtype=torch.float64, requires_grad=True), tensor([0.8398], dtype=torch.float64, requires_grad=True), tensor([-0.8098], dtype=torch.float64, requires_grad=True), tensor([0.9852], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8338], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.6944], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4072], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6367], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.59s/it]\n",
      " 82%|████████▏ | 41/50 [17:45<04:02, 26.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 41; loss >> [6478.3916]\n",
      "model parameter $\\theta$ >> [tensor([0.9164], dtype=torch.float64, requires_grad=True), tensor([0.0604], dtype=torch.float64, requires_grad=True), tensor([-0.0404], dtype=torch.float64, requires_grad=True), tensor([0.9239], dtype=torch.float64, requires_grad=True), tensor([0.8475], dtype=torch.float64, requires_grad=True), tensor([-0.8175], dtype=torch.float64, requires_grad=True), tensor([1.0145], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8469], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7080], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4244], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6397], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.34s/it]\n",
      " 84%|████████▍ | 42/50 [18:10<03:31, 26.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 42; loss >> [6627.542]\n",
      "model parameter $\\theta$ >> [tensor([0.9456], dtype=torch.float64, requires_grad=True), tensor([0.0586], dtype=torch.float64, requires_grad=True), tensor([-0.0386], dtype=torch.float64, requires_grad=True), tensor([0.9535], dtype=torch.float64, requires_grad=True), tensor([0.8551], dtype=torch.float64, requires_grad=True), tensor([-0.8251], dtype=torch.float64, requires_grad=True), tensor([1.0436], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8594], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7210], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4411], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6423], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.76s/it]\n",
      " 86%|████████▌ | 43/50 [18:36<03:04, 26.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 43; loss >> [6587.4775]\n",
      "model parameter $\\theta$ >> [tensor([0.9752], dtype=torch.float64, requires_grad=True), tensor([0.0592], dtype=torch.float64, requires_grad=True), tensor([-0.0392], dtype=torch.float64, requires_grad=True), tensor([0.9829], dtype=torch.float64, requires_grad=True), tensor([0.8610], dtype=torch.float64, requires_grad=True), tensor([-0.8310], dtype=torch.float64, requires_grad=True), tensor([1.0724], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8713], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7334], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4572], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6445], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.42s/it]\n",
      " 88%|████████▊ | 44/50 [19:01<02:36, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 44; loss >> [6578.3306]\n",
      "model parameter $\\theta$ >> [tensor([1.0047], dtype=torch.float64, requires_grad=True), tensor([0.0570], dtype=torch.float64, requires_grad=True), tensor([-0.0370], dtype=torch.float64, requires_grad=True), tensor([1.0123], dtype=torch.float64, requires_grad=True), tensor([0.8705], dtype=torch.float64, requires_grad=True), tensor([-0.8405], dtype=torch.float64, requires_grad=True), tensor([1.1012], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8826], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7452], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4728], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6463], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.37s/it]\n",
      " 90%|█████████ | 45/50 [19:27<02:08, 25.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 45; loss >> [6297.338]\n",
      "model parameter $\\theta$ >> [tensor([1.0342], dtype=torch.float64, requires_grad=True), tensor([0.0509], dtype=torch.float64, requires_grad=True), tensor([-0.0309], dtype=torch.float64, requires_grad=True), tensor([1.0417], dtype=torch.float64, requires_grad=True), tensor([0.8845], dtype=torch.float64, requires_grad=True), tensor([-0.8545], dtype=torch.float64, requires_grad=True), tensor([1.1299], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.8933], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7564], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.4879], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6479], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.75s/it]\n",
      " 92%|█████████▏| 46/50 [19:53<01:43, 25.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 46; loss >> [6213.596]\n",
      "model parameter $\\theta$ >> [tensor([1.0638], dtype=torch.float64, requires_grad=True), tensor([0.0472], dtype=torch.float64, requires_grad=True), tensor([-0.0272], dtype=torch.float64, requires_grad=True), tensor([1.0712], dtype=torch.float64, requires_grad=True), tensor([0.8972], dtype=torch.float64, requires_grad=True), tensor([-0.8672], dtype=torch.float64, requires_grad=True), tensor([1.1585], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9034], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7670], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5024], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6491], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.32s/it]\n",
      " 94%|█████████▍| 47/50 [20:18<01:16, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 47; loss >> [5682.2007]\n",
      "model parameter $\\theta$ >> [tensor([1.0931], dtype=torch.float64, requires_grad=True), tensor([0.0497], dtype=torch.float64, requires_grad=True), tensor([-0.0297], dtype=torch.float64, requires_grad=True), tensor([1.1007], dtype=torch.float64, requires_grad=True), tensor([0.9108], dtype=torch.float64, requires_grad=True), tensor([-0.8808], dtype=torch.float64, requires_grad=True), tensor([1.1870], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9130], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7771], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5163], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6502], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.44s/it]\n",
      " 96%|█████████▌| 48/50 [20:43<00:51, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 48; loss >> [5628.618]\n",
      "model parameter $\\theta$ >> [tensor([1.1226], dtype=torch.float64, requires_grad=True), tensor([0.0585], dtype=torch.float64, requires_grad=True), tensor([-0.0385], dtype=torch.float64, requires_grad=True), tensor([1.1300], dtype=torch.float64, requires_grad=True), tensor([0.9251], dtype=torch.float64, requires_grad=True), tensor([-0.8951], dtype=torch.float64, requires_grad=True), tensor([1.2153], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9220], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7867], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5298], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6510], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.63s/it]\n",
      " 98%|█████████▊| 49/50 [21:09<00:25, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 49; loss >> [5825.3135]\n",
      "model parameter $\\theta$ >> [tensor([1.1518], dtype=torch.float64, requires_grad=True), tensor([0.0597], dtype=torch.float64, requires_grad=True), tensor([-0.0397], dtype=torch.float64, requires_grad=True), tensor([1.1592], dtype=torch.float64, requires_grad=True), tensor([0.9372], dtype=torch.float64, requires_grad=True), tensor([-0.9072], dtype=torch.float64, requires_grad=True), tensor([1.2436], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9305], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.7957], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5426], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6516], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.21s/it]\n",
      "100%|██████████| 50/50 [21:34<00:00, 25.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 50; loss >> [5657.096]\n",
      "model parameter $\\theta$ >> [tensor([1.1808], dtype=torch.float64, requires_grad=True), tensor([0.0601], dtype=torch.float64, requires_grad=True), tensor([-0.0401], dtype=torch.float64, requires_grad=True), tensor([1.1884], dtype=torch.float64, requires_grad=True), tensor([0.9480], dtype=torch.float64, requires_grad=True), tensor([-0.9180], dtype=torch.float64, requires_grad=True), tensor([1.2718], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([0.9385], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.8042], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([0.5550], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.6521], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28628e1ab00>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKEAAAGwCAYAAABxdXa+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAABcSAAAXEgFnn9JSAAB1LElEQVR4nO3dd3gU1R7G8fekQ+hVOtJJQKVIlaIiTemigCCgAnbsFcu1oFiwV1BBURCkg6B0KSJKJ0jvHUILgfRz/9jNmoQEQpLNJtnv53n2Gc6ZOXN+i3cu5GXmjLHWCgAAAAAAAHAnH08XAAAAAAAAgLyPEAoAAAAAAABuRwgFAAAAAAAAtyOEAgAAAAAAgNsRQgEAAAAAAMDtCKEAAAAAAADgdoRQAAAAAAAAcDtCKAAAAAAAALgdIRQAAAAAAADcjhAKAAAAAAAAbkcIBQAAAAAAALcjhAIAAAAAAIDb+Xm6AGQfY8wRSfkl7fd0LQAAAAAAINepIOm8tfaqjAw21tosrgc5lTHmbGBgYMGqVat6uhQAAAAAAJDL7Ny5U9HR0RHW2kIZGc+dUN5lf9WqVUPCwsI8XQcAAAAAAMhlQkNDtXnz5gw/XcWaUAAAAAAAAHA7QigAAAAAAAC4HSEUAAAAAAAA3I4QCgAAAAAAAG5HCAUAAAAAAAC3I4QCAAAAAACA2xFCAQAAAAAAwO38PF0AAAAAAACAJFlrZa31dBlewRgjY0y2zkkIBQAAAAAAPCY+Pl7h4eGKiIhQTEyMp8vxKgEBASpYsKCKFy8uX19ft89HCAUAAAAAADwiPj5e+/btU1RUlKdL8UoxMTEKDw9XZGSkKlas6PYgihAKAAAAAAB4RHh4uKKiouTr66vSpUsrODhYPj4sX50dEhISFBkZqaNHjyoqKkrh4eEqVaqUW+ckhAIAAAAAAB4REREhSSpdurQKFy7s4Wq8i4+Pj+v3/NChQ4qIiHB7CEW8CK9zPPK4Hvn1Ed35y53acHSDp8sBAAAAAK9krXWtARUcHOzharxX4u99TEyM2xeF504oeJU52+do4PSBOhp5VJI0c+tMfXnbl7r72rs9XBkAAAAAeJekgQeP4HlO0t97a61b35jHf2V4hQuxF/TonEfV8aeOrgBKki7EXVD/af314OwHFR0X7cEKAQAAAADI2wihkOetP7Je14+6Xp+s+sTVF+gbqKJBRV3tL/75Qi3HtNT+M/s9USIAAAAAAHkeIRTyrASboJF/jlSj0Y0UdjzM1V+3VF39M/gfrR2yVg3LNnT1rzq4SvW/rq8FuxZ4olwAAAAAAPI0QijkSQfPHlS7ce305O9PKiY+xtX/eJPHtWrQKtUpVUeVilTS0oFLNbj+YNf+E+dPqO24tnpr6VtKsAmeKB0AAAAAgDyJEAp5zpR/p+iaL6/R/F3zXX1lCpTR731/18h2IxXkF+TqD/IL0ledvtK3nb919SfYBL2w8AV1+7mbTkedzu7yAQAAAADIkwihkGecizmne6ffqx4Te+jkhZOu/m61umnDAxt0S9Vb0hw7sN5Arbhnha4ucrWrb8bWGbp+1PXacHSDW+sGAAAAAMAbEEIhT1h1cJXqfVVP36771tWX3z+/Rncarcl3TFaJ/CUue456Zepp9eDV6li9o6tvx8kdajK6icZtGOeWugEAAAAAyAqLFi1S79691ahRIxUrVkwffPCBp0u6CCEUcrW4hDi9vuR1NfummXac3OHqv77s9Vo3ZJ3urX+vjDHpPl/RfEU1s/dM/a/1/2TkGHch7oL6Te2nh2Y/lGx9KQAAAAAAPC06OloDBgzQhx9+qFGjRmnVqlXq2rWrnn32WZ0+fdrT5SVDCIVca/ep3Wo9prVeXvyy4m28JMnH+GhYi2Fafs9yVS9ePUPn9TE+ernVy/r1rl9VLF8xV//n/3yuVmNa6cDZA1lSPwAAAAAAmdW/f3/Nnj1b33//vQoUKKBJkyZp7Nixio2NVXh4uKfLS4YQCrmOtVbjNozTtV9eq+X7l7v6KxeprCUDluj1m16Xv69/pudpX629Vg9erQZlGrj6Vh5Yqfpf1dfC3QszfX4AAAAAADLjl19+0c8//6w+ffqocOHCkqT4+HgZY3TXXXepatWqHq4wOT9PFwBcidNRp/XA7Ac0YdOEZP19r+mrTzt8qsJBhbN0vspFKmvZPcv0yK+PaPTa0ZKk4+eP65YfbtHwm4brmebPXNHjfgAAAACA9LHW6kz0GU+XccUKBxbOtp8Thw8fLkm65Zb/XsTVq1cv9ezZU76+vtlSw5UghEKusWTPEvWb2k/7z+539RUOLKwvb/tSver0ctu8QX5BGtV5lJpWaKoHZz+o6PhoJdgEPbfgOa08uFJjuozJ8vALAAAAALzdmegzKjqiqKfLuGKnnj2lIkFF3D7P7t27tXbtWhlj1Lx582T7cmIAJfE4HnKBmPgYPT//ed049sZkAVSrSq204YENbg2gkrqn3j1ace8KVS5S2dU3bcs0XT/qem08ujFbagAAAAAAQJLmz58vSQoJCVHRorkjrONOKOR4G49u1Dsr3pGVlST5+fjp9Rtf19PNnpavT/amu/XL1NfqwavVd0pfzdkxR5K0/eR2NfmmicZ0GaOeoT2ztR4AAAAAQN4zYMCAi/q6du2qrl27utpLliyRJN10003ZVFXmEUIhx2tQtoFeavmS/rfkf6pZvKZ+7P6jGpRtcPmBblIsXzHN6jNLry95Xf9b8j9ZWZ2PPa8+U/qoWrFqqlemnsdqAwAAAIC8onBgYZ169pSny7hihQMzv1zL2LFjL+qrXLlyqiFUmzZtMj1fdiGEQq4wrOUw5fPLp4cbPazggGBPlyMf46NXWr+ixuUbq8/kPjoVdUpxCXHqP62//h70twL9Aj1dIgAAAADkasaYbFlbKSey1l5y/86dO3XgwAEFBgaqdevW2VNUFmBNKOQKfj5+evaGZ3NEAJVU+2rtNfmOya72xmMb9dqS1zxYEQAAAAAgr0u8C+r2229XoUKFPFxN+hFCAZl049U36uHrH3a1317+tlYdXOXBigAAAAAAedmiRYsUGBiofv366bffftOCBQt0+vTpi4779ttvNWvWrOwvMA08jgdkgbfbvK05O+Zo56mdSrAJ6j+tv9YMXqN8/vk8XRoAAAAAIA85deqUZs6cqYSEBLVv397VX7BgQQ0ZMkQtW7bU0aNHNWPGDPXp00e33XabB6tNjjuhgCwQHBCsMV3HyMhIkrac2KKXFr3k4aoAAAAAAHlJWFiY+vTpowYNGqhv377q2bOnQkNDFRAQoIiICL333nsaMmSINm/erFGjRqlXr16eLjkZ7oQCssgNFW/Q400e18iVIyVJI/8cqa61uuqGijd4uDIAAAAAQF4QGhqqOXPmXNRvrdWRI0cUFBSkokWLeqCy9OFOKCALvXHTG6pVopYkycpqwLQBioyJ9HBVAAAAAIC8zBijMmXK5OgASiKEArJUPv98GtNljHyM49LaeWqnnpv/nIerAgAAAADA8wihgCzWuHxjPdv8WVf7078/1cLdCz1YEQAAAAAAnkcIBbjBK61eUd1SdV3te6bfo7PRZz1YEQAAAAAAnkUIBbhBoF+gxnYdKz8fx9r/e8/s1VO/P+XhqgAAAAAA8BxCKMBN6pWpp2Ethrnao9aM0twdcz1YEQAAAAAAnkMIBbjRCy1eUP0y9V3t+2bcp9NRpz1XEAAAAADkEMYY168TEhI8WIl3S/p7n/S/iTsQQgFu5O/rr7FdxyrAN0CSdDDioIbOHerhqgAAAADA84wxCghw/KwUGRnp4Wq8V+LvfUBAgNtDKD+3nh2A6pSqo/+1/p+eX/C8JOn79d+rR+0e6lyzs4crAwAAAADPKliwoMLDw3X06FFJUnBwsHx8uF8mOyQkJCgyMtL1e1+wYEG3z0kIBWSDp5o9pWlbpumvg39JkgbPHKzmFZqreP7iHq4MAAAAADynePHiioyMVFRUlA4dOuTpcrxWUFCQihd3/8+nxItANvDz8dPYrmMV5BckSToaeVQP/fqQh6sCAAAAAM/y9fVVxYoVVbx4cdejecg+AQEBKl68uCpWrChfX1+3z8edUEA2qVmipobfNFxP/P6EJOnnsJ/Vo3YP9Qzt6eHKAAAAAMBzfH19VapUKZUqVUrWWllrPV2SVzDGuH0NqJQIoYBsNLTJUE3dMlVL9y2VJD0w+wG1rNRSpQuU9nBlAAAAAOB5nghGkH14HA/IRj7GR991+U75/fNLksIvhOv+2feT9AMAAAAA8jxCKCCbVS1WVe/e8q6rPW3LNP248UcPVgQAAAAAgPsRQgEecH/D+3XT1Te52o/MeUQHzx70YEUAAAAAALgXIRTgAT7GR992/lYFAwpKkk5HndagmYO86rG8qLgoHY887ukyAAAAAADZhBAK8JBKRSppZLuRrvacHXP07dpvPVhR9jgeeVzPz39eJd8tqavev0rDFg7zqvANAAAAALwVIRTgQffWu1cdqnVwtR//7XHtO7PPgxW5z9FzR/X070+r8keV9fbyt3Uu5pwSbILeXPqmHpz9oOIT4j1dIgAAAADAjQihAA8yxmhUp1EqElREkhQRE6F7Z9ybp+4MOhxxWE/89oSu/uhqvffnezofe/6iY75c/aX6Tu2rmPgYD1QIAAAAAMgOhFCAh5UrVE4ft//Y1Z6/a76+/OdLD1aUNQ6ePahH5zyqqz+6Wh+s/EAX4i649pXIX0LDbxqupuWbuvombJqgrhO6phpSAQAAAAByP0IoIAfoe01fdanZxdV+at5TGrFshI6cO+LBqjJm35l9emj2Q6rycRV9suoTRcdHu/aVCi6ld295V3uG7tHzLZ7XvH7zdEuVW1z75+yYo/bj2utM1BlPlA4AAAAAcCOTlx77waUZY8JCQkJCwsLCPF0KUnH03FGFfh6q8Avhrj5f46vbatzmWDuqegf5+fh5sMJL23N6j95e9ra+XfutYhNik+27qsBVerb5sxrcYLDy++dPti86Llp9pvTRlH+nuPrqXVVPv/X9TSWDS2ZL7QAAAACAywsNDdXmzZs3W2tDMzKeO6GAHKJ0gdIa23WsgvyCXH3xNl7Tt05X5wmdVfGDinphwQvacXKHB6u82K5Tu3TfjPtU/ZPq+mr1V8kCqLIFy+rj9h9r16O79FiTxy4KoCQp0C9QP9/+swZeN9DVt/bIWrX4roX2n9mfLd8BAAAAAOB+3AnlRbgTKnfYe3qvvlv3nb5b912ab8prVamV7q13r3qE9Eg12MkO28O3a/iy4fph/Q+Kt8nfbFehUAU9f8PzGlhvYLJQ7VKstXrq96c0cuXIZOeZf/d81SheI0trBwAAAABcuczeCUUI5UUIoXKX+IR4zd81X9+s/UbTtky76BE3SSocWFh96vbRvfXuVf0y9WWMcXtdW09s1ZtL39SPG39Ugk1Itq9S4Up6ocULGnDdAAX4Blzxua21enPpm3pp0UuuvpL5S+q3vr+pXpl6ma4dAAAAAJBxhFBIN0Ko3Ot45HGN2zBO36z9RmHHU//vd23pa3Vf/ft0V927VDRf0UzPGR0XrQNnD+jA2QPaf3a/9p/ZrzVH1mjy5smySv7/G1WKVtGLLV5Uv2v6yd/XP9Nzf7rqUz0y5xFXu1BgIc3uM1s3VLwh0+cGAAAAAGSM14ZQxpgGkm6R1Mj5KSdJ1tqLbgUxxvhIai6pk6SbJdWQFCDpgKR5kkZYa3dfYq7mkl6U1MQ5brOkT621319iTHlJr0tqJ6mYpH2Sxkt6y1oblcaYfJKel9RLUkVJJyXNlfSStfZgWnOlFyFU7met1aqDq/TN2m80ftN4nYs5d9Exgb6B6l67u+6rf59aV24tH3Px0m+x8bE6GHHQETCd2e8KmQ5E/Nc+FnnssvVUL1Zdw1oOU5+6fbJ80fRxG8ZpwLQBrkf98vnl05Q7p6h9tfZZOg8AAAAAIH28OYSaJqlLyv40QqhqkrY7m0ckrZIUr//CqwhJHa21y1IZ20PSz3Is4v6HpBNyBFlFJL1vrX0qjfn+lFRC0iY5QquGkqpIWi7pZmttdIoxQZIWyRF0HZa0VFJlZ43HJTWx1u5K8zckHQih8pZzMec0KWySvln7jZbvX57qMVcXuVp3hN6hqLioZHc0HTl35KK7ma5ErRK1NKzFMN1Z5063vrFvxtYZumPSHYqOd1wu/j7+Gtd9nO4IvcNtcwIAAAAAUufNIdSzkoIl/e387JEUmEYIVVXSF5LelrTIOr+0MSZQ0peSBshxp1I1a21sknHFJO2WVEhSD2vtFGd/aUnLJFWTdKO1dnGK+ZbJcefVx9baoc4+P0kTJXWT9D9r7aspxrwhx91Wf0pqa6095+x/QtL7kpZYa1tf8W9U8jkIofKoLSe26Js13+j7Dd+n6w6m9DIyuqrAVapQuILKFyqvCoUqqEXFFupaq6t8fXyzbJ5LWbR7kTpP6Oy668vI6KvbvtKgBoOyZX4AAAAAgIPXhlApGWOilEYIdZlx+eS486iwpNbW2iVJ9j0jaYSk6dbarinGdZM0RdIsa22nJP2NJP0l6ZikiknveHKGV/slnZNUylob5+wPcB5fWFJ9a+3aFHOtl3SNpIbW2tVX8v1SnIcQKo+LjY/VrG2zNHrtaM3dMfeihcNTKpm/pCoUrqAKhZwf56/LFyqvCoUrqGzBshlaYDyr/X3wb7X/sb1OXjjp6hvRZoSeaf6MB6sCAAAAAO+S2RDKfc/R5BLW2gvGmG2SrpdUNsXuW53bX1IZOltSlKQ2xpigJOs8JY6ZmfKRO2vtUWPMUkk3SbpB0mLnruZyBFA7UwZQSea/Ro41rTIcQiHv8/f1V7fa3dStdjcdOHtA36//XuuOrFOJ/CVcdzIlBk3lCpVTkF+Qp0tOl+vLXa8/BvyhtuPa6lDEIUnSs/Of1akLpzT85uHZ8lZAAAAAAEDmeH0I5Vy0vJKzeSTF7mud2zUpx1lrY4wxm+RY66mGpA2XG5Ok/yY5QqXFVzBGzjFAupQvVF4vtHjB02VkmdBSoVo2cJlu+eEW7Ty1U5L09vK3dTrqtD679bNUF2AHAAAAAOQc/NQm9ZZUSo7Fv1ckdhpjCslxd5LkeIteahL7KyXpq5hNYwCvc3XRq7V04FLVLVXX1ffl6i/Vd0pfxcbHXmKk52wL36ZJYZNSfZMhAAAAAHgTr74TyhhTQdKHzubLKR6fK5Dk1+fTOEWkc1swlXHuHpMmY0xaiz5VTc94ICcrU7CMFg9YrFt/ulUrD6yUJI3fNF5no89qYs+Jyu+f38MVOqzYv0LvLH9H07dOlyTVLF5TK+5doWL5inm4MgAAAADwDK+9E8oYEyzHwuIlJE2z1n7p4ZIApFOxfMU0r988tanSxtU3e/tsNfi6gT7565NkC5hnpwSboJlbZ6rFdy3U/NvmrgBKkraGb1X3n7srJj7GI7UBAAAAgKd5ZQhljPGXNEmO9ZyWSeqTymFJn51J69aKYOc2IpVx7h6TJmttaGofSTvTMx7IDQoEFNCs3rPUvXZ3V9+WE1v06NxHVfb9suo7pa8W71ms7HgDaEx8jMasG6O6X9RV5wmdtWzfslSPW7J3ie6fdX+21AQAAAAAOY3XhVDOhcjHSuogaZ2kTtbaCymPs9aelXTG2SyfxukS+/cm6duXTWMArxfoF6ifb/9ZDzR8IFl/dHy0ftz4o24ce6NqflpTI5aN0NFzR7N8/rPRZ/X+ivdV5aMqGjh9oDYf35xsf4uKLTSz90z1u6afq++7dd/pneXvZHktAAAAAJDTeV0IJekTORYj3yapnbX29CWOXe/c1k+5w3k3VR1JUc5zXXZMiv4NSfoyMgaAJD8fP31+6+fa8tAWPd3saZXMXzLZ/u0nt+u5Bc+p/Afl1f3n7pqzfY7iE+IzNeeRc0f0woIXVPGDinpq3lM6GHHQtc/IqGutrlpxzwr9MfAP3VbjNo3qNEo3VLzBdcxzC57TlH+nZKoGAAAAAMhtTF55LMQYEyUp0FprLnHMG5JelOPOoxbW2n1pHes8/hlJIyRNt9Z2TbGvmxxrSs2y1nZK0t9I0l+SjkmqmHSxc2NMaUn75Xj8rrS1NtbZH+A8vrCketbadSnmWi/pGkkNrbWrL1XzZb5PWEhISEhYWFrrlgO5X0x8jGZunalRa0bp952/y+ri/4+rUKiC7ql3jwZeN1CViqT/pZPbwrfpvRXvaez6sRet7RTgG6C7r7lbTzZ7UrVK1Lpo7InzJ9R4dGPtOrVLkpTPL5+WDlyqBmUbXOE3BAAAAADPCA0N1ebNmzc7l/y5Yl4TQhljHpc0UtIRSS2ttdvTcc5iknZLKiSph7V2irO/lKTlkqpJutFauzjFuGWSmkv6yFr7mLPPT9LPkrpL+p+19tUUYxIDshWS2lprI539T0h6X9ISa23ry9V8me9DCAWvsvf0Xn279lt9u+5bHTh74KL9RkbtqrXTffXuU6eanRTgG5DqeVYdXKURy0do6r9TLwq1CgUW0gMNH9CjjR9V2YJlL1nPlhNb1GR0E52JdjzpW6ZAGa0atErlC6X1JC4AAAAA5BxeG0IZY26V9FKSrkaSjBx3ISV63Vo72xhznaQ1zv1/Kvnjc0mNttYmW1HYGNND0kTn2MWSwiW1kVRE0khr7ZOp1FbdOU9xSRslbZZ0vaQqcoRMNyW9Q8o5Jsh5/saSDktaKqmSs31cUhNr7a406k4XQih4q/iEeP228zeNXjNaM7fNVFxC3EXHlAoupf7X9td99e9TjeI1ZK3V3B1z9c6Kd7R4z+KLji9ToIweb/K4BjcYrMJBhdNdy/xd89V+XHvFW8cjgddddZ2WDlyqAgEFMvz9AAAAACA7eHMINUDSd5c5bKC1dowxprWkRek47UBr7ZhU5mouaZikJpIC5AiVPrXWjr1EfRUkvSapvaRicjwCOF7ScGttVBpj8kl6Xo639VWQdFLSXEkvWWsvvo3jChFCAY71nMauG6vRa0drx8kdqR7TslJLnbpwShuPbbxoX60StfR0s6d1V927FOgXmKEavl79tYbMGuJqd67ZWVPumCJfH98MnQ8AAAAAsoPXhlC4coRQwH+stVqyd4lGrRmlyZsnKzo++pLHN6vQTM82f1a31bhNPibz73R48rcnNXLlyP/aTZ/Ue23fy/R5AQAAAMBdMhtCeePb8QBAxhi1rtxaP3b/UYeePKSP23+suqXqXnRcpxqdtGzgMi2/Z7k61+ycJQGUJL1zyzvqVMP1TgO9/+f7GrV6VJacGwAAAAByIu6E8iLcCQVcmrVWfx/6W+M2jJMk3d/wfoWUDHHbfOdizumGb2/Q+qPrJUl+Pn6ae9dc3VzlZrfNCQAAAAAZxeN4SDdCKCDn2X9mvxqPbqzD5w5LkgoHFtbK+1aqVolaHq4MAAAAAJLjcTwAyMUqFK6gGb1nKJ9fPknSmegzuvWnW3Xi/AkPVwYAAAAAWYsQCgA8rGHZhhrXfZyrvevULnX7uZui4y69WDoAAAAA5CaEUACQA3Sv3V1v3fyWq71s3zINmjlIPDINAAAAIK8ghAKAHOLZ5s9q4HUDXe0fNvyg4UuHe7AiAAAAAMg6hFAAkEMYY/TlbV+qVaVWrr5hi4ZpYthED1YFAAAAAFmDEAoAcpAA3wBNvmOyqher7urrP62//jrwlwerAgAAAIDMI4QCgBymeP7imtVnlooGFZUkRcVFqcuELtp7eq+HKwMAAACAjCOEAoAcqEbxGpp8x2T5+fhJko5GHlWn8Z0UER3h4coAAAAAIGMIoQAgh7rx6hv15a1futobj21U78m9FZ8Q78GqAAAAACBjCKEAIAe7t/69errZ06727O2z9cRvT8ha68GqAAAAAODKEUIBQA73dpu31bVWV1f741Uf6+FfH1ZcQpznigIAAACAK0QIBQA5nI/x0bhu41S/TH1X3+f/fK5bf7pVZ6LOeLAyAAAAAEg/QigAyAWCA4L1a59f1ahcI1ff7zt/V7Nvm2n3qd0erAwAAAAA0ocQCgByidIFSmtx/8XqGdLT1bf5+GY1Ht1YK/av8GBlAAAAAHB5hFAAkIvk88+nCbdP0LAWw1x9x88f101jb9JPG3/yYGUAAAAAcGmEUACQy/gYH71+0+v6vuv3CvANkCRFx0frril36dXFr/LmPAAAAAA5EiEUAORS/a7tp/n95qt4vuKuvv8t+Z/umnKXouKisrWWfWf26bNVn2nZvmWEYAAAAABSRQgFALlYi0ot9Nd9f6lWiVquvvGbxuvGsTfq6Lmjbp9/x8kdum/Gfar6cVU9POdhtfiuhZp800RT/p2iBJvg9vkBAAAA5B6EUACQy1UtVlV/3vunbr76ZlffygMr1Xh0Y206tsktc24+vll9p/RVzU9r6pu13yguIc61b9XBVeoxsYdqf1Zbo9eMVnRctFtqAAAAAJC7EEIBQB5QJKiI5tw1R4PrD3b17T2zV82+aaa5O+Zm2TxrD6/V7RNvV53P6+jHjT8mu9upaFDRZMduC9+mQTMHqfJHlTVi2QidiTqTZXUAAAAAyH0IoQAgj/D39deXt32pkW1HyshIkiJiInTrT7fqs1WfZercKw+sVKfxnVT/6/qa/O9kWf237lO1YtX0bedvdeSpI1p13yrdHnK7a35JOnLuiJ5b8JwqflhRz857VocjDmeqFgAAAAC5k2EBWe9hjAkLCQkJCQsL83QpANxs5taZ6j25tyJjI119D1//sD5o/4H8fPzSdQ5rrf7Y+4feWPqG5u+af9H+0JKherHFi+oZ2vOic+44uUPvrXhPY9aNUXR88sfxAnwD1O+afnq62dOqWaJmBr4dAAAAAE8IDQ3V5s2bN1trQzMynhDKixBCAd5l3ZF16jS+kw6cPeDq61CtgybcPkGFAgulOc5aq993/q43lr6hZfuWXbS/3lX1NKzlMHWt1VU+5tI31B45d0Sf/PWJPv/nc52OOp1sn5FR11pd9WzzZ9W4fOMr+3IAAAAAsh0hFNKNEArwPocjDqvzhM7659A/rr46pepoVu9ZqlSkUrJjE2yCZm6dqTeWvpHs+ERNyzfVsJbD1KFaBxljLtp/KRHREfp69df6YOUHOhhx8KL9rSq10jPNn8nQuQEAAABkD0IopBshFOCdzsee191T79bkfye7+koFl9L0XtPVpHwTxSfE65fNv+jNpW9q47GNF42/sfKNGtZymG6sfGOmA6KY+Bj9uOFHvbPiHW05seWi/XVL1dUzzZ/RnaF3yt/XP1NzAQAAAMhahFBIN0IowHsl2AQNWzhMby17y9UX6BuoJ5o+ocn/Tta28G0XjelQrYNebPGimlds7pZ6Zm2bpRHLR2jF/hUX7a9YuKKGNh6qHrV7XHTHFgAAAADPIIRCuhFCARi7bqwGzRyk2ITYNI/pVqubXmzxohqUbZAtNS3bt0zvLH9HM7fNTHV/SMkQ3Vr9VnWs3lHNKzTnDikAAADAQwihkG6EUAAk6Y+9f6jbz9108sJJV5+P8dGdoXfqhRYvqE6pOh6pK+xYmN5d8a5+3Pij4hLiUj2mUGAhta3aVh2rdVSH6h10VYGrsrlKAAAAwHsRQiHdCKEAJNpxcod6T+6tsGNh6lWnl5674TnVKF7D02VJkvaf2a/P/v5M07ZM09bwrZc8tkGZBupYvaM6Vu+o68teL18f32yqEgAAAPA+hFBIN0IoAElZa2Vl5WN8PF1Kmnae3Kk5O+Zo9vbZWrR7kaLjo9M8tkT+Empfrb06VuuodtXaqVi+YtlYKQAAAJD3EUIh3QihAORm52PPa9HuRZq9fbZmb5+tfWf2pXmsj/FR0/JNXXdJXVv62ky/2Q8AAADwdoRQSDdCKAB5hbVW/574V7O3zdavO37Vsn3L0lxHSpLKFSynx5o8psebPJ6jHtnbf2a//j3xr1pXbq0A3wBPlwMAAABcEiEU0o0QCkBedSbqjObtmqdft/+qX7f/qqORR1M9rkn5JhrbdazH17+KjY/ViOUj9PofrysmPkZ96vbRj91/9GhNAAAAwOUQQiHdCKEAeIMEm6C1h9dq9vbZ+nX7r1p1cJWs/vuzLp9fPr3d5m093Ohhj6yHtfbwWt0z4x6tO7IuWf/i/ovVqnKrbK8HAAAASK/MhlA5dzVaAAAywMf4qEHZBnq51ctaed9KHX7ysPpd08+1/0LcBQ2dO1Q3f3+z9pzek211RcVF6YUFL+j6UddfFEBJ0pO/P6kEm5Bt9QAAAADZjRAKAJCnlS5QWt93+15T75yqUsGlXP2L9yxW3S/qatTqUXL3XcEr9q9Qva/q6a1lbynexrv6u9Xq5vr16sOrNX7jeLfWAQAAAHgSIRQAwCt0rdVVmx7YpB61e7j6zsWc0+BZg9Xxp446ePZgls8ZGROpx+Y+phu+vUFbTmxx9VcpWkUL716oKXdO0e0ht7v6X1j4gi7EXsjyOgAAAICcgBAKAOA1SgaX1KSek/RT959UNKioq3/ujrmq80UdjdswLsvuilqwa4HqflFXH/31kWtNKiOjxxo/pg33b9CNV98oSXr75rfl7+MvSdp3Zp8+/uvjLJkfAAAAyGkIoQAAXsUYo951e2vTg5t0a/VbXf2no06r39R+6jGxh45FHsvw+c9EndHgmYPV5oc22n16t6u/donaWn7Pcn3Q/gMFBwS7+qsWq6qHGz3sag9fNlzHI49neH4AAAAgpyKEAgB4pbIFy2pm75n6tvO3KhhQ0NU/dctUhX4eqsmbJ1/xOWdtm6XQz0M1as0oV5+v8dULN7ygNUPWqGmFpqmOG9ZymIoEFZEknY0+q9eWvHbFcwMAAAA5HSEUAMBrGWM0sN5AbXxgo266+iZX/4nzJ3T7pNt115S7dPLCycueJ/x8uPpO6atO4zvpYMR/a0tdd9V1+nvQ33rz5jcV5BeU5vhi+YrppZYvudpfrv5SW09szeC3AgAAAHImQigAgNerVKSS5vWbp087fKr8/vld/T9t/El1Pq+jX7f/muo4a60mhU1SyOch+nHjj67+AN8AvXHjG1p13yrVK1MvXTU8dP1DurrI1ZKkuIQ4PbfguUx8o8zbcmKLVuxf4dEaAAAAkLcQQgEAIMnH+OihRg9p/f3r1bxCc1f/4XOHdetPt2rQjEE6G332v/6Iw+oxsYfu+OWOZGtINS7XWGuHrNWLLV+Uv69/uucP9AvU223edrWnbZmmJXuWZPJbZczUf6eq7hd11fzb5np/xfseqQEAAAB5DyEUAABJVCtWTUsGLNG7t7yrQN9AV//otaNV94u6Wrh7ocauG6uQz0M0dctU1/58fvk0su1ILb9nuUJKhmRo7p4hPdWkfBNX+6l5TynBJmT8y2TA1hNb1X9af8UlxEmS/rfkf+l6JBEAAAC4HEIoAABS8PXx1VPNntKaIWvUsGxDV/++M/t08/c3a8D0ATodddrV37pya218YKMeb/q4fH18MzyvMUbvt/3vzqN/Dv2jCZsmZPh8VyoyJlI9JvZQREyEqy8iJkIfrvww22oAAABA3kUIBQBAGkJKhmjFPSv0WuvX5Ofjd9H+ggEF9eWtX2rB3QtUtVjVLJmzWYVmuj3kdlf7+QXPKyouKkvOfSnWWg2aOUhhx8Mu2vfRXx/p1IVTbq8BAAAAeRshFAAAl+Dv66+XWr2kVfetUt1SdV39Hap1UNiDYRrScIh8TNb+cfrWzW/J38exntS+M/v08V8fZ+n5U/Ppqk81ftN4V/vBhg+qSFARSdLZ6LP66K+P3F4DAAAA8jZCKAAA0qFemXr6e9DfmtBjgub1m6fZfWarQuEKbpmrWrFqeuj6h1ztN5e+qRPnT7hlLklasX+Fnvj9CVf7xso36qMOH+nxJo+7+j5c+WGyRxABAACAK0UIBQBAOgX6BerOOneqTZU2Msa4da5hLYcluxPptSWvuWWeo+eOqueknq6FyMsWLKvxPcbLz8dPjzZ+VIUDC0uSzkSfyZY7sgAAAJB3EUIBAJADFc9fXMNaDHO1v/jnC20L35alc8QlxKnX5F46FHFIkuTn46dJPSepdIHSkqQiQUU0tPFQ1/EfrPxAZ6LOZGkNAAAA8B6EUAAA5FAPN3pYVxe5WpIjMHp2/rNZev4XFrygxXsWu9oj245UswrNkh3zWJPHVCiwkCTpdNRpfbLqkyytAQAAAN6DEAoAgBwq0C9Qb7d529WetmWa/tj7R5ace8q/U/Tuindd7d51euvhRg9fdFzRfEX1aKNHXe2Rf45URHREltQAAAAA70IIBQBADtYzpKcal2vsaj/1+1NKsAmZOufWE1s1YNoAVzu0ZKhGdRqV5jpXjzd9XAUDCkqSTkWd0qerPs3U/AAAAPBOhFAAAORgxhi93/Z9V/vvQ3/r500/Z/h8kTGR6jGxhyJiHHczFQwoqCl3TlFwQHCaY4rlK6ZHGj3iar//5/s6F3MuwzUAAADAOxFCAQCQwzWv2Fw9avdwtZ9f8Lyi4qKu+DzWWg2aOUhhx8NcfWO6jlGN4jUuO/aJpk+oQEABSVL4hXB9tuqzK54fAAAA3o0QCgCAXODtNm/L38dfkrT3zF598teVLxD+6apPNX7TeFf76WZPq3vt7ukaWzx/cT18/X9rRr3353vcDQUAAIArQggFAEAuUK1YNT10/UOu9ptL39SJ8yfSPX7F/hV64vcnXO3WlVtr+M3Dr6iGJ5o+ofz++SVJJ86f0Bd/f3FF4wEAAODdCKEAAMglhrUcpiJBRSRJZ6LP6LUlr6Vr3NFzR9VzUk/FJcRJksoWLKsJPSbIz8fviuYvGVwyWRD27op3FRkTeUXnAAAAgPcihAIAIJconr+4hrUY5mp/8c8X2ha+7ZJj4hLi1GtyLx2KOCRJ8vPx06Sek1S6QOkM1fBUs6dcd0MdP39cX/7zZYbOAwAAAO9DCAUAQC7ycKOHVblIZUmOgOm5+c9d8vgXF7yoxXsWu9rvt31fzSo0y/D8pYJL6YGGD7ja7654V+djz2f4fBmxPXy79p7em61zAgAAIPNybQhljGlgjHnOGDPFGHPAGGONMTYd4wYYY1YZY84ZY04aY341xlzyb+PGmObO4046x60yxtx9mTHljTHfGWMOGWOijDHbjDH/M8YEXWJMPmPMa85jo5xjvzXGlLvc9wIAeIdAv0C9ffPbrvbULVO1dO/SVI+d+u9UvbPiHVe7d53eeqTRI5mu4elmTyufXz5J0tHIo/p69deZPmd6vbfiPdX8tKaqf1JdkzdPzrZ5AQAAkHm5NoSS9JKktyR1k5SukMYY86Gk7yTVkTRf0ipJt0j6wxjTNY0xPSQtkdRe0gZJcyVVlzTWGPNeGmOqSVoraYCkcEnTJflKelnSfGNMYCpjgiQtdH6vAs4x+yUNlLTWGFMlPd8RAJD33RF6hxqXa+xqP/n7k0qwCcmO2Ra+Tf2n9Xe1Q0qG6OtOX8sYk+n5Sxcorfsb3u9qj1g+QhdiL2T6vJczes1oPT3vaVlZxSbEqt/UflpzeI3b5wUAAEDWyM0h1J+SXpfUWVIZSdGXOtgY00bSUDlCoWuttV2tte0ltZQUL+k7Y0yRFGOKSfpWjgDpdmtta2vt7ZJqSdoh6UljTOtUphsjqYSkj621da21d0qqKWmqpOaSnk9lzDBJTZzfq4a19k5rbWNJT0oq6awDAAAZY/R+2/dd7b8P/a2JYRNd7ciYSPWY2EMRMRGSpIIBBTXljikqEFAgy2p4pvkzCvJz3Nx75NwRjVozKsvOnZop/07RkFlDkvVdiLugzuM763DEYbfODQAAgKyRa0Moa+0Ia+3L1tqZ1toj6RiS+F7qN6y125Oc509JX0oqIuneFGPuk1RI0nRr7ZQkY45KesbZfDLpAGNMIzmCpmNJjpG1Nk7SA5JiJT1qjPFLMiZA0sPO5kPW2nNJxo2U4w6sVsaYBun4ngAAL9C8YnP1qN3D1X5u/nOKiouStVaDZw3WpmObXPvGdB2jmiVqZun8VxW4SkMa/BcKjVg+QlFxUVk6R6JFuxep9+Terru9SuYvKV/jK0k6GHFQXX/umi13YgEAACBzcm0IdSWMMfkk3eRs/pLKIYl9nVL033qJMbMlRUlqk2Kdp8QxM621ye7OcoZXSyUVlXRDkl3NJRWWtNNau/YK6gMAeLG327wtPx/Hv2nsPbNXn/z1iT77+zP9tPEn1zFPN3ta3Wt3d8v8zzR/RoG+jifMD0Uc0ug1o7N8jn8O/aPOEzorJj5GklQkqIgW9l+oj9p/5Dpm1cFVunfGvbL2sktDAgAAwIO8IoSS41G4QEnHrbUHUtmfuKDENSn6r02x38VaGyNpk6QgSTXSM+YSc2VkDADAy1UrVk0PXf+Qq/36H6/rid+ecLVbV26t4TcPd9v8ZQuW1aD6g1ztt5e9rei4Sz4df0W2ntiqDj920LkYxw3C+fzyaXaf2apTqo4evP5B3d/gv3Wpxm8ar7eWvZVlcwMAACDreUsIVdG5TS2AkrU2UtJpSUWNMQUlyRhTSI67k9Icl6S/UnrnysIxaTLGhKX2kVQ1PeMBALnHSy1fUuFAxx9XETERik2IleQIiCb0mOC6U8pdnr3hWQX4BkhyPBr3zdpvsuS8B84e0C0/3KIT509Ikvx8/DT5jslqVsHxQltjjD7u8LFuuvom15gXF76oqf9OzZL5AQAAkPW8JYRKXIn1/CWOiXRuC6YYc6lxKcekZ66sGgMAgIrnL65hLYcl6/Pz8dOknpNUukBpt89fvlB53VfvPlf7rWVvZfpuqPDz4Wr7Q1vtP7tfkmRk9H3X79Wheodkx/n7+mtSz0mqVqyaq6/v1L5ad2RdpuYHAACAe3hLCOVVrLWhqX0k7fR0bQCArPdwo4d1dZGrXe33277vumMoOzx3w3Py9/GX5LiDacy6MRk+17mYc+r4U0f9e+JfV9/HHT5W77q9Uz2+WL5imtl7putusPOx59V5fGcdOZeed5YAAAAgO3lLCJX4trn8lzgm2LmNSDHmUuNSjknPXFk1BgAASVKQX5Dm3DVHfa/pq087fKpHGj2SrfNXKFxB99b77wWzw5cNdy0kfiWi46LV/efuWnVwlavvlVav6OFGD19ilFSrRC1N7DlRPsbx15r9Z/er28/d3Pa2PgAAAGSMt4RQ+5zb8qntNMYESyoi6ZS1NkKSrLVnJZ251Lgk/XvTO1cWjgEAwKVmiZr6odsPeqjRQzLGZPv8z7d43nU31L4z+zR23dgrGh+fEK9+U/tp3q55rr6Hrn9Ir7R6JV3j21Ztqw/afeBqrzywUoNnDuaNeQAAADmIt4RQWyVFSyppjCmXyv76zu2GFP3rU+x3Mcb4S6ojKUrStvSMucRcGRkDAECOUbFwRQ28bqCrPXzZcMXGx6ZrrLVWD/36kCZtnuTq612ntz7u8PEVBWqPNHok2dv6ftjwg95Z/k66xwMAAMC9vCKEstZekLTQ2eyZyiG3O7czU/TPTrE/qdskBUmab61Ner9/4phOxpjApAOMMaUltZB0StLyJLuWy3HXVVVjzHVXUB8AADnG8y2ed72Nb8/pPfp+/ffpGvfyopf11eqvXO12VdtpTNcxrsfr0ssYo087fqpWlVr9V9OC5zVj64wrOg8AAADcwytCKKeRzu0wY0z1xE5jTFNJQySdlpTyvdKjJZ2V1MUY0z3JmFKSEv9p9f2kA6y1q+QIlUpJGpFkjJ+kzyX5S/rYWhubZEyMpE+dzc+cjwcmjntC0jWSllhrV1/ZVwYAIPtULlJZ/a/t72q/ufTNy94N9eHKD/XG0jdc7Sblm2jyHZMV4BuQoRoCfAM0+Y7JqlK0iiTJyqrP5D7acJSbiQEAADwt14ZQxphbjTErEz+SApz9K5N8bk083lo7X9JHkopLWmeMmWaM+VXSH5L8JA201p5OOoe19qSkeyQlSPrFGLPQGDNJjsf7qkkaaa1dnEp5AyWFSxpqjNlgjJngHNNd0gpJb6Uy5g1Jf0lqJmm7MeZn5/d6X9JxZx0AAORoL7R4Qb7GV5K0+/RujdswLs1jf1j/gx7/7XFXO7RkqGb3ma3ggOA0x6RH8fzFNbP3TBUKLCRJioyNVOfxnXUs8limzgsAAIDMybUhlKSSkhon+SQuGpG0r2TSAdbax+QIiP6VdIukppLmS2pprZ2W2iTW2smSWkr6TVI9SR0l7ZA0wFr7ZBpjtjuPHeOsoZscQdbrkm621kanMiZK0o3OY85L6iqpkvMc9a21uy7xewEAQI5QpWgV3X3t3a72m0vfVFxC3EXHzd42WwOn/7eGVOUilfVb399ULF+xLKkjpGSIJvSY4Hqkb++Zver+c3dFx130RzAAAACyieGtMd7DGBMWEhISEhYW5ulSAAB52M6TO1Xz05qKt/GSpLFdxyYLppbuXaq249oqKs6xpGKp4FJaNnCZqhevnur5MmPknyP15O///ZvRgOsG6NvO33rkDYIAAAC5XWhoqDZv3rzZWhuakfHZeieUMaZjds4HAACyX9ViVdX3mr6u9ht/vOG6G2r9kfXqNL6TK4AqFFhIc++a65YASpIeb/K47rnuvyfax6wbo/f/fP8SI3KG6Lho7Ty5U/vO7PN0KQAAAFnGLytOYowpJKm4tXb3ZQ4tbYy5w1o7MSvmBQAAOdOLLV7UDxt+UIJN0PaT2zVh0wQ1Ld9U7ca105noM5KkQN9Azeg1Q/XK1HNbHcYYfXHbF9p+cruW7lsqSXpm3jOqVaKWbqtxm9vmvRRrrcIvhGvfmX2pfvae2asj5464jn+l1St6tfWrHqkVAAAgK2X6cTxjzFA53gLnL2mctbb/ZY6fLuk+a+3xTE2MK8bjeACA7HT31Lv1w4YfJEnVilVTgk3QrlOOJQ59ja+m3DlFnWt2zpZajkceV6PRjbTn9B5JUoGAAvrz3j9Vp1SdLJ8rOi5aB84euChYStq+EHfhis45/Kbher7F81leKwAAwJXI7ON4WRFChUuaJqm/HItvB9pLnNQYc6+k2tbapzI1Ma4YIRQAIDttPbFVIZ+HKMEmXLRvTJcx6n/dJf/dKsttOrZJTb9pqnMx5yRJVxe5WqsGrVKJ/CWu+FzxCfHad2aftpzYoq3hW13brSe26vC5w1lduiTpw3YfamiToW45NwAAQHpkNoTKisfxdlhr7zXGzJHke6kAyumopP9JIoQCACAPq1mipnrV6aWfNv6UrP+9W97L9gBKkuqUqqPxPcar8/jOsrLafXq3ekzsoXn95inANyDVMRHREf+FTCe2aku4Y7stfJui4zP3pr1g/2BVKlJJFQtXVMVCFR3bwhVdfX4+frr5+5u1LXybJOmx3x5TcECw7qt/X6bmBQAA8JSsCKF2GmPyWWt/SefxLSWVMcYUttaeyYL5AQBADjWsxTCN3zheVo5/o3qu+XN6stmTlxnlPrfVuE0j2ozQM/OfkST9sfcPPTj7QQ1rOcwRMqW4s+lQxKEMzWNkVLZgWVewlPJTqXAlFQkqctm39M3vN18tvmuhvWf2SpIGzxysfH75dNc1d2WoLgAAAE/KisfxWksaKqmftfbcZY4tLGmfpAKSylprj2ZqclwRHscDAHjCZ6s+08erPlafOn30cquXLxu8uJu1VgOnD9TY9WMzfa6KhSuqZvGaqlWilmoWr6maJWqqatGqKleoXJp3V12pXad2qcV3LVyBmK/x1aSek9StdrcsOT8AAEB6eXxNKEkyxoyR1EHSj5LmS1qe2l1OxpibnPujrbX5Mj0xrgghFAAADtFx0br5+5u1fP/yyx6b3z+/K2CqVbyWY1uilqoXq67ggOBsqFbacmKLWn7XUsfPO97r4u/jr+m9pqtD9Q7ZMj8AAICUc0KoAEnfS7pDknV+NktaKEfotNhae84Y01bSXEmbrLXXZHpiXBFCKAAA/nMs8phajWmlLSe2SJIqFKqQLGhKvMOpXKFy8jE+Hq5WWn9kvW4ce6NORZ2SJAX5BWnOXXPUunJrzxYGAAC8Ro4IoVwnM+Z2SS9Ius7ZlXjyaEmTJI2T9JukidbaXlk2MdKFEAoAgOSi4qK078w+lStYLtvuasqMVQdXqc33bRQREyHJsbj5vH7z1LRCUw9XBgAAvEFmQ6gs/Wc9a+0v1tr6kqpIGizpJ0kHJQVJ6idpuqQYSZdcOwoAACA7BPkFqUbxGrkigJKkRuUaaVafWcrn51jVIDI2Uh1+7KA1h9d4uDIAAIDLc8u95dbaPdba0dbaftbaipKqSbpX0mRJFyRVcse8AAAAeV3LSi01rdc018LnZ6LPqO0PbRV2jDudAQBAzpYtCxxYa3dZa7+z1vaT4y6p2OyYFwAAIC9qW7WtJt4+Ub7GV5IUfiFct/xwi3ac3OHhygAAANKW7atsWmtPSXoqu+cFAADIS7rU6qJx3cfJyEiSDp87rJu/v1l7T+/1cGUAAACpc2sIZYzpYox5OWW/tXazO+cFAADwBr3q9NI3nb9xtfed2ac2P7TR4YjDHqwKAAAgde6+E6qrpFfcPAcAAIDXGlhvoD7t8KmrvePkDrX5oY2ORx73YFUAAAAXy/bH8QAAAJC1Hmr0kEa0GeFqbz6+We3GtdPpqNOeKwoAACAFQigAAIA84Jnmz+jllv+tgrD2yFp1+LGDIqIjPFgVAADAfwihAAAA8ohXW7+qJ5o84WqvPLBSnSd01oXYCx6sCgAAwMHdIZRxfgAAAOBmxhi91/Y93d/gflff4j2L1X1id0XHRXuwMgAAADeHUNbaAdZa7rYCAADIJsYYfXbrZ7r72rtdfXN3zFXvyb0VlxDnwcoAAIC3IyACAADIY3yMj77p/I16hvR09U3dMlWdx3fWuiPrPFcYAADwaoRQAAAAeZCfj5/GdR+nW6vf6uqbs2OO6n1VT+3GtdPC3QtlrfVghQAAwNsQQgEAAORRAb4B+uWOX9Suartk/b/v/F03f3+zGo9urMmbJys+Id5DFQIAAG9CCAUAAJCHBfkFaXaf2Zp4+0TVL1M/2b6/D/2t2yfdrtqf1dao1aNYvBwAALgVIRQAAEAe5+vjq56hPfXPoH80r988tanSJtn+7Se3a/Cswar8UWWNWDZCZ6LOeKhSAACQlxFCAQAAeAljjNpUaaN5/ebpn0H/6I7QO+Rj/vvr4JFzR/TcgudU8cOKem7+czoccdiD1QIAgLyGEAoAAMALNSjbQD/f/rO2PrxVQxoMUaBvoGvf2eizGrF8hCp/VFmDZw7W9vDtHqwUAADkFYa3ongPY0xYSEhISFhYmKdLAQAAOcyRc0f08V8f6/O/P9eZ6OSP4xkZda/dXc82f1bXl7s+Q+e31ups9Fkdizx20edczDnVLllbDcs2VK0SteTn45cVXwkAAGSx0NBQbd68ebO1NjQj4wmhvAghFAAAuJyz0Wf19eqv9cHKD3Qo4tBF+2+6+iY92/xZ3VLlFsUmxOp45PFkgdLRyKOpBk3HIo8pOv7yC5/n98+velfVU4MyDdSwbEM1LNtQNYrXkK+Przu+LgAAuAKEUEg3QigAAJBe0XHRGrdhnN5d8a62hm+9aH+wf7AiYyOzpZYCAQVUv0z9ZMFUtWLVkq1nBQAA3I8QCulGCAUAAK5Ugk3Q9C3TNWL5CP118K9Mn8/H+Khk/pIqFVzK9fHz8dP6o+sVdixM8TY+XecpFFjIFUolbqsUrSJjTKZrBAAAqSOEQroRQgEAgIyy1uqPvX9oxPIRmrNjTrJ9BQIKqFRwKZUOLp0sXEqtr1i+Ymk+Wnch9oLWH12vfw794/r8e+JfJdiEdNVYNKioGpRtoIZlGrrumKpYuCLBFAAAWYQQCulGCAUAALLC3tN7dSzymEoFl1LJ4JLK75/fbXNFxkRq3ZF1jlDqsCOY2npiq6zS93fYEvlLOAKpJMFU2YJlCaYAAMgAQiikGyEUAADIC85Gn9Xaw2u1+vBq1x1T209uT/f4qwpcdVEwVbpAaTdWDABA3kAIhXQjhAIAAHnV6ajTWnN4jf459I8rnNp1ale6x5cvVD5ZMNWgbAOVyF/CjRUDAJD7EEIh3QihAACANzl54aRWH1qd7FG+fWf2pXt85SKV1apSK71505sqV6icGysFACB3yGwI5ZfVBQEAAAA5QbF8xXRL1Vt0S9VbXH3HIo9p9aHVyR7lOxhxMNXxe07v0Z7Te/TngT+1ZvAaBQcEZ1fpAADkSYRQAAAA8BqlgkupQ/UO6lC9g6vvcMThZKHU34f+1rHIY67928K36bG5j2lU51GeKBkAgDyDEAoAAABerUzBMrqt4G26rcZtkiRrrQ5GHNSIZSP06d+fSpJGrx2tdtXa6faQ2z1ZKgAAuZqPpwsAAAAAchJjjMoXKq+R7Ubq+rLXu/oHzRyk/Wf2e7AyAAByN0IoAAAAIBX+vv76qcdPKhBQQJLjDXx9p/ZVfEK8hysDACB3IoQCAAAA0lCtWDV91vEzV/uPvX/o7WVve7AiAAByL0IoAAAA4BL6XdNPvev0drVfWfyKVh5Y6cGKAADInQihAAAAgEswxuiLW79Q5SKVJUnxNl59JvfR2eizni0MAIBchhAKAAAAuIzCQYX1Y/cf5WMcf33efXq3Hvr1IQ9XBQBA7kIIBQAAAKRDswrN9EqrV1ztcRvGadyGcR6sCACA3IUQCgAAAEinF1q8oBsq3uBqPzj7Qe06tcuDFQEAkHsQQgEAAADp5Ofjp3HdxqlwYGFJUkRMhPpM7qPY+FgPV5Zx07ZM073T79WsbbM8XQoAII8jhAIAAACuQKUilfR1p69d7b8O/qXXlrzmwYoy5nzsed034z51+7mbvl33rTqN76Q7f7lTxyKPebo0AEAeRQgFAAAAXKE7Qu/QwOsGutpvLn1TS/Ys8WBFV2bLiS1qPLqxvln7TbL+iWETFfp5qCZsmiBrrYeqAwDkVYRQAAAAQAZ83OFjVS9WXZJkZdV3al+dvHDSw1Vd3rgN49Tw64badGyTq69IUBHXr0+cP6Hek3ur28/ddDjisAcqBADkVYRQAAAAQAYUCCign3r8JD8fP0nSgbMHNGjmoBx7B1Hi43f9pvZTZGykq//Jpk/qyJNH9EmHTxTsH+zqn751ukI+D9HYdWNz7HcCAOQuhFAAAABABjUs21Bv3vSmqz3l3ykXPeKWE6T2+F3RoKKa3mu63mv7ngL9AvVwo4e18YGNuunqm1zHnI46rQHTB6jjTx21/8x+T5QOAMhDCKEAAACATHiq2VPJgpuhc4dqy4ktHqwoudQev2tcrrHWDlmrzjU7Jzv26qJXa36/+frqtq9UMKCgq3/ujrkK/TxUX6/+mruiAAAZRggFAAAAZIKP8dH3Xb9X8XzFJTkee+szuY+i46I9WtelHr/7Y+AfqlSkUqrjjDEa3GCwwh4MU/tq7V39ETERGjJriNr80Ea7Tu1ye/0AgLyHEAoAAADIpHKFyumbzv896rb2yFq9uPBFj9VzucfvAnwDLnuOCoUr6Nc+v2pMlzHJFi5fuHuh6n5RV5/89YkSbII7ygcA5FGEUAAAAEAW6FKrix5o+ICr/f6f7+v3nb9nex1X8vjd5Rhj1P+6/tr84GZ1qdnF1X8+9rwenfuoWo1ppW3h27KsdgBA3kYIBQAAAGSR99q+p5CSIa723VPv1rHIY9kyd0Yfv0uPMgXLaOqdUzW+x3jXY4eStGzfMl375bV6b8V7ik+Iz1T9AIC8jxAKAAAAyCL5/fNrfI/xCvQNlCQdjTyqe6bf4/bFvLPi8bvLMcaoV51e2vzQZt0ReoerPyouSk/Pe1rNvm2msGNhmZojKi5KB88e1Poj67Vw90JNCpukuTvmKiouKrPlAwByAMPbLbyHMSYsJCQkJCwsc385AAAAwKV9/NfHGjp3qKv9SYdP9HCjh90y17gN43T/rPuT3f3UuFxj/Xz7z5m6++lypvw7RQ/OflBHI4+6+gJ8A/Ryy5f1TPNndCHugsLPh+vE+RMKvxCu8PPhCr/gbDt/ndifeMz52POpzhVSMkQTekxQ3dJ13fZ9AACXFxoaqs2bN2+21oZmZDwhlBchhAIAAMge1lrd+tOtmrNjjiQp0DdQfw/6O0tDlPOx5/XonEeT3f0kOR6/G37z8Cy5++lyws+H6/HfHtcPG35I1m9kZJW1P2cE+QVpZNuRur/h/TLGZOm5AQDpk9kQyusexzPGXG+MmWiMOWSMiTXGnDbGLDXGDDSp/GlmjPE1xjxujNlojLlgjDnuHF/7MvN0MsYsMcacdX4WG2NuvcyYUGPMJOccF5xzPmaM8br/TgAAALmZMUZjuo5R6eDSkqTo+Gj1ntxbF2IvXPG5EmyCouOiFREdofDz4ToccVh/H/zb7Y/fpUfx/MX1fbfvNav3LJUrWM7Vn9kAKr9/flUsXFHXlL7G1RcVF6UHf31QPSb20MkLJzN1fgCAZ3jVnVDGmB6SfpbkK2mNpB2SSkpqIclP0k/W2ruSHO8j6RdJ3SSdlrRAUglJLSVdkHSjtXZVKvM8JukDSXGS5kuKltRWUj5Jj1hrP01lTFPn+fNJWiVpj3OeqyRNknSnzeR/LO6EAgAAyF5zd8xVhx87uNrXXXWdiucrrpj4GMUmxComPibZJzb+4r54e/kFv7Pj8bvLORN1Rk/9/pRGrx2drL9oUFEVz19cxfMVd21L5C+RrF08f/K+IL8g1/i5O+aq/7T+yRZ4r1Cogn7q8ZNuqHhDtn0/AACP46WbMcZP0kFJpSTdZa39Kcm+2pKWSSom6SZr7SJn/32SRknaLqmFtfaos7+HHOHUDkm1rbVxSc5VU1KYHAHUjdbaP539NSStkFTYOWZHkjH+krZKulrSE9baD5z9BST9LqmppIHW2jGZ/D0ghAIAAMhmT/z2hD5Y+YHbzp+dj9+lx4nzJ3Ti/AkVz1dcRfMVlZ+PX6bPeeTcEfWb2k/zd8139fkYH73a6lW90OIF+fr4ZnoOAMDl8The+tWSI4DamjSAkiRr7b+Sxjmb1yfZ9YRz+0xiAOU8frKkGZKqSeqSYp6hctxp9WViAOUcs03Sm3LccTU0xZhucgRQ6xMDKOeYc5ISV7B8Mn1fEwAAADnJWze/pfpl6mf5easXq57tj9+lR4n8JVSrRC2VDC6ZJQGUJF1V4Cr91vc3vX3z265zJtgEvbz4ZbX5oY0Onj2YJfMAANwra/5UyB2i03lcuCQZY66WVFuOx+5mp3LcL5I6S+okaXKS/luT7E9tzEjnmEfSM8Zau8YYs0tSHWNMZWvtnnR+DwAAAOQAgX6BWnD3Ak35d4qi4qIU4BugAN8A+fv4u37t6vNN3pfymMT9/j7+Xnf3j4/x0bM3PKvWlVur9+Te2n16tyRp8Z7FuubLa/Rdl+/UuWZnD1cJALgUbwqhdknaKammMaZPKo/j9ZV0StJUZ/e1zu0ma21sKudb49y6Vks0xhSRVNHZXJtygLV2vzHmhKRKxphC1tqzKeZak3JMkv4qzrn2pPUFAQAAkDMVCSqie+rd4+ky8oTG5Rtr7ZC1GjJriH4O+1mSdPLCSXWZ0EWPNHpE79zyTrI1pQAAOYfXPI5nrY2X1F+OBcZ/NMasNsZMMMYslLRB0gFJN1trE1+1kRgmHUjjlIn9SVd/TBxzylobmYFxVzJXmowxYal9JFVNz3gAAAAgJyscVFjje4zXN52/UX7//K7+T1Z9oqbfNNXWE1s9WB0AIC1eE0JJkrV2uaRWctwVVV/SnZJulJQgaZ6zP1EB5/Z8GqdLDJkKXsGYjI5LbQwAAADgtYwxuqfePfpn0D+6prTr4QStO7JO9b+ur+/WfidveQkTAOQWXhVCGWN6S1olab+kxnKEPzUkjZFj4e+FxphAjxWYRay1oal95HgcEQAAAMgzapesrb/u+0sPX/+wq+987HndM+Me3TXlLp2NPnuJ0QCA7OQ1IZQxprqksZJOSLrNWrvKWhtprd1urR0iaZYcd0clPqx/zrnNf/HZJEnBzm1Ekr7LjcnouNTGAAAAAJAU5BekTzp+oml3TlOxfMVc/eM3jVe9r+pp1cFVHqwOAJDIa0IoSb0k+Uuaa609l8r+ic5tS+d2n3NbPo3zJfbvTdKXOKaoMSZYqbvUuCuZCwAAAEASXWp10fr716tlpZauvl2ndqn5t8317vJ3lWATPFgdAMCbQqjEIOdMGvsT+4s6t+ud2zrGGP9Ujq/v3G5I7LDWntZ/gVK9lAOMMRUklZC0N8mb8ZLOVT/lmLTmAgAAAHCx8oXKa+HdC/W/1v+Tj3H8uBOXEKdn5j+jjj921NFzRz1cIQB4L28KoY44tw3T2H+9c7tHkqy1uyX9KymfpFtTOf5253Zmiv7ZKfZnaowxpp6kKpI2WWv3pF46AAAAgES+Pr56udXLWtx/scoX+u9hg992/qYGXzfQoYhDHqwOALyXN4VQ053blsaYB5LuMMY0kfS4s/lLkl0jndt3jDGlkhzfXVJnSTuSnDfRR5LiJd3vPG/imOqSXpQU5zwmqamSdku61hjzeJIxwZI+czbfT8d3BAAAAODUolILrb9/vbrW6urqOxhxUH0m91FcQpznCgMAL+U1IZS1do2k95zNz40xm4wxE40xyyQtl2Px76+ttfOTDPtWjoCouqQtxphJxphFcgRVFyT1tdYm+9PLWrtV0tOSAiUtNcb8aoyZJscjd8UlPWGt3ZFiTKykvs5zjjTGrDTG/Cxpu6SmzvnGZtXvBQAAAOAtiuUrpil3TNFbN7/l6luyd4leW/KaB6sCAO/kNSGUJFlrn5bUXdLvkq6S1E1SiKQlkvo435KX9PgEST0lPSnpkKTbJNWVNFlSQ2vtX2nM84Ecd0r9KamFpJsl/SOpk7X2kzTGrJDjkcDJkqo5x5+U9ISkO621NsNfHAAAAPBixhg92/xZ9a7T29X3xh9vaP6u+ZcYBQDIaoZsw3sYY8JCQkJCwsLCPF0KAAAAkO0ioiPU4OsG2n5yuySpVHAprRuyTmUKlvFwZQCQO4SGhmrz5s2brbWhGRnvVXdCAQAAAPBeBQMLamLPiQr0DZQkHYs8pj5T+ig+Id7DlQGAdyCEAgAAAOA1rrvqOn3U/r/3BC3es5j1oQAgmxBCAQAAAPAqgxsMVq86vVzt1/94XQt2LfBgRQDgHQihAAAAAHgVY4y+uu0rVStWTZJkZXXXlLt05NwRD1cGAHkbIRQAAAAAr1MosJAm3v7f+lBHI4+qz2TWhwIAdyKEAgAAAOCV6pWppw/bf+hqL9qzSK//8brnCgKAPI4QCgAAAIDXGtJgiO4MvdPVfm3Ja1q4e6EHKwKAvIsQCgAAAIDXMsbo605fJ1sfqs/kPqwPBQBuQAgFAAAAwKslrg8V4BsgybE+1F1T7mJ9KADIYoRQAAAAALxevTL19GG7D13thbsX6s2lb3quIADIgwihAAAAAEDS/Q3v1x2hd7jary5+lfWhACALEUIBAAAAgBzrQ43qNEpVi1aVxPpQAJDVCKEAAAAAwKlQYCFN7Jl8fai+U/qyPhQAZAFCKAAAAABIon6Z+vqg3Qeu9oLdCzR86XAPVgQAeQMhFAAAAACk8EDDB9QzpKer/eqSV7Vo9yIPVgQAuR8hFAAAAACkkLg+VJWiVSRJCTZBfab00dFzR7NsjtNRpzUpbJLumX6PGn7dUK8uflUXYi9k2fkBIKfx83QBAAAAAJATFQ4qrIm3T1Szb5spJj5GR84dUd+pfTX3rrny9fG94vNZa7X+6HrN2T5Hv+74VX/u/1Px9r+1plYfXq3v13+vTzt+qo7VO2blVwGAHIE7oQAAAAAgDQ3KNtDItiNd7fm75uutZW+le3zSu53KjSynel/V0wsLX9CyfcuSBVCJdp/erVt/ulXdf+6u/Wf2Z8l3AICcwlhrPV0DsokxJiwkJCQkLCzM06UAAAAAuYa1Vnf8cod+2fyLJMnH+GjB3QvUunLrVI+91N1OKZXIX0LtqrZT4cDC+mr1V8mODfYP1qutX9XQxkPl7+uf5d8LAK5UaGioNm/evNlaG5qR8YRQXoQQCgAAAMiYM1FnVP/r+tp1apck6aoCV2ndkHUqXaC0Tked1ryd8zRnxxzN3TFXh88dTvM8RkaNyjVSh2od1KF6BzUs21A+xvGAysajG/XA7Ae0fP/yZGPqlKqjL279QjdUvMF9XxAA0oEQCulGCAUAAABk3OpDq13rQ0lSgzINlM8/X7rudmpfrb06VOugtlXbqkT+Emkem2ATNHbdWD0972mFXwhPtm/AdQP0Tpt3VDK4ZNZ8IQC4QoRQSDdCKAAAACBzPl31qR6Z88glj0l6t1PH6h3VoGwD191O6RV+PlzPL3heo9aMStZfNKio3m7ztu6rf98Vn9PT1hxeoxlbZ6jeVfXUpVYXT5cDIAMIoZBuhFAAAABA5lhr1XNST03+d3Ky/pL5S6pdtXbputvpSqw8sFL3z7pf64+uT9bfuFxjfXHrF6pXpl6WzOMu1lrN3zVf76x4R/N3zXf1T+gxQXfWudODlQHICEIopBshFAAAAJB5Z6PP6vG5j2vvmb1qWamlOlTrkKG7ndIrLiFOn676VC8teknnYs65+n2Mjx5p9Iheu/E1FQos5Ja5MyouIU6TwibpnRXvaN2RdRftLxpUVBsf2Khyhcplf3EAMowQCulGCAUAAADkXgfPHtQTvz+hiWETk/WXKVBGH7T7QHeE3iFjjIeqc4iMidS3a7/VyJUjtef0nov2GxlZOX4GvaXKLZrbd26ue6wQ8GaZDaG42gEAAAAgFyhXqJx+vv1n/db3N1UrVs3Vf/jcYfWa3EvtxrXT9vDtHqnteORxvbLoFVX8sKIenfvoRQFUh2odtKj/In3d6WtX37xd8/T5359nc6UAPIk7obwId0IBAAAAeUNUXJTeWf6Ohi8druj4aFd/gG+Anmv+nJ674Tnl88/n9jp2ndqlkX+O1Ldrv9WFuAvJ9vn5+Kl3nd56qtlTuqb0NZIca0R1/bmrZmydIUkK8gvS2iFrVatELbfXCiDzeBwP6UYIBQAAAOQtO07u0MO/Pqzfdv6WrL9E/hKqd1U91SlVR6ElQ1WnVB2FlAxRwcCCWTLv6kOr9e6KdzVp8yQl2IRk+4L9gzWo/iA93vRxVSxc8aKxxyKPqc7ndXT8/HFJUoMyDfTnvX/K39c/S2oD4D6EUEg3QigAAAAg77HWavK/k/XY3Md0MOLgJY+tXKRysmCqTqk6qlWiloL8gtI1z/xd8zVi+Qgt2L3gov0l85fU0MZD9cD1D6hYvmKXPNeMrTPUZUIXV/ulli/ptRtfu2wNADyLEArpRggFAAAA5F0R0RF6dfGr+njVx4pLiEv3OB/jo2rFqjlCqZJ1XOFUtWLV5O/rf9k33VUrVk1PNX1Kd1979xU9AjhoxiCNXjvaVcPye5arSfkm6R4PIPsRQiHdCKEAAACAvO/E+RNac3iNNh3b5PpsPr5ZkbGRV3Qefx9/1SpRS2ejz2rvmb0X7W9YtqGebf6sutXqJl8f3yuuMyI6Qtd9dZ12ndolyRFmrR2yVgUCClzxuQBkD0IopBshFAAAAOCdEmyC9p7e+18wdXyTwo6F6d8T/yomPuaKztWhWgc90/wZtarUSsaYTNW1fN9ytRzT0rWu1JAGQ/TlbV9m6pwA3IcQCulGCAUAAAAgqbiEOO04ucMVToUdD9OmY5u0PXy74m286zhf46vedXvr6WZPu950l1VeXPCihi8b7mrP7jNbHat3zNI5AGQNQiikGyEUAAAAgPSIiovS1hNbtenYJkXGRqpd1XaqVKSSW+aKiY9Rk9FNtPbIWklS6eDS2vTgJpXIX8It8wHIuMyGUD5ZXRAAAAAAIHcL8gvStVddq7uuuUuDGwx2WwAlSQG+ARrXfZwCfQMlSUcjj2rwzMHihgkg7yGEAgAAAAB4VEjJEI1oM8LVnrplqr5f/70HKwLgDoRQAAAAAACPe6TxI7r56pv/a895RHtO7/FcQQCyHCEUAAAAAMDjfIyPxnQdoyJBRSRJETERunvq3YpPiL/0QAC5BiEUAAAAACBHKF+ovD7v+LmrvXTfUo38c6QHKwKQlQihAAAAAAA5Ru+6vdWrTi9X+8WFL2r9kfUerAhAViGEAgAAAADkKJ91/ExlC5aVJMUmxKrf1H6KiovycFUAMosQCgAAAACQoxTLV0xjuoxxtTce26iXFr7kuYIAZAlCKAAAAABAjnNL1Vv0SKNHXO33/3xfS/Ys8WBFADLLz9MFAAAAAACQmrfbvK15u+Zpy4ktsrK6e9rd2nD/BhUOKpxlc5y6cEpzdszRn/v/VD7/fCqZv6RKBpe8aBvsHyxjTJbNC3gjQigAAAAAQI6U3z+/fuj2g5p+01RxCXHad2afhs4dqjFdx2TqvLtO7dKMrTM0Y+sM/bH3D8Xb+MuOCfILSj2gSiO0KhRYSD6Gh4+ApAihAAAAAAA5VsOyDfVKq1f00iLHmlBj149Vpxqd1COkR7rPkWAT9PfBvzV963TN2DpDYcfDrriOqLgo7T+7X/vP7k/3GB/jI38ff/n5+Mnf11/+Pv7y93W2nb9Oz/4iQUXU95q+al259RXXDeQkxlrr6RqQTYwxYSEhISFhYVf+f7gAAAAA4ClxCXFq8V0LrTywUpJUPF9xbXxgo8oULJPmmPOx57Vg1wLN2DpDM7fN1NHIo2keWyq4lDpU66AA3wAdP39cxyOPu7anok5l+ffJqG61uum9tu+pStEqni4FXio0NFSbN2/ebK0Nzch4QigvQggFAAAAILfacXKHrv3yWp2PPS9J6lCtg2b3mZ1snaaj545q1rZZmrFthubtnKcLcRfSPF9IyRB1rtFZnWt2VqNyjeTr45vqcbHxsQq/EJ4smEq2TdEXfiFcCTYha798EgG+AXqiyRN6ocULKhhY0G3zAKkhhEK6EUIBAAAAyM2+Xv21hswa4mp/3vFztarcyrW+08oDK2WV+s+4vsZXLSq1UOcandWpZidVK1bNLTUm2ASdvHBSkTGRikuIU2xCrGLjY13blH1xCXHJ9qfWN23rNK3YvyLZPFcVuErDbxqu/tf1Z+0pZBtCKKQbIRQAAACA3Mxaq07jO2n29tnpOr5gQEG1r9ZeXWp2UYfqHVQsXzE3V+ge1lpN2DRBz8x/RgfOHki2r0GZBvqw/Ye6oeINHqoO3oQQCulGCAUAAAAgtzty7ojqflFXJ86fSHV/hUIV1Lmm4zG7VpVaKdAvMJsrdJ/zsef1zvJ39M7ydy561PDO0Dv1zi3vqGLhih6qDt6AEArpRggFAAAAIC+YvmW6uk/s7lp7qUGZBq7g6drS1yZbJyov2n9mv56d/6zGbxqfrD/IL0jPNHtGzzR/RsEBwR6qDnkZIRTSjRAKAAAAQF7x14G/tPPUTrWs1FLlC5X3dDkesXzfcg2dO1SrD69O1l+uYDmNaDNCfer2yfOBHLJXZkMoVi8DAAAAAOQ6jcs3Vp+6fbw2gJKk5hWba9WgVfquy3e6qsBVrv6DEQfVd2pfNfu2mVYdXOXBCoHkCKEAAAAAAMilfIyPBlw3QNse3qbnb3heAb4Brn0rD6xU49GN1X9afx2KOOTBKgEHQigAAAAAAHK5goEFNfzm4fr3oX/VvXb3ZPu+X/+9anxSQ2/+8aYuxF5I4wyA+xFCAQAAAACQR1QpWkWT75ishXcv1DWlr3H1R8ZGatiiYar9WW19tuoz/bn/T52NPuvBSuGNWJjci7AwOQAAAAB4j/iEeI1eM1rDFg3TifMnUj2mYuGKqlOqjuqUrKPQUqGqU6qOapeorXz++bK5WuQGvB0P6UYIBQAAAADe53TUab2+5HV9vOpjxSXEXfZ4H+OjqkWrOsKpUnUUWtIRTtUoXkP+vv7ZUDFyKkIopBshFAAAAAB4r23h2/TRyo+05sgahR0LU0RMxBWN9/fxV80SNZPdOdWwbEOvfkOht8lsCOWX1QUBAAAAAICcp0bxGvrs1s8kSdZa7T+7X5uObUr22Xx8s6Ljo1MdH5sQ6zouka/x1Ws3vqYXWryQLd8BuRshFAAAAAAAXsYYo4qFK6pi4YrqWL2jqz8+IV47T+28KJzaFr5N8Tb+ovPE23i9uPBFFQgooEcbP5qdXwG5ECEUAAAAAACQJPn6+KpG8RqqUbyGutfu7uqPjovWtvBt/wVTxzfpz/1/6vj545KkoXOHqni+4rrrmrs8VTpyAR9PF+AJxpiSxpj3jDFbjTEXjDEnjTFrjDHvpnF8J2PMEmPMWednsTHm1svMEWqMmWSMOe6cY6Mx5jFjTJq/58aYosaYj4wxe40x0c7th8aYIpn8ygAAAAAAZFigX6Dqlq6r3nV7682b39T0XtO1dshaVSpcyXXMgOkD9Ov2Xz1YJXI6rwuhjDENJP0r6UlJsZKmS1opqZikx1M5/jFJMyQ1k7Rc0kJJjSTNMsY8nMYcTSX9Lel2Sbuc40tI+kDSBGOMSWVMCUmrJD0qKU7SNEkRkoZK+ssYUyyDXxkAAAAAgCxXrlA5/d7vd5XMX1KSFJcQp9sn3q7l+5Z7uDLkVF4VQhljSkqaKymfpC7W2jrW2l7W2o7W2spyBE1Jj68p6T1J0ZJaWms7WGu7SrpOUrikD4wx1VKM8Zf0o3OOJ6y1ja21d0qqLulPST0l9U+lvA8lVZM0RVJNa+2d1to6kj6RVEPSyMz/DgAAAAAAkHVqFK+hOXfNUcGAgpKkC3EXdNv427Tx6EYPV4acyKtCKEn/k+OOpKettTNS7rTWrkrRNVSSr6QvrbV/Jjlum6Q35VhTa2iKMd0kXS1pvbX2gyRjzklKvHPqyaQDjDFlJPWWFCPpQWttXJLdT0s6LqmvMaZUOr8nAAAAAADZokHZBprea7oCfAMkSaejTqvduHbafWq3hytDTuM1IZQxJp+kvpIiJX2XzmGJ6z79ksq+xL5O6R1jrV0jx+N5dYwxlZPsai/Hf4ul1tqjKcZES5opRxjWUQAAAAAA5DA3Xn2jJvSYIB/nMsiHzx3WLT/coqPnjl5mJLyJ14RQkhpKKihprbX2gjGmgzFmpDHmc+eC4WWTHuxcDLyis7k25cmstfslnZBUyRhTKMmua53bNWnUkdh/TSbHAAAAAACQY3Sr3U1f3/a1q73z1E61/7G9zkSd8WBVyEn8PF1ANgpxbo8ZY6ZJ6pJi/3BjzL3W2vHOdmIAdcpaG5nGOQ/I8XhfJUmJD7xWTLIvrTFyjkmUkTFpMsaEpbGranrGAwAAAACQEffWv1cnzp/QcwuekyStO7JOnSd01ty75iqffz4PVwdP86Y7oYo6t53lePztIUmlJFWWY/HxfJLGGmOucx5XwLk9f4lzJoZTBZP0XW5cVo0BAAAAACDHeab5M3qq6VOu9h97/1Cvyb0UlxB3iVHwBt4UQiV+Vz9JL1trP7fWHrfW7rXWPi1pkiR/ORYCz9WstaGpfSTt9HRtAAAAAIC8zRijd255RwOuG+Dqm7F1hgbNHCRrrecKg8d5Uwh1LsmvU1uYPLGvVYrj81/inMHObUQq86Q1LqvGAAAAAACQIxljNKrTKHWu2dnVN2bdGD0z7xkPVgVP86YQaq9ze95aezyV/Xuc21LO7T7ntqgxJvjiwyVJ5VOcO+m48kpdVo0BAAAAACDH8vPx04QeE9SyUktX33t/vqd3lr/jwargSd4UQiW+4S6fMSYwlf3FnNtzkmStPa3/wqF6KQ82xlSQY1Hyvdbas0l2rXdu66dRR2L/hkyOAQAAAAAgR8vnn08zes3QdVdd5+p7dv6z+mbNN54rCh7jNSGUtXafHGGP0X+P3CWV2Lc2Sd9s5/b2VI5P7JuZoj/NMcaYepKqSNpkrd2TZNdcSQmSWhhjSqUYEyipk6R4Sb+mUgcAAAAAADlW4aDCmnvXXFUrVs3VN3jWYE39d6oHq0qfwxGHNXzpcN015S69vext7T6129Ml5WpeE0I5Jd7z954xpkxip/ONeE86m18mOf4jOcKf+40xTZIcX13Si5LinMckNVXSbknXGmMeTzImWNJnzub7SQdYaw9LGi8pQNLnxhi/FDWXlDTOWnss3d8UAAAAAIAconSB0vq97+8qU8Dxo3iCTVDvyb21aPciD1d2sQSboN93/q4eE3uo4ocV9eLCF/XTxp/0/ILnVeXjKmr6TVN9tPIjHYo45OlScx3jbSvTG2PGSOov6bSkFZLySWomKVDSKGvt4BTHPy5ppByB0zxJMZLaOsc9aq39JJU5mkma7zzmLznWcmohqYykXyTdYVP8xhtjSkhaKamqHG+x+0dSqKQ6krZLamKtPZnJ7x4WEhISEhYWlpnTAAAAAACQIRuPblTLMS11Ouq0JKlgQEEtHrBY9cuktTpN9jl67qi+W/edRq0ZpV2ndl32eCOjVpVbqVdoL/UI6aES+UtkQ5WeFRoaqs2bN2+21oZmZLw3hlBG0n2ShkiqLcnKsdbSV9basWmM6STpaf23NtRaSe9Ya2ddYp5QSf+T1FqOt9vtlPSNpI+stQlpjCkm6VVJXSWVlnRUjjurXnGuUZUphFAAAAAAAE9bvm+5bvnhFl2IuyBJKpm/pJbds0w1itfI9loSbIIW7V6kr1Z/pWlbpik2IfaiYyoUqqDbatymRXsWacuJLamex9f46paqt6h3nd7qUrOLCgcVdnfpHkEIhXQjhAIAAAAA5AS/bv9VXSZ0UVxCnCSpUuFKWn7PcpUrVC5b5j8eeVxj1o3R12u+1o6TOy7a72N8dGv1WzWkwRC1r9Zevj6+stZqw9ENmrBpgiaETdCe03tSPXegb6A6Vu+oXnV66bYatym/f343f5vsQwiFdCOEAgAAAADkFD9u+FF9p/Z1tUNKhmjpwKUqlq/YJUZlnLVWS/Yu0Verv9KUf6coJj7momPKFSyn++rfp3vr3asKhStc8lyrDq7ShE0T9HPYzzp87nCqxwX7B6tzzc7qVaeX2lVtp0C/wCz7Pp5ACIV0I4QCAAAAAOQkH//1sYbOHepqB/kFqXyh8v99CpZP3i5UXiWDS8rHpP89a+HnwzV2/Vh9vfprbQ3fetF+I6P21drr/ob3q2P1jvLz8UvlLGmLT4jX0n1LNWHTBP2y+ReFXwhP9bgiQUXUvVZ39arTSzdefeMVz5MTEEIh3QihAAAAAAA5zUsLX9IbS99I9/H+Pv4qV6jcRUFVhcIVXH2lg0trxf4V+mr1V/pl8y+Kjo++6DxXFbhK99a7V/fVv0+Vi1TOku8SGx+rBbsXaPym8Zr671RFxESkelzJ/CU1tPFQvdjyxSyZN7tkNoTKfbEbAAAAAADIM1678TUl2AS9u+LdVBcGTyk2IVZ7Tu9Jc00myXF3k1XqN920rdpWQxoMUacaneTv65/RslPl7+uv9tXaq3219vrqtq80Z/scTQiboJlbZ7oWYpek4+ePJ2t7C+6E8iLcCQUAAAAAyKnORJ3R3jN7deDsgVQ/+8/u17mYcxk6d6ngUrrnuns0qMEgVSlaJYsrv7xzMec0c+tMTQiboDnb5yg2IVYbH9ioOqXqZHstmcGdUAAAAAAAINcrHFRY1wRdo2tKX5PmMWejz6YZUiV+TkWdch1/89U3a0iDIepSq4sCfAOy42ukqkBAAfWu21u96/bWqQunNG/XvFwXQGUFQigAAAAAAJArFAospJCSIQopGZLmMZExkToYcVCFAgvpqgJXZWN16VM0X1HdEXqHp8vwCEIoAAAAAACQZwQHBKtG8RqeLgOpSP87DQEAAAAAAIAMIoQCAAAAAACA2xFCAQAAAAAAwO0IoQAAAAAAAOB2hFAAAAAAAABwO0IoAAAAAAAAuB0hFAAAAAAAANyOEAoAAAAAAABuRwgFAAAAAAAAtyOEAgAAAAAAgNsRQgEAAAAAAMDtjLXW0zUgmxhjzgYGBhasWrWqp0sBAAAAAAC5zM6dOxUdHR1hrS2UkfGEUF7EGHNEUn5J+7NpysS0a2c2zQfkRFwHgAPXAsB1AEhcB4CUu6+DCpLOW2uvyshgQii4jTEmTJKstaGergXwFK4DwIFrAeA6ACSuA0Dy7uuANaEAAAAAAADgdoRQAAAAAAAAcDtCKAAAAAAAALgdIRQAAAAAAADcjhAKAAAAAAAAbsfb8QAAAAAAAOB23AkFAAAAAAAAtyOEAgAAAAAAgNsRQgEAAAAAAMDtCKEAAAAAAADgdoRQAAAAAAAAcDtCKAAAAAAAALgdIRQAAAAAAADcjhAKWc4Yk88Y85oxZpsxJsoYc8gY860xppynawOyijGmgTHmOWPMFGPMAWOMNcbYdIwbYIxZZYw5Z4w5aYz51RjTLDtqBrKaMSa/MaarMeYbY8xW5//nRxpj1htjXjbGFLjEWK4F5BnGmCecfx5sN8acMcZEG2P2GmO+N8bUvcQ4rgPkWcaY4saYY86/I+24zLFcC8gTjDGLE38uSOPTPo1xXnMNGGsv+zMTkG7GmCBJiyQ1kXRY0lJJlSU1knRcUhNr7S6PFQhkEWPMNEldUvZba80lxnwoaaikC5J+lxQk6WZJRtLt1tppbigVcBtjzH2SRjmb/0raJKmQpGaSCkraIqmVtfZYinEfimsBeYgx5oSkYEkbJB10dodKqiEpVlJ3a+2sFGM+FNcB8jBjzBhJd8vxv+md1tpqaRz3obgWkEcYYxZLaiVpsqRzqRzyvrV2Y4oxH8qLrgFCKGQpY8wbkl6U9Kekttbac87+JyS9L2mJtba15yoEsoYx5lk5fuD42/nZIykwrRDKGNNG0jxJ4ZKaWmu3O/ubSlos6bykq621p91dO5BVjDH95QicPrTW/pukv4yk2ZLqSRpvre2TZB/XAvIcY0xzSauttVEp+h+U9Jmko5LKW2vjnP1cB8jTjDE3S5ov6WtJg5VGCMW1gLwmSQh1tbV2TzqO97prgMfxkGWMMQGSHnY2H0oMoCTJWjtSjn8dbGWMaeCJ+oCsZK0dYa192Vo701p7JB1DnnBu30j8w8V5nj8lfSmpiKR7s75SwH2stWOttUOSBlDO/sOSHnI2uzv/fEjEtYA8x1q7PGUA5ez/XNJOSaUlhSTZxXWAPMsYk0/SV5I2S3rvModzLcDbed01QAiFrNRcUmE5/qVjbSr7f3FuO2VfSYDnOf8ydpOz+Usqh3BtIC9a79wGSioucS3Aa8U6tzES1wG8wiuSqki6X//97/8iXAvwdt56Dfh5ugDkKdc6t2vS2J/Yf0021ALkJDXl+EH8uLX2QCr7uTaQF1VxbmMlnXT+mmsBXsUY00+O/91vd34krgPkYcaYayQ9Kek7a+1SY0zlSxzOtYC87F5jTHFJCZK2SZpmrd2X4hivvAYIoZCVKjq3qV1ASfsrZUMtQE5yyWvDWhtpjDktqagxpqC1NiLbKgPcZ6hzO9daG+38NdcC8jRjzNNyLEgeLKm289eHJPW21sY7D+M6QJ5kjPGRNFrSaUnPpGMI1wLysmEp2u8ZY1631r6epM8rrwEex0NWSnwV9/k09kc6twWzoRYgJ7nctSFxfSAPMcZ0lGP9glhJLyXZxbWAvK6dpP6SbpcjgNorRwC1OskxXAfIqx6RdL2kp6214ek4nmsBedEfkvpJqiopvxx3O70oKU7Sa8aYoUmO9cprgBAKAABkGWNMLUnj5Hit8NPW2vWXGQLkGdbaNs63pBaV1FKOR/CWGGNe9GxlgHsZYypKekOON2GP8XA5gMc4X1w0zlq7y1p7wVq7zVo7XFJX5yGvOteC8lqEUMhKiW/Dy5/G/mDnNk/cRghcgctdGxLXB/IAY0w5SXPl+AF8pLX2oxSHcC3AK1hrT1trl0rqKGm1pNeNMdc7d3MdIC/6TFKAHIuRpxfXAryGtfZ3Sf/I8ba7xs5ur7wGWBMKWSlxobXyaexP7N+bDbUAOcklrw1jTLAcfyCdyivPesP7GGOKSfpdjnX/vpP0VCqHcS3Aq1hrY40xP0tqIMfbjf4W1wHyptvkWAvqS2NM0v4g57acMWax89e9rLVHxLUA77NdUkNJZZxtr7wGCKGQlRIfuaifxv7E/g3ZUAuQk2yVFC2ppDGmnLX2YIr9XBvI1YwxBSTNkRQiaYqkQdZam8qhXAvwRiec25LOLdcB8qoiklqlsS8oyb7EYIprAd6mqHObuM6TV14DPI6HrLRc0hlJVY0x16Wy/3bndma2VQTkANbaC5IWOps9UzmEawO5ljEmUNJ0SY0k/abkbwFLhmsBXirxB++dEtcB8iZrrUntI+lq5yE7k/TvcY7hWoDXMMaUlNTC2Vwjee81YFL/h0ogY4wxb8ix+v8KSW2ttZHO/ickvS/HYoWtPVch4B7GmChJgc6/cKW2v42keZLCJTW11m539jeVtEjSBUlXW2tPZ0/FQOYZY3wlTZLUTdJSSe2ttZd6wwvXAvIcY0xzOd5a9Lu1NiFJv78c6+N8KMe/dNe01u537uM6gFcwxlSWtFuOEKpaKvu5FpBnGGOaSSolaWbSf5BzXgfjJDWXNMNa2yXJPq+7BgihkKWMMUGSFsux2NphOX4oqeRsH5fUxFq7y2MFAlnEGHOrkr96vpEcbwP7K0nf69ba2UnGfChpqByvYZ0nxwKetzjH3W6tnebeqoGs5XzN8IfO5lRJZ9M49ClrbeIjSVwLyFOMMQPkWAfthByLkIdLKiGprhzrfkRJ6m+tnZhi3IfiOkAed7kQynnMh+JaQB6Q5M+DI3Lc7XRajp+FG8jxGGqYpJustcdSjPtQXnQNEEIhyzlfOfm8pD6SKkg6Kcfbkl6y1h7wZG1AVknyh8ylDEz5mmLnuIcl1ZYUI2mlHGHViqyvEnAvY8yrkl5Jx6FXJz5+kWTsAHEtIA8wxlwt6T45HrurIkcAFSNpjxyPWXxsrd2RxtgB4jpAHpaeEMp53ABxLSCXM8bUlvSIHDdgVJBjDahISf/Kcef4F85H8FIbO0Becg0QQgEAAAAAAMDtWJgcAAAAAAAAbkcIBQAAAAAAALcjhAIAAAAAAIDbEUIBAAAAAADA7QihAAAAAAAA4HaEUAAAAAAAAHA7QigAAAAAAAC4HSEUAAAAAAAA3I4QCgAAAAAAAG5HCAUAAAAAAAC3I4QCAAAAAACA2xFCAQAAAAAAwO0IoQAAAPIYY4w1xuzxdB0AAABJEUIBAAB4AWNMa2c4NcbTtQAAAO/k5+kCAAAAkOVqS4r1dBEAAABJEUIBAADkMdbaLZ6uAQAAICUexwMAAMhjUq4J5XwEb5Gz2d+5P/HzaoqxFYwxnxpjdhpjoowxJ40xs4wxzVKZx/WInzHmKmPMaGPMAWNMnDHmMfd9QwAAkBtxJxQAAEDet0zSVZLaSdrpbCdal/gLY0xTSbMlFZW01fnrks5x7Y0xd1lrf07l/CUl/S3H3y2XSQqSdD7LvwUAAMjVjLXW0zUAAAAgCxljrKS91trKSfpay3E31Fhr7YBUxhSStEVSKUn9rbU/JtnXUNLvkvwlVbHWHk9xTkmaKqmPtTYqq78PAADIG3gcDwAAAJJ0j6Qykj5MGkBJkrX2H0mvSyogqW8qY6MlPUIABQAALoUQCgAAAJLU1rmdksb+pc5to1T2rbHWHsz6kgAAQF7CmlAAAACQpMrO7XJjzKWOK5FK374srwYAAOQ5hFAAAACQ/rtD/hdJkZc4bksqfTyGBwAALosQCgAAAJJ0QFJNSW9ba1d7uhgAAJD3sCYUAACAd4hxbtP6R8h5zm23bKgFAAB4IUIoAAAA73DIua2Zxv6vJB2T9IwxZrAxJtnfE40xfsaYdsaYOu4sEgAA5F08jgcAAOAFrLV7jDEbJDU0xqySFCYpXtIMa+0Ma+1pY0wXSTPlCKSGGWM2STol6SpJ9SUVkeNOqU2e+A4AACB3I4QCAADwHj0kvSuphaQGctwVf0DSDEmy1q40xtSV9LikWyW1co47LGmJpKmS5mdzzQAAII8w1lpP1wAAAAAAAIA8jjWhAAAAAAAA4HaEUAAAAAAAAHA7QigAAAAAAAC4HSEUAAAAAAAA3I4QCgAAAAAAAG5HCAUAAAAAAAC3I4QCAAAAAACA2xFCAQAAAAAAwO0IoQAAAAAAAOB2hFAAAAAAAABwO0IoAAAAAAAAuB0hFAAAAAAAANyOEAoAAAAAAABuRwgFAAAAAAAAtyOEAgAAAAAAgNsRQgEAAAAAAMDtCKEAAAAAAADgdv8H/Hf0SM0XIOIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1350x450 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = Logic_Model_Generator()\n",
    "num_sample = 48\n",
    "\n",
    "data = gen.generate_data(num_sample=num_sample, time_horizon=3)\n",
    "#print(data)\n",
    "action_history = {}\n",
    "for i in range(num_sample):\n",
    "    action_history_ = dict([(key, data[i][key]) for key in [3,4,5,6]])\n",
    "    action_history[i] = action_history_\n",
    "#print(data)\n",
    "learn = Logic_Model_Incomplete_Data(time_horizon=1,action_history=action_history,hidden_size=(15,10),output_size=(10,4),batch_size=16)\n",
    "num_iter = 50\n",
    "losses = learn.train_model(temperature=0.8,num_iter=num_iter,lr=(0.01,0.002))\n",
    "\n",
    "X = np.arange(1,num_iter+1,1)\n",
    "plt.figure(figsize=(9,3),dpi=150)\n",
    "plt.plot(X, losses, c='green',label='-$\\mathcal{L}$')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('-$\\mathcal{L}$')\n",
    "plt.legend(bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data has been generated!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.45s/it]\n",
      "  1%|          | 1/100 [00:28<46:46, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 1; loss >> [109883.836]\n",
      "model parameter $\\theta$ >> [tensor([-0.2701], dtype=torch.float64, requires_grad=True), tensor([-0.0166], dtype=torch.float64, requires_grad=True), tensor([0.0366], dtype=torch.float64, requires_grad=True), tensor([-0.2700], dtype=torch.float64, requires_grad=True), tensor([-0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0400], dtype=torch.float64, requires_grad=True), tensor([-0.1700], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1263], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.2794], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5715], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0709], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.49s/it]\n",
      "  2%|▏         | 2/100 [00:56<46:25, 28.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 2; loss >> [102685.65]\n",
      "model parameter $\\theta$ >> [tensor([-0.2401], dtype=torch.float64, requires_grad=True), tensor([-0.0244], dtype=torch.float64, requires_grad=True), tensor([0.0444], dtype=torch.float64, requires_grad=True), tensor([-0.2401], dtype=torch.float64, requires_grad=True), tensor([-0.0396], dtype=torch.float64, requires_grad=True), tensor([0.0696], dtype=torch.float64, requires_grad=True), tensor([-0.1403], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1463], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3082], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5435], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0439], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.33s/it]\n",
      "  3%|▎         | 3/100 [01:24<45:37, 28.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 3; loss >> [105819.74]\n",
      "model parameter $\\theta$ >> [tensor([-0.2100], dtype=torch.float64, requires_grad=True), tensor([-0.0367], dtype=torch.float64, requires_grad=True), tensor([0.0567], dtype=torch.float64, requires_grad=True), tensor([-0.2104], dtype=torch.float64, requires_grad=True), tensor([-0.0697], dtype=torch.float64, requires_grad=True), tensor([0.0997], dtype=torch.float64, requires_grad=True), tensor([-0.1106], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1622], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3372], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5162], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0189], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.37s/it]\n",
      "  4%|▍         | 4/100 [01:52<45:05, 28.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 4; loss >> [99532.914]\n",
      "model parameter $\\theta$ >> [tensor([-0.1804], dtype=torch.float64, requires_grad=True), tensor([-0.0497], dtype=torch.float64, requires_grad=True), tensor([0.0697], dtype=torch.float64, requires_grad=True), tensor([-0.1805], dtype=torch.float64, requires_grad=True), tensor([-0.1001], dtype=torch.float64, requires_grad=True), tensor([0.1301], dtype=torch.float64, requires_grad=True), tensor([-0.0811], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1737], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3659], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4898], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0042], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.46s/it]\n",
      "  5%|▌         | 5/100 [02:21<44:44, 28.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 5; loss >> [102399.04]\n",
      "model parameter $\\theta$ >> [tensor([-0.1507], dtype=torch.float64, requires_grad=True), tensor([-0.0581], dtype=torch.float64, requires_grad=True), tensor([0.0781], dtype=torch.float64, requires_grad=True), tensor([-0.1505], dtype=torch.float64, requires_grad=True), tensor([-0.1306], dtype=torch.float64, requires_grad=True), tensor([0.1606], dtype=torch.float64, requires_grad=True), tensor([-0.0521], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1810], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3933], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4646], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0235], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.47s/it]\n",
      "  6%|▌         | 6/100 [02:49<44:21, 28.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 6; loss >> [98093.65]\n",
      "model parameter $\\theta$ >> [tensor([-0.1215], dtype=torch.float64, requires_grad=True), tensor([-0.0674], dtype=torch.float64, requires_grad=True), tensor([0.0874], dtype=torch.float64, requires_grad=True), tensor([-0.1209], dtype=torch.float64, requires_grad=True), tensor([-0.1604], dtype=torch.float64, requires_grad=True), tensor([0.1904], dtype=torch.float64, requires_grad=True), tensor([-0.0231], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1846], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4209], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4409], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0383], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.29s/it]\n",
      "  7%|▋         | 7/100 [03:17<43:39, 28.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 7; loss >> [96045.38]\n",
      "model parameter $\\theta$ >> [tensor([-0.0926], dtype=torch.float64, requires_grad=True), tensor([-0.0729], dtype=torch.float64, requires_grad=True), tensor([0.0929], dtype=torch.float64, requires_grad=True), tensor([-0.0916], dtype=torch.float64, requires_grad=True), tensor([-0.1901], dtype=torch.float64, requires_grad=True), tensor([0.2201], dtype=torch.float64, requires_grad=True), tensor([0.0058], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1854], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4486], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4192], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0480], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.51s/it]\n",
      "  8%|▊         | 8/100 [03:46<43:22, 28.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 8; loss >> [95896.46]\n",
      "model parameter $\\theta$ >> [tensor([-0.0647], dtype=torch.float64, requires_grad=True), tensor([-0.0874], dtype=torch.float64, requires_grad=True), tensor([0.1074], dtype=torch.float64, requires_grad=True), tensor([-0.0622], dtype=torch.float64, requires_grad=True), tensor([-0.2199], dtype=torch.float64, requires_grad=True), tensor([0.2499], dtype=torch.float64, requires_grad=True), tensor([0.0343], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1840], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4753], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3996], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0534], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.91s/it]\n",
      "  9%|▉         | 9/100 [04:15<43:35, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 9; loss >> [95897.44]\n",
      "model parameter $\\theta$ >> [tensor([-0.0380], dtype=torch.float64, requires_grad=True), tensor([-0.1069], dtype=torch.float64, requires_grad=True), tensor([0.1269], dtype=torch.float64, requires_grad=True), tensor([-0.0328], dtype=torch.float64, requires_grad=True), tensor([-0.2494], dtype=torch.float64, requires_grad=True), tensor([0.2794], dtype=torch.float64, requires_grad=True), tensor([0.0620], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1813], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5014], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3824], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0537], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.63s/it]\n",
      " 10%|█         | 10/100 [04:44<43:11, 28.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 10; loss >> [92994.664]\n",
      "model parameter $\\theta$ >> [tensor([-0.0112], dtype=torch.float64, requires_grad=True), tensor([-0.1284], dtype=torch.float64, requires_grad=True), tensor([0.1484], dtype=torch.float64, requires_grad=True), tensor([-0.0035], dtype=torch.float64, requires_grad=True), tensor([-0.2779], dtype=torch.float64, requires_grad=True), tensor([0.3079], dtype=torch.float64, requires_grad=True), tensor([0.0894], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1781], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5266], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3678], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0511], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:31<00:00, 10.59s/it]\n",
      " 11%|█         | 11/100 [05:16<44:03, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 11; loss >> [91459.22]\n",
      "model parameter $\\theta$ >> [tensor([0.0156], dtype=torch.float64, requires_grad=True), tensor([-0.1524], dtype=torch.float64, requires_grad=True), tensor([0.1724], dtype=torch.float64, requires_grad=True), tensor([0.0251], dtype=torch.float64, requires_grad=True), tensor([-0.3064], dtype=torch.float64, requires_grad=True), tensor([0.3364], dtype=torch.float64, requires_grad=True), tensor([0.1169], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1748], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5516], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3560], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0461], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:31<00:00, 10.57s/it]\n",
      " 12%|█▏        | 12/100 [05:48<44:28, 30.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 12; loss >> [88460.125]\n",
      "model parameter $\\theta$ >> [tensor([0.0424], dtype=torch.float64, requires_grad=True), tensor([-0.1692], dtype=torch.float64, requires_grad=True), tensor([0.1892], dtype=torch.float64, requires_grad=True), tensor([0.0534], dtype=torch.float64, requires_grad=True), tensor([-0.3353], dtype=torch.float64, requires_grad=True), tensor([0.3653], dtype=torch.float64, requires_grad=True), tensor([0.1435], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1719], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5757], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3468], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0394], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.11s/it]\n",
      " 13%|█▎        | 13/100 [06:15<42:39, 29.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 13; loss >> [87305.21]\n",
      "model parameter $\\theta$ >> [tensor([0.0692], dtype=torch.float64, requires_grad=True), tensor([-0.1819], dtype=torch.float64, requires_grad=True), tensor([0.2019], dtype=torch.float64, requires_grad=True), tensor([0.0818], dtype=torch.float64, requires_grad=True), tensor([-0.3647], dtype=torch.float64, requires_grad=True), tensor([0.3947], dtype=torch.float64, requires_grad=True), tensor([0.1696], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1697], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5987], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3401], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0332], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.05s/it]\n",
      " 14%|█▍        | 14/100 [06:42<41:11, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 14; loss >> [91717.33]\n",
      "model parameter $\\theta$ >> [tensor([0.0954], dtype=torch.float64, requires_grad=True), tensor([-0.1922], dtype=torch.float64, requires_grad=True), tensor([0.2122], dtype=torch.float64, requires_grad=True), tensor([0.1101], dtype=torch.float64, requires_grad=True), tensor([-0.3951], dtype=torch.float64, requires_grad=True), tensor([0.4251], dtype=torch.float64, requires_grad=True), tensor([0.1950], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1682], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.6206], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3357], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0277], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.44s/it]\n",
      " 15%|█▌        | 15/100 [07:11<40:32, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 15; loss >> [86126.58]\n",
      "model parameter $\\theta$ >> [tensor([0.1202], dtype=torch.float64, requires_grad=True), tensor([-0.2042], dtype=torch.float64, requires_grad=True), tensor([0.2242], dtype=torch.float64, requires_grad=True), tensor([0.1384], dtype=torch.float64, requires_grad=True), tensor([-0.4247], dtype=torch.float64, requires_grad=True), tensor([0.4547], dtype=torch.float64, requires_grad=True), tensor([0.2201], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1674], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.6424], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3334], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0246], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.09s/it]\n",
      " 16%|█▌        | 16/100 [07:38<39:29, 28.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 16; loss >> [86090.195]\n",
      "model parameter $\\theta$ >> [tensor([0.1447], dtype=torch.float64, requires_grad=True), tensor([-0.2134], dtype=torch.float64, requires_grad=True), tensor([0.2334], dtype=torch.float64, requires_grad=True), tensor([0.1658], dtype=torch.float64, requires_grad=True), tensor([-0.4544], dtype=torch.float64, requires_grad=True), tensor([0.4844], dtype=torch.float64, requires_grad=True), tensor([0.2450], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1673], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.6639], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3327], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0228], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.53s/it]\n",
      " 17%|█▋        | 17/100 [08:07<39:11, 28.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 17; loss >> [85800.89]\n",
      "model parameter $\\theta$ >> [tensor([0.1691], dtype=torch.float64, requires_grad=True), tensor([-0.2181], dtype=torch.float64, requires_grad=True), tensor([0.2381], dtype=torch.float64, requires_grad=True), tensor([0.1924], dtype=torch.float64, requires_grad=True), tensor([-0.4827], dtype=torch.float64, requires_grad=True), tensor([0.5127], dtype=torch.float64, requires_grad=True), tensor([0.2694], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1676], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.6842], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3333], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0217], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.17s/it]\n",
      " 18%|█▊        | 18/100 [08:34<38:22, 28.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 18; loss >> [83701.3]\n",
      "model parameter $\\theta$ >> [tensor([0.1927], dtype=torch.float64, requires_grad=True), tensor([-0.2281], dtype=torch.float64, requires_grad=True), tensor([0.2481], dtype=torch.float64, requires_grad=True), tensor([0.2187], dtype=torch.float64, requires_grad=True), tensor([-0.5103], dtype=torch.float64, requires_grad=True), tensor([0.5403], dtype=torch.float64, requires_grad=True), tensor([0.2931], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1683], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.7038], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3348], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0219], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.12s/it]\n",
      " 19%|█▉        | 19/100 [09:01<37:37, 27.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 19; loss >> [80076.51]\n",
      "model parameter $\\theta$ >> [tensor([0.2158], dtype=torch.float64, requires_grad=True), tensor([-0.2360], dtype=torch.float64, requires_grad=True), tensor([0.2560], dtype=torch.float64, requires_grad=True), tensor([0.2440], dtype=torch.float64, requires_grad=True), tensor([-0.5383], dtype=torch.float64, requires_grad=True), tensor([0.5683], dtype=torch.float64, requires_grad=True), tensor([0.3157], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1691], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.7217], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3370], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0207], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.33s/it]\n",
      " 20%|██        | 20/100 [09:29<37:12, 27.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 20; loss >> [82001.16]\n",
      "model parameter $\\theta$ >> [tensor([0.2374], dtype=torch.float64, requires_grad=True), tensor([-0.2474], dtype=torch.float64, requires_grad=True), tensor([0.2674], dtype=torch.float64, requires_grad=True), tensor([0.2690], dtype=torch.float64, requires_grad=True), tensor([-0.5652], dtype=torch.float64, requires_grad=True), tensor([0.5952], dtype=torch.float64, requires_grad=True), tensor([0.3378], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1699], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.7393], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3395], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0210], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:31<00:00, 10.41s/it]\n",
      " 21%|██        | 21/100 [10:01<38:03, 28.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 21; loss >> [81820.484]\n",
      "model parameter $\\theta$ >> [tensor([0.2575], dtype=torch.float64, requires_grad=True), tensor([-0.2606], dtype=torch.float64, requires_grad=True), tensor([0.2806], dtype=torch.float64, requires_grad=True), tensor([0.2934], dtype=torch.float64, requires_grad=True), tensor([-0.5922], dtype=torch.float64, requires_grad=True), tensor([0.6222], dtype=torch.float64, requires_grad=True), tensor([0.3597], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1706], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.7568], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3420], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0222], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.56s/it]\n",
      " 22%|██▏       | 22/100 [10:29<37:29, 28.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 22; loss >> [82642.13]\n",
      "model parameter $\\theta$ >> [tensor([0.2787], dtype=torch.float64, requires_grad=True), tensor([-0.2754], dtype=torch.float64, requires_grad=True), tensor([0.2954], dtype=torch.float64, requires_grad=True), tensor([0.3169], dtype=torch.float64, requires_grad=True), tensor([-0.6200], dtype=torch.float64, requires_grad=True), tensor([0.6500], dtype=torch.float64, requires_grad=True), tensor([0.3800], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1711], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.7726], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3445], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0213], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.85s/it]\n",
      " 23%|██▎       | 23/100 [10:59<37:17, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 23; loss >> [77722.875]\n",
      "model parameter $\\theta$ >> [tensor([0.3006], dtype=torch.float64, requires_grad=True), tensor([-0.2868], dtype=torch.float64, requires_grad=True), tensor([0.3068], dtype=torch.float64, requires_grad=True), tensor([0.3402], dtype=torch.float64, requires_grad=True), tensor([-0.6480], dtype=torch.float64, requires_grad=True), tensor([0.6780], dtype=torch.float64, requires_grad=True), tensor([0.3995], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1715], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.7871], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3467], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0199], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.57s/it]\n",
      " 24%|██▍       | 24/100 [11:28<36:41, 28.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 24; loss >> [86233.48]\n",
      "model parameter $\\theta$ >> [tensor([0.3220], dtype=torch.float64, requires_grad=True), tensor([-0.2975], dtype=torch.float64, requires_grad=True), tensor([0.3175], dtype=torch.float64, requires_grad=True), tensor([0.3630], dtype=torch.float64, requires_grad=True), tensor([-0.6753], dtype=torch.float64, requires_grad=True), tensor([0.7053], dtype=torch.float64, requires_grad=True), tensor([0.4178], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1716], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8006], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3485], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0182], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n",
      " 25%|██▌       | 25/100 [11:56<36:03, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 25; loss >> [80541.1]\n",
      "model parameter $\\theta$ >> [tensor([0.3418], dtype=torch.float64, requires_grad=True), tensor([-0.3136], dtype=torch.float64, requires_grad=True), tensor([0.3336], dtype=torch.float64, requires_grad=True), tensor([0.3863], dtype=torch.float64, requires_grad=True), tensor([-0.7014], dtype=torch.float64, requires_grad=True), tensor([0.7314], dtype=torch.float64, requires_grad=True), tensor([0.4354], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1716], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8142], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0186], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.49s/it]\n",
      " 26%|██▌       | 26/100 [12:25<35:26, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 26; loss >> [78110.83]\n",
      "model parameter $\\theta$ >> [tensor([0.3592], dtype=torch.float64, requires_grad=True), tensor([-0.3379], dtype=torch.float64, requires_grad=True), tensor([0.3579], dtype=torch.float64, requires_grad=True), tensor([0.4086], dtype=torch.float64, requires_grad=True), tensor([-0.7274], dtype=torch.float64, requires_grad=True), tensor([0.7574], dtype=torch.float64, requires_grad=True), tensor([0.4527], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1715], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8275], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3510], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0187], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.48s/it]\n",
      " 27%|██▋       | 27/100 [12:53<34:51, 28.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 27; loss >> [77881.195]\n",
      "model parameter $\\theta$ >> [tensor([0.3754], dtype=torch.float64, requires_grad=True), tensor([-0.3624], dtype=torch.float64, requires_grad=True), tensor([0.3824], dtype=torch.float64, requires_grad=True), tensor([0.4305], dtype=torch.float64, requires_grad=True), tensor([-0.7540], dtype=torch.float64, requires_grad=True), tensor([0.7840], dtype=torch.float64, requires_grad=True), tensor([0.4690], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1714], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8398], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3518], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0184], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.92s/it]\n",
      " 28%|██▊       | 28/100 [13:23<34:47, 28.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 28; loss >> [78156.125]\n",
      "model parameter $\\theta$ >> [tensor([0.3904], dtype=torch.float64, requires_grad=True), tensor([-0.3823], dtype=torch.float64, requires_grad=True), tensor([0.4023], dtype=torch.float64, requires_grad=True), tensor([0.4519], dtype=torch.float64, requires_grad=True), tensor([-0.7791], dtype=torch.float64, requires_grad=True), tensor([0.8091], dtype=torch.float64, requires_grad=True), tensor([0.4849], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1712], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8522], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3521], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0191], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.54s/it]\n",
      " 29%|██▉       | 29/100 [13:52<34:10, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 29; loss >> [79291.89]\n",
      "model parameter $\\theta$ >> [tensor([0.4049], dtype=torch.float64, requires_grad=True), tensor([-0.4013], dtype=torch.float64, requires_grad=True), tensor([0.4213], dtype=torch.float64, requires_grad=True), tensor([0.4728], dtype=torch.float64, requires_grad=True), tensor([-0.8038], dtype=torch.float64, requires_grad=True), tensor([0.8338], dtype=torch.float64, requires_grad=True), tensor([0.4998], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1710], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8640], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3523], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0185], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:32<00:00, 10.79s/it]\n",
      " 30%|███       | 30/100 [14:24<34:55, 29.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 30; loss >> [74542.88]\n",
      "model parameter $\\theta$ >> [tensor([0.4199], dtype=torch.float64, requires_grad=True), tensor([-0.4078], dtype=torch.float64, requires_grad=True), tensor([0.4278], dtype=torch.float64, requires_grad=True), tensor([0.4923], dtype=torch.float64, requires_grad=True), tensor([-0.8287], dtype=torch.float64, requires_grad=True), tensor([0.8587], dtype=torch.float64, requires_grad=True), tensor([0.5132], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8751], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3522], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0149], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.78s/it]\n",
      " 31%|███       | 31/100 [14:53<34:13, 29.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 31; loss >> [75302.59]\n",
      "model parameter $\\theta$ >> [tensor([0.4349], dtype=torch.float64, requires_grad=True), tensor([-0.4122], dtype=torch.float64, requires_grad=True), tensor([0.4322], dtype=torch.float64, requires_grad=True), tensor([0.5114], dtype=torch.float64, requires_grad=True), tensor([-0.8538], dtype=torch.float64, requires_grad=True), tensor([0.8838], dtype=torch.float64, requires_grad=True), tensor([0.5246], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1707], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8841], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3519], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0106], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.90s/it]\n",
      " 32%|███▏      | 32/100 [15:23<33:42, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 32; loss >> [76565.58]\n",
      "model parameter $\\theta$ >> [tensor([0.4509], dtype=torch.float64, requires_grad=True), tensor([-0.4196], dtype=torch.float64, requires_grad=True), tensor([0.4396], dtype=torch.float64, requires_grad=True), tensor([0.5301], dtype=torch.float64, requires_grad=True), tensor([-0.8776], dtype=torch.float64, requires_grad=True), tensor([0.9076], dtype=torch.float64, requires_grad=True), tensor([0.5347], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1706], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.8921], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3516], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0079], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.57s/it]\n",
      " 33%|███▎      | 33/100 [15:52<32:52, 29.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 33; loss >> [76293.43]\n",
      "model parameter $\\theta$ >> [tensor([0.4667], dtype=torch.float64, requires_grad=True), tensor([-0.4195], dtype=torch.float64, requires_grad=True), tensor([0.4395], dtype=torch.float64, requires_grad=True), tensor([0.5481], dtype=torch.float64, requires_grad=True), tensor([-0.9004], dtype=torch.float64, requires_grad=True), tensor([0.9304], dtype=torch.float64, requires_grad=True), tensor([0.5441], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1706], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9006], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3512], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0062], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.62s/it]\n",
      " 34%|███▍      | 34/100 [16:21<32:11, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 34; loss >> [77916.16]\n",
      "model parameter $\\theta$ >> [tensor([0.4811], dtype=torch.float64, requires_grad=True), tensor([-0.4223], dtype=torch.float64, requires_grad=True), tensor([0.4423], dtype=torch.float64, requires_grad=True), tensor([0.5651], dtype=torch.float64, requires_grad=True), tensor([-0.9224], dtype=torch.float64, requires_grad=True), tensor([0.9524], dtype=torch.float64, requires_grad=True), tensor([0.5544], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1706], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9093], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3509], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0073], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n",
      " 35%|███▌      | 35/100 [16:49<31:28, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 35; loss >> [75232.47]\n",
      "model parameter $\\theta$ >> [tensor([0.4940], dtype=torch.float64, requires_grad=True), tensor([-0.4312], dtype=torch.float64, requires_grad=True), tensor([0.4512], dtype=torch.float64, requires_grad=True), tensor([0.5818], dtype=torch.float64, requires_grad=True), tensor([-0.9443], dtype=torch.float64, requires_grad=True), tensor([0.9743], dtype=torch.float64, requires_grad=True), tensor([0.5628], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1706], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9168], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3505], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0083], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.55s/it]\n",
      " 36%|███▌      | 36/100 [17:18<30:52, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 36; loss >> [75507.05]\n",
      "model parameter $\\theta$ >> [tensor([0.5065], dtype=torch.float64, requires_grad=True), tensor([-0.4441], dtype=torch.float64, requires_grad=True), tensor([0.4641], dtype=torch.float64, requires_grad=True), tensor([0.5978], dtype=torch.float64, requires_grad=True), tensor([-0.9665], dtype=torch.float64, requires_grad=True), tensor([0.9965], dtype=torch.float64, requires_grad=True), tensor([0.5690], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1706], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9233], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3502], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0073], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.34s/it]\n",
      " 37%|███▋      | 37/100 [17:46<30:05, 28.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 37; loss >> [77600.72]\n",
      "model parameter $\\theta$ >> [tensor([0.5186], dtype=torch.float64, requires_grad=True), tensor([-0.4552], dtype=torch.float64, requires_grad=True), tensor([0.4752], dtype=torch.float64, requires_grad=True), tensor([0.6135], dtype=torch.float64, requires_grad=True), tensor([-0.9894], dtype=torch.float64, requires_grad=True), tensor([1.0194], dtype=torch.float64, requires_grad=True), tensor([0.5737], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1707], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9285], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0060], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.13s/it]\n",
      " 38%|███▊      | 38/100 [18:13<29:13, 28.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 38; loss >> [76399.13]\n",
      "model parameter $\\theta$ >> [tensor([0.5295], dtype=torch.float64, requires_grad=True), tensor([-0.4645], dtype=torch.float64, requires_grad=True), tensor([0.4845], dtype=torch.float64, requires_grad=True), tensor([0.6289], dtype=torch.float64, requires_grad=True), tensor([-1.0110], dtype=torch.float64, requires_grad=True), tensor([1.0410], dtype=torch.float64, requires_grad=True), tensor([0.5775], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1707], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9338], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3498], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0051], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.09s/it]\n",
      " 39%|███▉      | 39/100 [18:41<28:27, 27.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 39; loss >> [75982.45]\n",
      "model parameter $\\theta$ >> [tensor([0.5372], dtype=torch.float64, requires_grad=True), tensor([-0.4780], dtype=torch.float64, requires_grad=True), tensor([0.4980], dtype=torch.float64, requires_grad=True), tensor([0.6432], dtype=torch.float64, requires_grad=True), tensor([-1.0310], dtype=torch.float64, requires_grad=True), tensor([1.0610], dtype=torch.float64, requires_grad=True), tensor([0.5814], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9391], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3497], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0043], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.11s/it]\n",
      " 40%|████      | 40/100 [19:08<27:47, 27.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 40; loss >> [76299.336]\n",
      "model parameter $\\theta$ >> [tensor([0.5423], dtype=torch.float64, requires_grad=True), tensor([-0.4903], dtype=torch.float64, requires_grad=True), tensor([0.5103], dtype=torch.float64, requires_grad=True), tensor([0.6561], dtype=torch.float64, requires_grad=True), tensor([-1.0500], dtype=torch.float64, requires_grad=True), tensor([1.0800], dtype=torch.float64, requires_grad=True), tensor([0.5866], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9448], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3496], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0043], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.22s/it]\n",
      " 41%|████      | 41/100 [19:36<27:17, 27.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 41; loss >> [75378.16]\n",
      "model parameter $\\theta$ >> [tensor([0.5442], dtype=torch.float64, requires_grad=True), tensor([-0.5045], dtype=torch.float64, requires_grad=True), tensor([0.5245], dtype=torch.float64, requires_grad=True), tensor([0.6674], dtype=torch.float64, requires_grad=True), tensor([-1.0678], dtype=torch.float64, requires_grad=True), tensor([1.0978], dtype=torch.float64, requires_grad=True), tensor([0.5920], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9504], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3496], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0042], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.72s/it]\n",
      " 42%|████▏     | 42/100 [20:05<27:14, 28.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 42; loss >> [76683.445]\n",
      "model parameter $\\theta$ >> [tensor([0.5450], dtype=torch.float64, requires_grad=True), tensor([-0.5160], dtype=torch.float64, requires_grad=True), tensor([0.5360], dtype=torch.float64, requires_grad=True), tensor([0.6779], dtype=torch.float64, requires_grad=True), tensor([-1.0866], dtype=torch.float64, requires_grad=True), tensor([1.1166], dtype=torch.float64, requires_grad=True), tensor([0.5985], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9566], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3496], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0056], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.06s/it]\n",
      " 43%|████▎     | 43/100 [20:32<26:29, 27.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 43; loss >> [77576.07]\n",
      "model parameter $\\theta$ >> [tensor([0.5433], dtype=torch.float64, requires_grad=True), tensor([-0.5280], dtype=torch.float64, requires_grad=True), tensor([0.5480], dtype=torch.float64, requires_grad=True), tensor([0.6883], dtype=torch.float64, requires_grad=True), tensor([-1.1049], dtype=torch.float64, requires_grad=True), tensor([1.1349], dtype=torch.float64, requires_grad=True), tensor([0.6048], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9631], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3496], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0085], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.09s/it]\n",
      " 44%|████▍     | 44/100 [21:02<26:42, 28.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 44; loss >> [74256.73]\n",
      "model parameter $\\theta$ >> [tensor([0.5385], dtype=torch.float64, requires_grad=True), tensor([-0.5413], dtype=torch.float64, requires_grad=True), tensor([0.5613], dtype=torch.float64, requires_grad=True), tensor([0.6991], dtype=torch.float64, requires_grad=True), tensor([-1.1240], dtype=torch.float64, requires_grad=True), tensor([1.1540], dtype=torch.float64, requires_grad=True), tensor([0.6112], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9698], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3497], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0126], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.30s/it]\n",
      " 45%|████▌     | 45/100 [21:33<26:51, 29.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 45; loss >> [74932.88]\n",
      "model parameter $\\theta$ >> [tensor([0.5319], dtype=torch.float64, requires_grad=True), tensor([-0.5516], dtype=torch.float64, requires_grad=True), tensor([0.5716], dtype=torch.float64, requires_grad=True), tensor([0.7099], dtype=torch.float64, requires_grad=True), tensor([-1.1426], dtype=torch.float64, requires_grad=True), tensor([1.1726], dtype=torch.float64, requires_grad=True), tensor([0.6172], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9755], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3497], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0167], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.58s/it]\n",
      " 46%|████▌     | 46/100 [22:02<26:12, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 46; loss >> [74973.95]\n",
      "model parameter $\\theta$ >> [tensor([0.5261], dtype=torch.float64, requires_grad=True), tensor([-0.5616], dtype=torch.float64, requires_grad=True), tensor([0.5816], dtype=torch.float64, requires_grad=True), tensor([0.7197], dtype=torch.float64, requires_grad=True), tensor([-1.1610], dtype=torch.float64, requires_grad=True), tensor([1.1910], dtype=torch.float64, requires_grad=True), tensor([0.6228], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9822], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3498], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0188], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.71s/it]\n",
      " 47%|████▋     | 47/100 [22:31<25:44, 29.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 47; loss >> [75253.41]\n",
      "model parameter $\\theta$ >> [tensor([0.5216], dtype=torch.float64, requires_grad=True), tensor([-0.5724], dtype=torch.float64, requires_grad=True), tensor([0.5924], dtype=torch.float64, requires_grad=True), tensor([0.7294], dtype=torch.float64, requires_grad=True), tensor([-1.1800], dtype=torch.float64, requires_grad=True), tensor([1.2100], dtype=torch.float64, requires_grad=True), tensor([0.6279], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9892], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0204], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.71s/it]\n",
      " 48%|████▊     | 48/100 [23:00<25:15, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 48; loss >> [74445.72]\n",
      "model parameter $\\theta$ >> [tensor([0.5188], dtype=torch.float64, requires_grad=True), tensor([-0.5756], dtype=torch.float64, requires_grad=True), tensor([0.5956], dtype=torch.float64, requires_grad=True), tensor([0.7388], dtype=torch.float64, requires_grad=True), tensor([-1.1987], dtype=torch.float64, requires_grad=True), tensor([1.2287], dtype=torch.float64, requires_grad=True), tensor([0.6324], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.9957], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0210], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.61s/it]\n",
      " 49%|████▉     | 49/100 [23:29<24:41, 29.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 49; loss >> [74563.43]\n",
      "model parameter $\\theta$ >> [tensor([0.5157], dtype=torch.float64, requires_grad=True), tensor([-0.5806], dtype=torch.float64, requires_grad=True), tensor([0.6006], dtype=torch.float64, requires_grad=True), tensor([0.7479], dtype=torch.float64, requires_grad=True), tensor([-1.2174], dtype=torch.float64, requires_grad=True), tensor([1.2474], dtype=torch.float64, requires_grad=True), tensor([0.6372], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0025], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0213], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.56s/it]\n",
      " 50%|█████     | 50/100 [23:58<24:07, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 50; loss >> [75855.93]\n",
      "model parameter $\\theta$ >> [tensor([0.5130], dtype=torch.float64, requires_grad=True), tensor([-0.5828], dtype=torch.float64, requires_grad=True), tensor([0.6028], dtype=torch.float64, requires_grad=True), tensor([0.7559], dtype=torch.float64, requires_grad=True), tensor([-1.2367], dtype=torch.float64, requires_grad=True), tensor([1.2667], dtype=torch.float64, requires_grad=True), tensor([0.6422], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0098], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0204], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.51s/it]\n",
      " 51%|█████     | 51/100 [24:26<23:32, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 51; loss >> [75032.125]\n",
      "model parameter $\\theta$ >> [tensor([0.5097], dtype=torch.float64, requires_grad=True), tensor([-0.5856], dtype=torch.float64, requires_grad=True), tensor([0.6056], dtype=torch.float64, requires_grad=True), tensor([0.7648], dtype=torch.float64, requires_grad=True), tensor([-1.2564], dtype=torch.float64, requires_grad=True), tensor([1.2864], dtype=torch.float64, requires_grad=True), tensor([0.6454], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0155], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0195], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.55s/it]\n",
      " 52%|█████▏    | 52/100 [24:55<23:01, 28.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 52; loss >> [74810.36]\n",
      "model parameter $\\theta$ >> [tensor([0.5065], dtype=torch.float64, requires_grad=True), tensor([-0.5873], dtype=torch.float64, requires_grad=True), tensor([0.6073], dtype=torch.float64, requires_grad=True), tensor([0.7733], dtype=torch.float64, requires_grad=True), tensor([-1.2748], dtype=torch.float64, requires_grad=True), tensor([1.3048], dtype=torch.float64, requires_grad=True), tensor([0.6471], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0196], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0174], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00, 10.00s/it]\n",
      " 53%|█████▎    | 53/100 [25:25<22:49, 29.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 53; loss >> [76211.82]\n",
      "model parameter $\\theta$ >> [tensor([0.5047], dtype=torch.float64, requires_grad=True), tensor([-0.5942], dtype=torch.float64, requires_grad=True), tensor([0.6142], dtype=torch.float64, requires_grad=True), tensor([0.7813], dtype=torch.float64, requires_grad=True), tensor([-1.2926], dtype=torch.float64, requires_grad=True), tensor([1.3226], dtype=torch.float64, requires_grad=True), tensor([0.6482], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0235], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0144], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.53s/it]\n",
      " 54%|█████▍    | 54/100 [25:54<22:13, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 54; loss >> [76945.43]\n",
      "model parameter $\\theta$ >> [tensor([0.5026], dtype=torch.float64, requires_grad=True), tensor([-0.6028], dtype=torch.float64, requires_grad=True), tensor([0.6228], dtype=torch.float64, requires_grad=True), tensor([0.7885], dtype=torch.float64, requires_grad=True), tensor([-1.3113], dtype=torch.float64, requires_grad=True), tensor([1.3413], dtype=torch.float64, requires_grad=True), tensor([0.6500], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0287], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0128], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.51s/it]\n",
      " 55%|█████▌    | 55/100 [26:22<21:38, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 55; loss >> [74818.266]\n",
      "model parameter $\\theta$ >> [tensor([0.5025], dtype=torch.float64, requires_grad=True), tensor([-0.6103], dtype=torch.float64, requires_grad=True), tensor([0.6303], dtype=torch.float64, requires_grad=True), tensor([0.7945], dtype=torch.float64, requires_grad=True), tensor([-1.3297], dtype=torch.float64, requires_grad=True), tensor([1.3597], dtype=torch.float64, requires_grad=True), tensor([0.6515], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0338], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0101], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.56s/it]\n",
      " 56%|█████▌    | 56/100 [26:51<21:07, 28.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 56; loss >> [74086.03]\n",
      "model parameter $\\theta$ >> [tensor([0.5035], dtype=torch.float64, requires_grad=True), tensor([-0.6130], dtype=torch.float64, requires_grad=True), tensor([0.6330], dtype=torch.float64, requires_grad=True), tensor([0.7995], dtype=torch.float64, requires_grad=True), tensor([-1.3482], dtype=torch.float64, requires_grad=True), tensor([1.3782], dtype=torch.float64, requires_grad=True), tensor([0.6526], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0378], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0077], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.55s/it]\n",
      " 57%|█████▋    | 57/100 [27:19<20:36, 28.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 57; loss >> [76151.37]\n",
      "model parameter $\\theta$ >> [tensor([0.5048], dtype=torch.float64, requires_grad=True), tensor([-0.6121], dtype=torch.float64, requires_grad=True), tensor([0.6321], dtype=torch.float64, requires_grad=True), tensor([0.8053], dtype=torch.float64, requires_grad=True), tensor([-1.3663], dtype=torch.float64, requires_grad=True), tensor([1.3963], dtype=torch.float64, requires_grad=True), tensor([0.6530], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0413], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0079], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.54s/it]\n",
      " 58%|█████▊    | 58/100 [27:48<20:06, 28.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 58; loss >> [75995.42]\n",
      "model parameter $\\theta$ >> [tensor([0.5062], dtype=torch.float64, requires_grad=True), tensor([-0.6136], dtype=torch.float64, requires_grad=True), tensor([0.6336], dtype=torch.float64, requires_grad=True), tensor([0.8107], dtype=torch.float64, requires_grad=True), tensor([-1.3839], dtype=torch.float64, requires_grad=True), tensor([1.4139], dtype=torch.float64, requires_grad=True), tensor([0.6534], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0447], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0097], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.83s/it]\n",
      " 59%|█████▉    | 59/100 [28:18<19:46, 28.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 59; loss >> [75936.36]\n",
      "model parameter $\\theta$ >> [tensor([0.5078], dtype=torch.float64, requires_grad=True), tensor([-0.6166], dtype=torch.float64, requires_grad=True), tensor([0.6366], dtype=torch.float64, requires_grad=True), tensor([0.8152], dtype=torch.float64, requires_grad=True), tensor([-1.4005], dtype=torch.float64, requires_grad=True), tensor([1.4305], dtype=torch.float64, requires_grad=True), tensor([0.6544], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0484], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0115], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n",
      " 60%|██████    | 60/100 [28:46<19:13, 28.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 60; loss >> [77408.7]\n",
      "model parameter $\\theta$ >> [tensor([0.5073], dtype=torch.float64, requires_grad=True), tensor([-0.6251], dtype=torch.float64, requires_grad=True), tensor([0.6451], dtype=torch.float64, requires_grad=True), tensor([0.8193], dtype=torch.float64, requires_grad=True), tensor([-1.4170], dtype=torch.float64, requires_grad=True), tensor([1.4470], dtype=torch.float64, requires_grad=True), tensor([0.6564], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0540], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0137], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.62s/it]\n",
      " 61%|██████    | 61/100 [29:15<18:44, 28.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 61; loss >> [74543.65]\n",
      "model parameter $\\theta$ >> [tensor([0.5067], dtype=torch.float64, requires_grad=True), tensor([-0.6331], dtype=torch.float64, requires_grad=True), tensor([0.6531], dtype=torch.float64, requires_grad=True), tensor([0.8230], dtype=torch.float64, requires_grad=True), tensor([-1.4336], dtype=torch.float64, requires_grad=True), tensor([1.4636], dtype=torch.float64, requires_grad=True), tensor([0.6577], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0585], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0151], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.62s/it]\n",
      " 62%|██████▏   | 62/100 [29:44<18:16, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 62; loss >> [75729.42]\n",
      "model parameter $\\theta$ >> [tensor([0.5061], dtype=torch.float64, requires_grad=True), tensor([-0.6423], dtype=torch.float64, requires_grad=True), tensor([0.6623], dtype=torch.float64, requires_grad=True), tensor([0.8271], dtype=torch.float64, requires_grad=True), tensor([-1.4498], dtype=torch.float64, requires_grad=True), tensor([1.4798], dtype=torch.float64, requires_grad=True), tensor([0.6571], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0610], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0146], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.09s/it]\n",
      " 63%|██████▎   | 63/100 [30:11<17:29, 28.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 63; loss >> [73359.375]\n",
      "model parameter $\\theta$ >> [tensor([0.5060], dtype=torch.float64, requires_grad=True), tensor([-0.6541], dtype=torch.float64, requires_grad=True), tensor([0.6741], dtype=torch.float64, requires_grad=True), tensor([0.8311], dtype=torch.float64, requires_grad=True), tensor([-1.4652], dtype=torch.float64, requires_grad=True), tensor([1.4952], dtype=torch.float64, requires_grad=True), tensor([0.6560], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0633], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0142], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:32<00:00, 10.68s/it]\n",
      " 64%|██████▍   | 64/100 [30:43<17:41, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 64; loss >> [75453.45]\n",
      "model parameter $\\theta$ >> [tensor([0.5064], dtype=torch.float64, requires_grad=True), tensor([-0.6646], dtype=torch.float64, requires_grad=True), tensor([0.6846], dtype=torch.float64, requires_grad=True), tensor([0.8341], dtype=torch.float64, requires_grad=True), tensor([-1.4802], dtype=torch.float64, requires_grad=True), tensor([1.5102], dtype=torch.float64, requires_grad=True), tensor([0.6541], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0644], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0122], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:31<00:00, 10.63s/it]\n",
      " 65%|██████▌   | 65/100 [31:15<17:37, 30.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 65; loss >> [76106.47]\n",
      "model parameter $\\theta$ >> [tensor([0.5058], dtype=torch.float64, requires_grad=True), tensor([-0.6768], dtype=torch.float64, requires_grad=True), tensor([0.6968], dtype=torch.float64, requires_grad=True), tensor([0.8357], dtype=torch.float64, requires_grad=True), tensor([-1.4946], dtype=torch.float64, requires_grad=True), tensor([1.5246], dtype=torch.float64, requires_grad=True), tensor([0.6525], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0662], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0090], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.13s/it]\n",
      " 66%|██████▌   | 66/100 [31:45<17:09, 30.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 66; loss >> [75057.234]\n",
      "model parameter $\\theta$ >> [tensor([0.5080], dtype=torch.float64, requires_grad=True), tensor([-0.6850], dtype=torch.float64, requires_grad=True), tensor([0.7050], dtype=torch.float64, requires_grad=True), tensor([0.8358], dtype=torch.float64, requires_grad=True), tensor([-1.5084], dtype=torch.float64, requires_grad=True), tensor([1.5384], dtype=torch.float64, requires_grad=True), tensor([0.6509], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0676], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0050], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.55s/it]\n",
      " 67%|██████▋   | 67/100 [32:14<16:22, 29.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 67; loss >> [77212.055]\n",
      "model parameter $\\theta$ >> [tensor([0.5128], dtype=torch.float64, requires_grad=True), tensor([-0.6961], dtype=torch.float64, requires_grad=True), tensor([0.7161], dtype=torch.float64, requires_grad=True), tensor([0.8363], dtype=torch.float64, requires_grad=True), tensor([-1.5215], dtype=torch.float64, requires_grad=True), tensor([1.5515], dtype=torch.float64, requires_grad=True), tensor([0.6490], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0685], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0024], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.53s/it]\n",
      " 68%|██████▊   | 68/100 [32:43<15:41, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 68; loss >> [74625.07]\n",
      "model parameter $\\theta$ >> [tensor([0.5148], dtype=torch.float64, requires_grad=True), tensor([-0.7104], dtype=torch.float64, requires_grad=True), tensor([0.7304], dtype=torch.float64, requires_grad=True), tensor([0.8380], dtype=torch.float64, requires_grad=True), tensor([-1.5344], dtype=torch.float64, requires_grad=True), tensor([1.5644], dtype=torch.float64, requires_grad=True), tensor([0.6470], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0701], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0025], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.57s/it]\n",
      " 69%|██████▉   | 69/100 [33:11<15:05, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 69; loss >> [78238.38]\n",
      "model parameter $\\theta$ >> [tensor([0.5148], dtype=torch.float64, requires_grad=True), tensor([-0.7205], dtype=torch.float64, requires_grad=True), tensor([0.7405], dtype=torch.float64, requires_grad=True), tensor([0.8390], dtype=torch.float64, requires_grad=True), tensor([-1.5469], dtype=torch.float64, requires_grad=True), tensor([1.5769], dtype=torch.float64, requires_grad=True), tensor([0.6455], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0710], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0032], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n",
      " 70%|███████   | 70/100 [33:40<14:30, 29.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 70; loss >> [76641.516]\n",
      "model parameter $\\theta$ >> [tensor([0.5147], dtype=torch.float64, requires_grad=True), tensor([-0.7302], dtype=torch.float64, requires_grad=True), tensor([0.7502], dtype=torch.float64, requires_grad=True), tensor([0.8387], dtype=torch.float64, requires_grad=True), tensor([-1.5591], dtype=torch.float64, requires_grad=True), tensor([1.5891], dtype=torch.float64, requires_grad=True), tensor([0.6445], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0721], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3499], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0032], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n",
      " 71%|███████   | 71/100 [34:09<13:57, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 71; loss >> [77992.18]\n",
      "model parameter $\\theta$ >> [tensor([0.5140], dtype=torch.float64, requires_grad=True), tensor([-0.7401], dtype=torch.float64, requires_grad=True), tensor([0.7601], dtype=torch.float64, requires_grad=True), tensor([0.8380], dtype=torch.float64, requires_grad=True), tensor([-1.5708], dtype=torch.float64, requires_grad=True), tensor([1.6008], dtype=torch.float64, requires_grad=True), tensor([0.6452], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0742], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0050], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n",
      " 72%|███████▏  | 72/100 [34:37<13:26, 28.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 72; loss >> [76481.19]\n",
      "model parameter $\\theta$ >> [tensor([0.5115], dtype=torch.float64, requires_grad=True), tensor([-0.7478], dtype=torch.float64, requires_grad=True), tensor([0.7678], dtype=torch.float64, requires_grad=True), tensor([0.8377], dtype=torch.float64, requires_grad=True), tensor([-1.5826], dtype=torch.float64, requires_grad=True), tensor([1.6126], dtype=torch.float64, requires_grad=True), tensor([0.6461], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0770], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0077], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.98s/it]\n",
      " 73%|███████▎  | 73/100 [35:07<13:06, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 73; loss >> [76549.4]\n",
      "model parameter $\\theta$ >> [tensor([0.5079], dtype=torch.float64, requires_grad=True), tensor([-0.7566], dtype=torch.float64, requires_grad=True), tensor([0.7766], dtype=torch.float64, requires_grad=True), tensor([0.8389], dtype=torch.float64, requires_grad=True), tensor([-1.5948], dtype=torch.float64, requires_grad=True), tensor([1.6248], dtype=torch.float64, requires_grad=True), tensor([0.6469], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0794], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0123], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.08s/it]\n",
      " 74%|███████▍  | 74/100 [35:37<12:46, 29.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 74; loss >> [75788.63]\n",
      "model parameter $\\theta$ >> [tensor([0.5037], dtype=torch.float64, requires_grad=True), tensor([-0.7686], dtype=torch.float64, requires_grad=True), tensor([0.7886], dtype=torch.float64, requires_grad=True), tensor([0.8391], dtype=torch.float64, requires_grad=True), tensor([-1.6068], dtype=torch.float64, requires_grad=True), tensor([1.6368], dtype=torch.float64, requires_grad=True), tensor([0.6493], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0821], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0165], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.58s/it]\n",
      " 75%|███████▌  | 75/100 [36:06<12:11, 29.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 75; loss >> [77418.69]\n",
      "model parameter $\\theta$ >> [tensor([0.5012], dtype=torch.float64, requires_grad=True), tensor([-0.7793], dtype=torch.float64, requires_grad=True), tensor([0.7993], dtype=torch.float64, requires_grad=True), tensor([0.8375], dtype=torch.float64, requires_grad=True), tensor([-1.6184], dtype=torch.float64, requires_grad=True), tensor([1.6484], dtype=torch.float64, requires_grad=True), tensor([0.6523], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0860], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0175], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.57s/it]\n",
      " 76%|███████▌  | 76/100 [36:35<11:38, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 76; loss >> [77230.54]\n",
      "model parameter $\\theta$ >> [tensor([0.4979], dtype=torch.float64, requires_grad=True), tensor([-0.7871], dtype=torch.float64, requires_grad=True), tensor([0.8071], dtype=torch.float64, requires_grad=True), tensor([0.8357], dtype=torch.float64, requires_grad=True), tensor([-1.6290], dtype=torch.float64, requires_grad=True), tensor([1.6590], dtype=torch.float64, requires_grad=True), tensor([0.6565], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0918], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0180], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.54s/it]\n",
      " 77%|███████▋  | 77/100 [37:03<11:05, 28.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 77; loss >> [74672.68]\n",
      "model parameter $\\theta$ >> [tensor([0.4941], dtype=torch.float64, requires_grad=True), tensor([-0.7925], dtype=torch.float64, requires_grad=True), tensor([0.8125], dtype=torch.float64, requires_grad=True), tensor([0.8346], dtype=torch.float64, requires_grad=True), tensor([-1.6396], dtype=torch.float64, requires_grad=True), tensor([1.6696], dtype=torch.float64, requires_grad=True), tensor([0.6602], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.0963], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0178], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.55s/it]\n",
      " 78%|███████▊  | 78/100 [37:32<10:35, 28.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 78; loss >> [77196.68]\n",
      "model parameter $\\theta$ >> [tensor([0.4926], dtype=torch.float64, requires_grad=True), tensor([-0.7985], dtype=torch.float64, requires_grad=True), tensor([0.8185], dtype=torch.float64, requires_grad=True), tensor([0.8338], dtype=torch.float64, requires_grad=True), tensor([-1.6496], dtype=torch.float64, requires_grad=True), tensor([1.6796], dtype=torch.float64, requires_grad=True), tensor([0.6627], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1006], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0155], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.62s/it]\n",
      " 79%|███████▉  | 79/100 [38:01<10:06, 28.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 79; loss >> [75879.97]\n",
      "model parameter $\\theta$ >> [tensor([0.4918], dtype=torch.float64, requires_grad=True), tensor([-0.8023], dtype=torch.float64, requires_grad=True), tensor([0.8223], dtype=torch.float64, requires_grad=True), tensor([0.8325], dtype=torch.float64, requires_grad=True), tensor([-1.6601], dtype=torch.float64, requires_grad=True), tensor([1.6901], dtype=torch.float64, requires_grad=True), tensor([0.6650], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1045], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0125], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.51s/it]\n",
      " 80%|████████  | 80/100 [38:29<09:35, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 80; loss >> [75760.96]\n",
      "model parameter $\\theta$ >> [tensor([0.4907], dtype=torch.float64, requires_grad=True), tensor([-0.8083], dtype=torch.float64, requires_grad=True), tensor([0.8283], dtype=torch.float64, requires_grad=True), tensor([0.8308], dtype=torch.float64, requires_grad=True), tensor([-1.6704], dtype=torch.float64, requires_grad=True), tensor([1.7004], dtype=torch.float64, requires_grad=True), tensor([0.6668], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1078], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0090], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n",
      " 81%|████████  | 81/100 [38:58<09:05, 28.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 81; loss >> [76959.984]\n",
      "model parameter $\\theta$ >> [tensor([0.4914], dtype=torch.float64, requires_grad=True), tensor([-0.8161], dtype=torch.float64, requires_grad=True), tensor([0.8361], dtype=torch.float64, requires_grad=True), tensor([0.8288], dtype=torch.float64, requires_grad=True), tensor([-1.6811], dtype=torch.float64, requires_grad=True), tensor([1.7111], dtype=torch.float64, requires_grad=True), tensor([0.6683], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1105], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0065], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.46s/it]\n",
      " 82%|████████▏ | 82/100 [39:26<08:35, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 82; loss >> [76175.11]\n",
      "model parameter $\\theta$ >> [tensor([0.4904], dtype=torch.float64, requires_grad=True), tensor([-0.8244], dtype=torch.float64, requires_grad=True), tensor([0.8444], dtype=torch.float64, requires_grad=True), tensor([0.8280], dtype=torch.float64, requires_grad=True), tensor([-1.6916], dtype=torch.float64, requires_grad=True), tensor([1.7216], dtype=torch.float64, requires_grad=True), tensor([0.6689], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1122], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0060], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.06s/it]\n",
      " 83%|████████▎ | 83/100 [39:54<07:59, 28.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 83; loss >> [77106.81]\n",
      "model parameter $\\theta$ >> [tensor([0.4882], dtype=torch.float64, requires_grad=True), tensor([-0.8294], dtype=torch.float64, requires_grad=True), tensor([0.8494], dtype=torch.float64, requires_grad=True), tensor([0.8276], dtype=torch.float64, requires_grad=True), tensor([-1.7021], dtype=torch.float64, requires_grad=True), tensor([1.7321], dtype=torch.float64, requires_grad=True), tensor([0.6693], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1136], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0067], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.08s/it]\n",
      " 84%|████████▍ | 84/100 [40:21<07:26, 27.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 84; loss >> [76875.33]\n",
      "model parameter $\\theta$ >> [tensor([0.4856], dtype=torch.float64, requires_grad=True), tensor([-0.8354], dtype=torch.float64, requires_grad=True), tensor([0.8554], dtype=torch.float64, requires_grad=True), tensor([0.8283], dtype=torch.float64, requires_grad=True), tensor([-1.7120], dtype=torch.float64, requires_grad=True), tensor([1.7420], dtype=torch.float64, requires_grad=True), tensor([0.6704], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1150], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0108], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.05s/it]\n",
      " 85%|████████▌ | 85/100 [40:48<06:55, 27.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 85; loss >> [76786.484]\n",
      "model parameter $\\theta$ >> [tensor([0.4829], dtype=torch.float64, requires_grad=True), tensor([-0.8352], dtype=torch.float64, requires_grad=True), tensor([0.8552], dtype=torch.float64, requires_grad=True), tensor([0.8304], dtype=torch.float64, requires_grad=True), tensor([-1.7215], dtype=torch.float64, requires_grad=True), tensor([1.7515], dtype=torch.float64, requires_grad=True), tensor([0.6705], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1161], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0155], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.78s/it]\n",
      " 86%|████████▌ | 86/100 [41:17<06:34, 28.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 86; loss >> [76290.71]\n",
      "model parameter $\\theta$ >> [tensor([0.4812], dtype=torch.float64, requires_grad=True), tensor([-0.8358], dtype=torch.float64, requires_grad=True), tensor([0.8558], dtype=torch.float64, requires_grad=True), tensor([0.8330], dtype=torch.float64, requires_grad=True), tensor([-1.7310], dtype=torch.float64, requires_grad=True), tensor([1.7610], dtype=torch.float64, requires_grad=True), tensor([0.6704], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1169], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0193], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.10s/it]\n",
      " 87%|████████▋ | 87/100 [41:45<06:02, 27.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 87; loss >> [76886.12]\n",
      "model parameter $\\theta$ >> [tensor([0.4798], dtype=torch.float64, requires_grad=True), tensor([-0.8375], dtype=torch.float64, requires_grad=True), tensor([0.8575], dtype=torch.float64, requires_grad=True), tensor([0.8363], dtype=torch.float64, requires_grad=True), tensor([-1.7403], dtype=torch.float64, requires_grad=True), tensor([1.7703], dtype=torch.float64, requires_grad=True), tensor([0.6695], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1167], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0223], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.32s/it]\n",
      " 88%|████████▊ | 88/100 [42:13<05:35, 27.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 88; loss >> [74431.766]\n",
      "model parameter $\\theta$ >> [tensor([0.4797], dtype=torch.float64, requires_grad=True), tensor([-0.8438], dtype=torch.float64, requires_grad=True), tensor([0.8638], dtype=torch.float64, requires_grad=True), tensor([0.8391], dtype=torch.float64, requires_grad=True), tensor([-1.7494], dtype=torch.float64, requires_grad=True), tensor([1.7794], dtype=torch.float64, requires_grad=True), tensor([0.6695], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1180], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0240], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.06s/it]\n",
      " 89%|████████▉ | 89/100 [42:40<05:04, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 89; loss >> [75976.21]\n",
      "model parameter $\\theta$ >> [tensor([0.4803], dtype=torch.float64, requires_grad=True), tensor([-0.8505], dtype=torch.float64, requires_grad=True), tensor([0.8705], dtype=torch.float64, requires_grad=True), tensor([0.8421], dtype=torch.float64, requires_grad=True), tensor([-1.7584], dtype=torch.float64, requires_grad=True), tensor([1.7884], dtype=torch.float64, requires_grad=True), tensor([0.6692], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1183], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0240], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.66s/it]\n",
      " 90%|█████████ | 90/100 [43:09<04:41, 28.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 90; loss >> [77793.516]\n",
      "model parameter $\\theta$ >> [tensor([0.4797], dtype=torch.float64, requires_grad=True), tensor([-0.8554], dtype=torch.float64, requires_grad=True), tensor([0.8754], dtype=torch.float64, requires_grad=True), tensor([0.8454], dtype=torch.float64, requires_grad=True), tensor([-1.7671], dtype=torch.float64, requires_grad=True), tensor([1.7971], dtype=torch.float64, requires_grad=True), tensor([0.6683], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1177], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0228], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.09s/it]\n",
      " 91%|█████████ | 91/100 [43:39<04:18, 28.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 91; loss >> [76007.664]\n",
      "model parameter $\\theta$ >> [tensor([0.4813], dtype=torch.float64, requires_grad=True), tensor([-0.8635], dtype=torch.float64, requires_grad=True), tensor([0.8835], dtype=torch.float64, requires_grad=True), tensor([0.8477], dtype=torch.float64, requires_grad=True), tensor([-1.7763], dtype=torch.float64, requires_grad=True), tensor([1.8063], dtype=torch.float64, requires_grad=True), tensor([0.6685], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1187], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0209], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:32<00:00, 10.96s/it]\n",
      " 92%|█████████▏| 92/100 [44:12<03:59, 29.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 92; loss >> [74091.125]\n",
      "model parameter $\\theta$ >> [tensor([0.4842], dtype=torch.float64, requires_grad=True), tensor([-0.8655], dtype=torch.float64, requires_grad=True), tensor([0.8855], dtype=torch.float64, requires_grad=True), tensor([0.8495], dtype=torch.float64, requires_grad=True), tensor([-1.7849], dtype=torch.float64, requires_grad=True), tensor([1.8149], dtype=torch.float64, requires_grad=True), tensor([0.6700], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1204], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0194], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.66s/it]\n",
      " 93%|█████████▎| 93/100 [44:41<03:27, 29.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 93; loss >> [73464.37]\n",
      "model parameter $\\theta$ >> [tensor([0.4862], dtype=torch.float64, requires_grad=True), tensor([-0.8681], dtype=torch.float64, requires_grad=True), tensor([0.8881], dtype=torch.float64, requires_grad=True), tensor([0.8528], dtype=torch.float64, requires_grad=True), tensor([-1.7932], dtype=torch.float64, requires_grad=True), tensor([1.8232], dtype=torch.float64, requires_grad=True), tensor([0.6712], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1217], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0200], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.74s/it]\n",
      " 94%|█████████▍| 94/100 [45:10<02:57, 29.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 94; loss >> [75116.65]\n",
      "model parameter $\\theta$ >> [tensor([0.4902], dtype=torch.float64, requires_grad=True), tensor([-0.8723], dtype=torch.float64, requires_grad=True), tensor([0.8923], dtype=torch.float64, requires_grad=True), tensor([0.8565], dtype=torch.float64, requires_grad=True), tensor([-1.8014], dtype=torch.float64, requires_grad=True), tensor([1.8314], dtype=torch.float64, requires_grad=True), tensor([0.6705], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1209], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0200], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.52s/it]\n",
      " 95%|█████████▌| 95/100 [45:39<02:26, 29.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 95; loss >> [76151.664]\n",
      "model parameter $\\theta$ >> [tensor([0.4956], dtype=torch.float64, requires_grad=True), tensor([-0.8777], dtype=torch.float64, requires_grad=True), tensor([0.8977], dtype=torch.float64, requires_grad=True), tensor([0.8580], dtype=torch.float64, requires_grad=True), tensor([-1.8097], dtype=torch.float64, requires_grad=True), tensor([1.8397], dtype=torch.float64, requires_grad=True), tensor([0.6709], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1213], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0186], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.55s/it]\n",
      " 96%|█████████▌| 96/100 [46:07<01:56, 29.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 96; loss >> [76212.4]\n",
      "model parameter $\\theta$ >> [tensor([0.5012], dtype=torch.float64, requires_grad=True), tensor([-0.8831], dtype=torch.float64, requires_grad=True), tensor([0.9031], dtype=torch.float64, requires_grad=True), tensor([0.8588], dtype=torch.float64, requires_grad=True), tensor([-1.8179], dtype=torch.float64, requires_grad=True), tensor([1.8479], dtype=torch.float64, requires_grad=True), tensor([0.6708], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1210], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0164], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.79s/it]\n",
      " 97%|█████████▋| 97/100 [46:37<01:27, 29.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 97; loss >> [76482.67]\n",
      "model parameter $\\theta$ >> [tensor([0.5089], dtype=torch.float64, requires_grad=True), tensor([-0.8862], dtype=torch.float64, requires_grad=True), tensor([0.9062], dtype=torch.float64, requires_grad=True), tensor([0.8575], dtype=torch.float64, requires_grad=True), tensor([-1.8265], dtype=torch.float64, requires_grad=True), tensor([1.8565], dtype=torch.float64, requires_grad=True), tensor([0.6704], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1213], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0120], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.94s/it]\n",
      " 98%|█████████▊| 98/100 [47:07<00:58, 29.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 98; loss >> [76789.6]\n",
      "model parameter $\\theta$ >> [tensor([0.5181], dtype=torch.float64, requires_grad=True), tensor([-0.8943], dtype=torch.float64, requires_grad=True), tensor([0.9143], dtype=torch.float64, requires_grad=True), tensor([0.8553], dtype=torch.float64, requires_grad=True), tensor([-1.8348], dtype=torch.float64, requires_grad=True), tensor([1.8648], dtype=torch.float64, requires_grad=True), tensor([0.6683], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1215], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0065], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.21s/it]\n",
      " 99%|█████████▉| 99/100 [47:37<00:29, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 99; loss >> [75677.64]\n",
      "model parameter $\\theta$ >> [tensor([0.5247], dtype=torch.float64, requires_grad=True), tensor([-0.9079], dtype=torch.float64, requires_grad=True), tensor([0.9279], dtype=torch.float64, requires_grad=True), tensor([0.8537], dtype=torch.float64, requires_grad=True), tensor([-1.8433], dtype=torch.float64, requires_grad=True), tensor([1.8733], dtype=torch.float64, requires_grad=True), tensor([0.6659], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1234], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0032], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.80s/it]\n",
      "100%|██████████| 100/100 [48:07<00:00, 28.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 100; loss >> [76981.195]\n",
      "model parameter $\\theta$ >> [tensor([0.5294], dtype=torch.float64, requires_grad=True), tensor([-0.9166], dtype=torch.float64, requires_grad=True), tensor([0.9366], dtype=torch.float64, requires_grad=True), tensor([0.8537], dtype=torch.float64, requires_grad=True), tensor([-1.8510], dtype=torch.float64, requires_grad=True), tensor([1.8810], dtype=torch.float64, requires_grad=True), tensor([0.6630], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-1.1237], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3500], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0028], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1350x450 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LSTM_a = LSTM_Encoding_Action(input_size = 4, hidden_size = 15, output_size= 8, batch_size=5, device='cuda').cuda()\n",
    "LSTM_m = LSTM_Encoding_History(input_size = 10, hidden_size = 8, output_size = 4, batch_size=5, device='cuda').cuda()\n",
    "a = torch.rand(size=(5,4,4)).cuda() # batch, num_predicate, length\n",
    "h_a = LSTM_a.forward(a)\n",
    "m = torch.rand(size=(5,3,10)).cuda()\n",
    "prob = LSTM_m.forward(m,h_a)\n",
    "\n",
    "logits = torch.log(prob)\n",
    "def generate_incomplete_data(num_sample:int=10, time_horizon:float=5.0):\n",
    "        gen = Logic_Model_Generator()\n",
    "        data = gen.generate_data(num_sample=num_sample, time_horizon=time_horizon)\n",
    "        action_history = {}\n",
    "        for i in range(num_sample):\n",
    "            action_history_ = dict([(key, data[i][key]) for key in [3,4,5,6]])\n",
    "            action_history[i] = action_history_\n",
    "        #NOTE: info\n",
    "        print('[INFO] data has been generated!!!')\n",
    "        return action_history\n",
    "\n",
    "action_history = generate_incomplete_data(num_sample=90,time_horizon=4.0)\n",
    "learn = Logic_Model_Incomplete_Data(time_horizon=4.0,action_history=action_history,hidden_size=(15,8),output_size=(8,4),batch_size=30)\n",
    "losses = learn.train_model(num_iter=100,lr=(0.01,0.002))\n",
    "learn.plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data has been generated!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "  3%|▎         | 1/30 [00:01<00:53,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 1; loss >> [5721.6094]\n",
      "model parameter $\\theta$ >> [tensor([-0.2900], dtype=torch.float64, requires_grad=True), tensor([-6.8343e-11], dtype=torch.float64, requires_grad=True), tensor([0.0200], dtype=torch.float64, requires_grad=True), tensor([-0.2900], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([0.0200], dtype=torch.float64, requires_grad=True), tensor([-0.1900], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1100], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.2600], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5900], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0900], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "  7%|▋         | 2/30 [00:03<00:47,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 2; loss >> [5627.7397]\n",
      "model parameter $\\theta$ >> [tensor([-0.2800], dtype=torch.float64, requires_grad=True), tensor([0.0054], dtype=torch.float64, requires_grad=True), tensor([0.0146], dtype=torch.float64, requires_grad=True), tensor([-0.2800], dtype=torch.float64, requires_grad=True), tensor([0.0003], dtype=torch.float64, requires_grad=True), tensor([0.0297], dtype=torch.float64, requires_grad=True), tensor([-0.1800], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1200], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.2700], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5800], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0800], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      " 10%|█         | 3/30 [00:05<00:44,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 3; loss >> [5340.889]\n",
      "model parameter $\\theta$ >> [tensor([-0.2700], dtype=torch.float64, requires_grad=True), tensor([0.0122], dtype=torch.float64, requires_grad=True), tensor([0.0078], dtype=torch.float64, requires_grad=True), tensor([-0.2702], dtype=torch.float64, requires_grad=True), tensor([-0.0091], dtype=torch.float64, requires_grad=True), tensor([0.0391], dtype=torch.float64, requires_grad=True), tensor([-0.1701], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1299], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.2798], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5700], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0700], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      " 13%|█▎        | 4/30 [00:06<00:45,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 4; loss >> [5546.9023]\n",
      "model parameter $\\theta$ >> [tensor([-0.2599], dtype=torch.float64, requires_grad=True), tensor([0.0134], dtype=torch.float64, requires_grad=True), tensor([0.0066], dtype=torch.float64, requires_grad=True), tensor([-0.2605], dtype=torch.float64, requires_grad=True), tensor([-0.0183], dtype=torch.float64, requires_grad=True), tensor([0.0483], dtype=torch.float64, requires_grad=True), tensor([-0.1601], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1397], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.2897], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5601], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0601], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      " 17%|█▋        | 5/30 [00:08<00:43,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 5; loss >> [5303.4546]\n",
      "model parameter $\\theta$ >> [tensor([-0.2499], dtype=torch.float64, requires_grad=True), tensor([0.0174], dtype=torch.float64, requires_grad=True), tensor([0.0026], dtype=torch.float64, requires_grad=True), tensor([-0.2506], dtype=torch.float64, requires_grad=True), tensor([-0.0277], dtype=torch.float64, requires_grad=True), tensor([0.0577], dtype=torch.float64, requires_grad=True), tensor([-0.1502], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1495], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.2996], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5501], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0501], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      " 20%|██        | 6/30 [00:10<00:40,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 6; loss >> [5490.371]\n",
      "model parameter $\\theta$ >> [tensor([-0.2399], dtype=torch.float64, requires_grad=True), tensor([0.0224], dtype=torch.float64, requires_grad=True), tensor([-0.0024], dtype=torch.float64, requires_grad=True), tensor([-0.2407], dtype=torch.float64, requires_grad=True), tensor([-0.0359], dtype=torch.float64, requires_grad=True), tensor([0.0659], dtype=torch.float64, requires_grad=True), tensor([-0.1403], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1591], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3094], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5402], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0402], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      " 23%|██▎       | 7/30 [00:11<00:38,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 7; loss >> [5091.1123]\n",
      "model parameter $\\theta$ >> [tensor([-0.2299], dtype=torch.float64, requires_grad=True), tensor([0.0264], dtype=torch.float64, requires_grad=True), tensor([-0.0064], dtype=torch.float64, requires_grad=True), tensor([-0.2308], dtype=torch.float64, requires_grad=True), tensor([-0.0427], dtype=torch.float64, requires_grad=True), tensor([0.0727], dtype=torch.float64, requires_grad=True), tensor([-0.1305], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1686], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3191], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5303], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0303], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      " 27%|██▋       | 8/30 [00:13<00:36,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 8; loss >> [5050.7686]\n",
      "model parameter $\\theta$ >> [tensor([-0.2200], dtype=torch.float64, requires_grad=True), tensor([0.0309], dtype=torch.float64, requires_grad=True), tensor([-0.0109], dtype=torch.float64, requires_grad=True), tensor([-0.2208], dtype=torch.float64, requires_grad=True), tensor([-0.0503], dtype=torch.float64, requires_grad=True), tensor([0.0803], dtype=torch.float64, requires_grad=True), tensor([-0.1207], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1778], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3287], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5205], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0203], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      " 30%|███       | 9/30 [00:15<00:36,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 9; loss >> [5273.241]\n",
      "model parameter $\\theta$ >> [tensor([-0.2100], dtype=torch.float64, requires_grad=True), tensor([0.0367], dtype=torch.float64, requires_grad=True), tensor([-0.0167], dtype=torch.float64, requires_grad=True), tensor([-0.2109], dtype=torch.float64, requires_grad=True), tensor([-0.0582], dtype=torch.float64, requires_grad=True), tensor([0.0882], dtype=torch.float64, requires_grad=True), tensor([-0.1108], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1869], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3385], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5107], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0104], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      " 33%|███▎      | 10/30 [00:17<00:35,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 10; loss >> [5208.8926]\n",
      "model parameter $\\theta$ >> [tensor([-0.2002], dtype=torch.float64, requires_grad=True), tensor([0.0396], dtype=torch.float64, requires_grad=True), tensor([-0.0196], dtype=torch.float64, requires_grad=True), tensor([-0.2009], dtype=torch.float64, requires_grad=True), tensor([-0.0666], dtype=torch.float64, requires_grad=True), tensor([0.0966], dtype=torch.float64, requires_grad=True), tensor([-0.1009], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.1956], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3483], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.5009], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([-0.0005], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      " 37%|███▋      | 11/30 [00:18<00:33,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 11; loss >> [4887.9937]\n",
      "model parameter $\\theta$ >> [tensor([-0.1903], dtype=torch.float64, requires_grad=True), tensor([0.0425], dtype=torch.float64, requires_grad=True), tensor([-0.0225], dtype=torch.float64, requires_grad=True), tensor([-0.1909], dtype=torch.float64, requires_grad=True), tensor([-0.0749], dtype=torch.float64, requires_grad=True), tensor([0.1049], dtype=torch.float64, requires_grad=True), tensor([-0.0910], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2041], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3580], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4913], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0094], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      " 40%|████      | 12/30 [00:20<00:32,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 12; loss >> [4727.06]\n",
      "model parameter $\\theta$ >> [tensor([-0.1804], dtype=torch.float64, requires_grad=True), tensor([0.0444], dtype=torch.float64, requires_grad=True), tensor([-0.0244], dtype=torch.float64, requires_grad=True), tensor([-0.1809], dtype=torch.float64, requires_grad=True), tensor([-0.0838], dtype=torch.float64, requires_grad=True), tensor([0.1138], dtype=torch.float64, requires_grad=True), tensor([-0.0812], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2122], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3676], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4817], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0192], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      " 43%|████▎     | 13/30 [00:23<00:32,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 13; loss >> [4640.6973]\n",
      "model parameter $\\theta$ >> [tensor([-0.1704], dtype=torch.float64, requires_grad=True), tensor([0.0440], dtype=torch.float64, requires_grad=True), tensor([-0.0240], dtype=torch.float64, requires_grad=True), tensor([-0.1708], dtype=torch.float64, requires_grad=True), tensor([-0.0930], dtype=torch.float64, requires_grad=True), tensor([0.1230], dtype=torch.float64, requires_grad=True), tensor([-0.0714], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2199], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3768], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4721], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0291], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      " 47%|████▋     | 14/30 [00:25<00:31,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 14; loss >> [4562.0625]\n",
      "model parameter $\\theta$ >> [tensor([-0.1604], dtype=torch.float64, requires_grad=True), tensor([0.0450], dtype=torch.float64, requires_grad=True), tensor([-0.0250], dtype=torch.float64, requires_grad=True), tensor([-0.1608], dtype=torch.float64, requires_grad=True), tensor([-0.1021], dtype=torch.float64, requires_grad=True), tensor([0.1321], dtype=torch.float64, requires_grad=True), tensor([-0.0617], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2272], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3861], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4627], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0390], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      " 50%|█████     | 15/30 [00:27<00:29,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 15; loss >> [4636.545]\n",
      "model parameter $\\theta$ >> [tensor([-0.1505], dtype=torch.float64, requires_grad=True), tensor([0.0433], dtype=torch.float64, requires_grad=True), tensor([-0.0233], dtype=torch.float64, requires_grad=True), tensor([-0.1507], dtype=torch.float64, requires_grad=True), tensor([-0.1113], dtype=torch.float64, requires_grad=True), tensor([0.1413], dtype=torch.float64, requires_grad=True), tensor([-0.0520], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2339], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.3951], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4533], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0488], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      " 53%|█████▎    | 16/30 [00:28<00:26,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 16; loss >> [4536.619]\n",
      "model parameter $\\theta$ >> [tensor([-0.1405], dtype=torch.float64, requires_grad=True), tensor([0.0419], dtype=torch.float64, requires_grad=True), tensor([-0.0219], dtype=torch.float64, requires_grad=True), tensor([-0.1407], dtype=torch.float64, requires_grad=True), tensor([-0.1209], dtype=torch.float64, requires_grad=True), tensor([0.1509], dtype=torch.float64, requires_grad=True), tensor([-0.0422], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2402], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4041], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4440], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0586], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      " 57%|█████▋    | 17/30 [00:30<00:23,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 17; loss >> [4608.754]\n",
      "model parameter $\\theta$ >> [tensor([-0.1306], dtype=torch.float64, requires_grad=True), tensor([0.0386], dtype=torch.float64, requires_grad=True), tensor([-0.0186], dtype=torch.float64, requires_grad=True), tensor([-0.1307], dtype=torch.float64, requires_grad=True), tensor([-0.1297], dtype=torch.float64, requires_grad=True), tensor([0.1597], dtype=torch.float64, requires_grad=True), tensor([-0.0324], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2460], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4132], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4348], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0684], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      " 60%|██████    | 18/30 [00:32<00:21,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 18; loss >> [4565.411]\n",
      "model parameter $\\theta$ >> [tensor([-0.1206], dtype=torch.float64, requires_grad=True), tensor([0.0372], dtype=torch.float64, requires_grad=True), tensor([-0.0172], dtype=torch.float64, requires_grad=True), tensor([-0.1208], dtype=torch.float64, requires_grad=True), tensor([-0.1389], dtype=torch.float64, requires_grad=True), tensor([0.1689], dtype=torch.float64, requires_grad=True), tensor([-0.0226], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2511], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4225], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4258], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0782], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      " 63%|██████▎   | 19/30 [00:33<00:19,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 19; loss >> [4432.659]\n",
      "model parameter $\\theta$ >> [tensor([-0.1107], dtype=torch.float64, requires_grad=True), tensor([0.0350], dtype=torch.float64, requires_grad=True), tensor([-0.0150], dtype=torch.float64, requires_grad=True), tensor([-0.1109], dtype=torch.float64, requires_grad=True), tensor([-0.1469], dtype=torch.float64, requires_grad=True), tensor([0.1769], dtype=torch.float64, requires_grad=True), tensor([-0.0127], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2557], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4316], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4169], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0880], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      " 67%|██████▋   | 20/30 [00:35<00:17,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 20; loss >> [4311.5337]\n",
      "model parameter $\\theta$ >> [tensor([-0.1008], dtype=torch.float64, requires_grad=True), tensor([0.0324], dtype=torch.float64, requires_grad=True), tensor([-0.0124], dtype=torch.float64, requires_grad=True), tensor([-0.1011], dtype=torch.float64, requires_grad=True), tensor([-0.1552], dtype=torch.float64, requires_grad=True), tensor([0.1852], dtype=torch.float64, requires_grad=True), tensor([-0.0029], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2597], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4408], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.4081], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.0977], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      " 70%|███████   | 21/30 [00:37<00:15,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 21; loss >> [4467.709]\n",
      "model parameter $\\theta$ >> [tensor([-0.0909], dtype=torch.float64, requires_grad=True), tensor([0.0300], dtype=torch.float64, requires_grad=True), tensor([-0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.0912], dtype=torch.float64, requires_grad=True), tensor([-0.1638], dtype=torch.float64, requires_grad=True), tensor([0.1938], dtype=torch.float64, requires_grad=True), tensor([0.0070], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2630], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4498], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3994], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1075], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      " 73%|███████▎  | 22/30 [00:39<00:14,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 22; loss >> [4395.932]\n",
      "model parameter $\\theta$ >> [tensor([-0.0811], dtype=torch.float64, requires_grad=True), tensor([0.0287], dtype=torch.float64, requires_grad=True), tensor([-0.0087], dtype=torch.float64, requires_grad=True), tensor([-0.0813], dtype=torch.float64, requires_grad=True), tensor([-0.1729], dtype=torch.float64, requires_grad=True), tensor([0.2029], dtype=torch.float64, requires_grad=True), tensor([0.0168], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2658], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4589], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3909], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1172], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      " 77%|███████▋  | 23/30 [00:41<00:12,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 23; loss >> [4366.562]\n",
      "model parameter $\\theta$ >> [tensor([-0.0712], dtype=torch.float64, requires_grad=True), tensor([0.0253], dtype=torch.float64, requires_grad=True), tensor([-0.0053], dtype=torch.float64, requires_grad=True), tensor([-0.0714], dtype=torch.float64, requires_grad=True), tensor([-0.1819], dtype=torch.float64, requires_grad=True), tensor([0.2119], dtype=torch.float64, requires_grad=True), tensor([0.0266], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2680], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4679], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3825], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1268], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      " 80%|████████  | 24/30 [00:42<00:10,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 24; loss >> [4218.8887]\n",
      "model parameter $\\theta$ >> [tensor([-0.0614], dtype=torch.float64, requires_grad=True), tensor([0.0207], dtype=torch.float64, requires_grad=True), tensor([-0.0007], dtype=torch.float64, requires_grad=True), tensor([-0.0615], dtype=torch.float64, requires_grad=True), tensor([-0.1908], dtype=torch.float64, requires_grad=True), tensor([0.2208], dtype=torch.float64, requires_grad=True), tensor([0.0364], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2696], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4768], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3743], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1365], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      " 83%|████████▎ | 25/30 [00:44<00:08,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 25; loss >> [4278.9023]\n",
      "model parameter $\\theta$ >> [tensor([-0.0516], dtype=torch.float64, requires_grad=True), tensor([0.0168], dtype=torch.float64, requires_grad=True), tensor([0.0032], dtype=torch.float64, requires_grad=True), tensor([-0.0517], dtype=torch.float64, requires_grad=True), tensor([-0.2000], dtype=torch.float64, requires_grad=True), tensor([0.2300], dtype=torch.float64, requires_grad=True), tensor([0.0462], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2706], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4860], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3663], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1461], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      " 87%|████████▋ | 26/30 [00:46<00:07,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 26; loss >> [4147.0894]\n",
      "model parameter $\\theta$ >> [tensor([-0.0419], dtype=torch.float64, requires_grad=True), tensor([0.0127], dtype=torch.float64, requires_grad=True), tensor([0.0073], dtype=torch.float64, requires_grad=True), tensor([-0.0418], dtype=torch.float64, requires_grad=True), tensor([-0.2092], dtype=torch.float64, requires_grad=True), tensor([0.2392], dtype=torch.float64, requires_grad=True), tensor([0.0560], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2712], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.4951], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3584], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1558], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      " 90%|█████████ | 27/30 [00:48<00:05,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 27; loss >> [4208.442]\n",
      "model parameter $\\theta$ >> [tensor([-0.0320], dtype=torch.float64, requires_grad=True), tensor([0.0079], dtype=torch.float64, requires_grad=True), tensor([0.0121], dtype=torch.float64, requires_grad=True), tensor([-0.0321], dtype=torch.float64, requires_grad=True), tensor([-0.2185], dtype=torch.float64, requires_grad=True), tensor([0.2485], dtype=torch.float64, requires_grad=True), tensor([0.0658], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2713], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5042], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3508], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1654], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      " 93%|█████████▎| 28/30 [00:50<00:03,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 28; loss >> [3869.64]\n",
      "model parameter $\\theta$ >> [tensor([-0.0220], dtype=torch.float64, requires_grad=True), tensor([0.0016], dtype=torch.float64, requires_grad=True), tensor([0.0184], dtype=torch.float64, requires_grad=True), tensor([-0.0224], dtype=torch.float64, requires_grad=True), tensor([-0.2281], dtype=torch.float64, requires_grad=True), tensor([0.2581], dtype=torch.float64, requires_grad=True), tensor([0.0755], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2709], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5132], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3433], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1749], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      " 97%|█████████▋| 29/30 [00:51<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 29; loss >> [3880.9768]\n",
      "model parameter $\\theta$ >> [tensor([-0.0123], dtype=torch.float64, requires_grad=True), tensor([-0.0042], dtype=torch.float64, requires_grad=True), tensor([0.0242], dtype=torch.float64, requires_grad=True), tensor([-0.0127], dtype=torch.float64, requires_grad=True), tensor([-0.2378], dtype=torch.float64, requires_grad=True), tensor([0.2678], dtype=torch.float64, requires_grad=True), tensor([0.0853], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2701], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5222], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3360], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1844], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "100%|██████████| 30/30 [00:53<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter >> 30; loss >> [3668.7031]\n",
      "model parameter $\\theta$ >> [tensor([-0.0024], dtype=torch.float64, requires_grad=True), tensor([-0.0098], dtype=torch.float64, requires_grad=True), tensor([0.0298], dtype=torch.float64, requires_grad=True), tensor([-0.0030], dtype=torch.float64, requires_grad=True), tensor([-0.2474], dtype=torch.float64, requires_grad=True), tensor([0.2774], dtype=torch.float64, requires_grad=True), tensor([0.0950], dtype=torch.float64, requires_grad=True), tensor([0.1000], dtype=torch.float64, requires_grad=True), tensor([-0.2690], dtype=torch.float64, requires_grad=True), tensor([0.0100], dtype=torch.float64, requires_grad=True), tensor([-0.5310], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True), tensor([-0.3290], dtype=torch.float64, requires_grad=True), tensor([0.8000], dtype=torch.float64, requires_grad=True), tensor([0.1938], dtype=torch.float64, requires_grad=True), tensor([0.0500], dtype=torch.float64, requires_grad=True)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1350x450 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LSTM_a = LSTM_Encoding_Action(input_size = 4, hidden_size = 15, output_size= 8, batch_size=5, device='cuda').cuda()\n",
    "LSTM_m = LSTM_Encoding_History(input_size = 10, hidden_size = 8, output_size = 4, batch_size=5, device='cuda').cuda()\n",
    "a = torch.rand(size=(5,4,4)).cuda() # batch, num_predicate, length\n",
    "h_a = LSTM_a.forward(a)\n",
    "m = torch.rand(size=(5,3,10)).cuda()\n",
    "prob = LSTM_m.forward(m,h_a)\n",
    "\n",
    "logits = torch.log(prob)\n",
    "def generate_incomplete_data(num_sample:int=10, time_horizon:float=5.0):\n",
    "        gen = Logic_Model_Generator()\n",
    "        data = gen.generate_data(num_sample=num_sample, time_horizon=time_horizon)\n",
    "        action_history = {}\n",
    "        for i in range(num_sample):\n",
    "            action_history_ = dict([(key, data[i][key]) for key in [3,4,5,6]])\n",
    "            action_history[i] = action_history_\n",
    "        #NOTE: info\n",
    "        print('[INFO] data has been generated!!!')\n",
    "        return action_history\n",
    "\n",
    "action_history = generate_incomplete_data(num_sample=20,time_horizon=1.0)\n",
    "learn = Logic_Model_Incomplete_Data(time_horizon=1.0,action_history=action_history,hidden_size=(15,20),output_size=(20,4),batch_size=20)\n",
    "losses = learn.train_model(num_iter=30,lr=(0.01,0.003))\n",
    "learn.plot_loss(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "271aaf9a14ca8aef692edd0e58d89184235237d981934b751bc9762a3149e378"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
